{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQ6glcvV1h73"
   },
   "source": [
    "<h2><strong>본격적으로 케라스와 버트를 활용하여 KorQUAD 예측 모델을 만들어 보겠습니다.</strong></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVGCHkKN0TZ3"
   },
   "source": [
    "텐서플로우, 판다스, 넘파이, 케라스 등 필요한 모듈들을 임포트합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "Ffa---Ov8WfF",
    "outputId": "6e28b257-6558-4eec-8015-7bd1b398fb8b"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.15.4 in c:\\users\\deeplearning_4\\appdata\\roaming\\python\\python36\\site-packages (1.15.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.15.4 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonnlp.data import SentencepieceTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVGK2j5tKJgS"
   },
   "source": [
    "SQUAD JSON파일을 PANDAS DATAFRAME으로 만들어주는 함수를 정의합니다. \n",
    "\n",
    "KorQuAD도 SQUAD랑 동일한 방식이기에, Pandas Dataframe으로 잘 변환 됩니다. \n",
    "출처 : https://www.kaggle.com/sanjay11100/squad-stanford-q-a-json-to-pandas-dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zgWmFtiaIZQK"
   },
   "outputs": [],
   "source": [
    "def squad_json_to_dataframe_train(input_file_path, record_path = ['data','paragraphs','qas','answers'], verbose = 1):\n",
    "    \"\"\"\n",
    "    input_file_path: path to the squad json file.\n",
    "    record_path: path to deepest level in json file default value is\n",
    "    ['data','paragraphs','qas','answers']\n",
    "    verbose: 0 to suppress it default is 1\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(\"Reading the json file\")    \n",
    "    file = json.loads(open(input_file_path).read())\n",
    "    if verbose:\n",
    "        print(\"processing...\")\n",
    "    # parsing different level's in the json file\n",
    "    js = pd.io.json.json_normalize(file , record_path )\n",
    "    m = pd.io.json.json_normalize(file, record_path[:-1] )\n",
    "    r = pd.io.json.json_normalize(file,record_path[:-2])\n",
    "    \n",
    "    #combining it into single dataframe\n",
    "    idx = np.repeat(r['context'].values, r.qas.str.len())\n",
    "    ndx  = np.repeat(m['id'].values,m['answers'].str.len())\n",
    "    m['context'] = idx\n",
    "    js['q_idx'] = ndx\n",
    "    main = pd.concat([ m[['id','question','context']].set_index('id'),js.set_index('q_idx')],1,sort=False).reset_index()\n",
    "    main['c_id'] = main['context'].factorize()[0]\n",
    "    if verbose:\n",
    "        print(\"shape of the dataframe is {}\".format(main.shape))\n",
    "        print(\"Done\")\n",
    "    return main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eoez6gHVGeP8"
   },
   "source": [
    "KorQUAD 데이터를 PANDAS DATAFRAME 형식으로 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "9j2vCEzCMW4K",
    "outputId": "dcc57443-eabf-4463-98e5-78200d0a08a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the json file\n",
      "processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DeepLearning_4\\anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "  \n",
      "C:\\Users\\DeepLearning_4\\anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:15: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\DeepLearning_4\\anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:16: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the dataframe is (60407, 6)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "train = squad_json_to_dataframe_train(\"KorQuAD_v1.0_train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "id": "waSYuY0kMfW5",
    "outputId": "f9498f40-282e-45dc-e842-3daaded3d4a7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>text</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>c_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6566495-0-0</td>\n",
       "      <td>바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?</td>\n",
       "      <td>1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...</td>\n",
       "      <td>교향곡</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6566495-0-1</td>\n",
       "      <td>바그너는 교향곡 작곡을 어디까지 쓴 뒤에 중단했는가?</td>\n",
       "      <td>1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...</td>\n",
       "      <td>1악장</td>\n",
       "      <td>421</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6566495-0-2</td>\n",
       "      <td>바그너가 파우스트 서곡을 쓸 때 어떤 곡의 영향을 받았는가?</td>\n",
       "      <td>1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...</td>\n",
       "      <td>베토벤의 교향곡 9번</td>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6566518-0-0</td>\n",
       "      <td>1839년 바그너가 교향곡의 소재로 쓰려고 했던 책은?</td>\n",
       "      <td>1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...</td>\n",
       "      <td>파우스트</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6566518-0-1</td>\n",
       "      <td>파우스트 서곡의 라단조 조성이 영향을 받은 베토벤의 곡은?</td>\n",
       "      <td>1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...</td>\n",
       "      <td>합창교향곡</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60402</th>\n",
       "      <td>6467478-1-1</td>\n",
       "      <td>뉴델리 메탈로 베타락마제가 처음 감염 된 지역은 어디인가?</td>\n",
       "      <td>유전자의 이름은 인도의 수도 뉴델리의 이름을 따 붙여졌는데, 이는 2009년 용 (...</td>\n",
       "      <td>인도</td>\n",
       "      <td>73</td>\n",
       "      <td>9604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60403</th>\n",
       "      <td>6467478-2-0</td>\n",
       "      <td>균은 유전자를 균에게 전달 할 수있는데 이러한 현상을 나타낸 용어는 무엇인가?</td>\n",
       "      <td>2010년 8월, 저널 The Lancet Infectious Diseases에 최...</td>\n",
       "      <td>유전자 전달</td>\n",
       "      <td>253</td>\n",
       "      <td>9605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60404</th>\n",
       "      <td>6467478-2-1</td>\n",
       "      <td>박테리아가 NDM-1 유전자를 가지고 있을때 발생하는 전파를 분석하기위해 사용된 영...</td>\n",
       "      <td>2010년 8월, 저널 The Lancet Infectious Diseases에 최...</td>\n",
       "      <td>37건</td>\n",
       "      <td>129</td>\n",
       "      <td>9605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60405</th>\n",
       "      <td>6490801-2-0</td>\n",
       "      <td>NDM-1 유전자를 가진 박테리아가 감수성을 보인 폴리믹슨 계열 항생제는?</td>\n",
       "      <td>2010년 8월, 저널 The Lancet Infectious Diseases에 최...</td>\n",
       "      <td>콜리스틴</td>\n",
       "      <td>404</td>\n",
       "      <td>9605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60406</th>\n",
       "      <td>6490801-2-1</td>\n",
       "      <td>2010년 8월, NDM-1 유전자를 가진 박테리아의 발생과 전파를 분석한 다국적 ...</td>\n",
       "      <td>2010년 8월, 저널 The Lancet Infectious Diseases에 최...</td>\n",
       "      <td>The Lancet Infectious Diseases</td>\n",
       "      <td>13</td>\n",
       "      <td>9605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60407 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             index                                           question  \\\n",
       "0      6566495-0-0                     바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?   \n",
       "1      6566495-0-1                      바그너는 교향곡 작곡을 어디까지 쓴 뒤에 중단했는가?   \n",
       "2      6566495-0-2                  바그너가 파우스트 서곡을 쓸 때 어떤 곡의 영향을 받았는가?   \n",
       "3      6566518-0-0                     1839년 바그너가 교향곡의 소재로 쓰려고 했던 책은?   \n",
       "4      6566518-0-1                   파우스트 서곡의 라단조 조성이 영향을 받은 베토벤의 곡은?   \n",
       "...            ...                                                ...   \n",
       "60402  6467478-1-1                   뉴델리 메탈로 베타락마제가 처음 감염 된 지역은 어디인가?   \n",
       "60403  6467478-2-0        균은 유전자를 균에게 전달 할 수있는데 이러한 현상을 나타낸 용어는 무엇인가?   \n",
       "60404  6467478-2-1  박테리아가 NDM-1 유전자를 가지고 있을때 발생하는 전파를 분석하기위해 사용된 영...   \n",
       "60405  6490801-2-0         NDM-1 유전자를 가진 박테리아가 감수성을 보인 폴리믹슨 계열 항생제는?    \n",
       "60406  6490801-2-1  2010년 8월, NDM-1 유전자를 가진 박테리아의 발생과 전파를 분석한 다국적 ...   \n",
       "\n",
       "                                                 context  \\\n",
       "0      1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...   \n",
       "1      1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...   \n",
       "2      1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...   \n",
       "3      1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...   \n",
       "4      1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로...   \n",
       "...                                                  ...   \n",
       "60402  유전자의 이름은 인도의 수도 뉴델리의 이름을 따 붙여졌는데, 이는 2009년 용 (...   \n",
       "60403  2010년 8월, 저널 The Lancet Infectious Diseases에 최...   \n",
       "60404  2010년 8월, 저널 The Lancet Infectious Diseases에 최...   \n",
       "60405  2010년 8월, 저널 The Lancet Infectious Diseases에 최...   \n",
       "60406  2010년 8월, 저널 The Lancet Infectious Diseases에 최...   \n",
       "\n",
       "                                 text  answer_start  c_id  \n",
       "0                                 교향곡            54     0  \n",
       "1                                 1악장           421     0  \n",
       "2                         베토벤의 교향곡 9번           194     0  \n",
       "3                                파우스트            15     0  \n",
       "4                               합창교향곡           354     0  \n",
       "...                               ...           ...   ...  \n",
       "60402                              인도            73  9604  \n",
       "60403                          유전자 전달           253  9605  \n",
       "60404                             37건           129  9605  \n",
       "60405                            콜리스틴           404  9605  \n",
       "60406  The Lancet Infectious Diseases            13  9605  \n",
       "\n",
       "[60407 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-NebUQmG1w-"
   },
   "source": [
    "\n",
    "- bert 훈련을 위한 사전 설정을 합니다. SEQ_LEN은 문장의 최대 길이입니다. SEQ_LEN 보다 문장의 길이가 작다면 남은 부분은 0이 채워지고, 만약에 SEQ_LEN보다 문장 길이가 길다면 SEQ_LEN을 초과하는 부분이 잘리게 됩니다.  \n",
    "본 문제에서는 메모리 문제 등으로 384로 정했습니다.\n",
    "- BATCH_SIZE는 메모리 초과 같은 문제를 방지하기 위해 작은 수인 10으로 정했습니다. 그리고 총 훈련 에포크 수는 1로 정했습니다. 학습율(LR;Learning rate)은 3e-5로 작게 정했습니다.\n",
    "- pretrained_path는 bert 사전학습 모형이 있는 폴더를 의미합니다.\n",
    "- 그리고 우리가 분석할 문장이 들어있는 칼럼의 제목인 document와 긍정인지 부정인지 알려주는 칼럼을 label로 정해줍니다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tLYWgZJAtsku"
   },
   "outputs": [],
   "source": [
    "SEQ_LEN = 384\n",
    "BATCH_SIZE = 3\n",
    "EPOCHS=1\n",
    "LR=3e-5\n",
    "\n",
    "pretrained_path =\"bert\"\n",
    "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
    "checkpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
    "vocab_path = os.path.join(pretrained_path, 'vocab.txt')\n",
    "\n",
    "DATA_COLUMN = \"context\"\n",
    "QUESTION_COLUMN = \"question\"\n",
    "TEXT = \"text\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IaU-13a9H4YJ"
   },
   "source": [
    "vocab.txt에 있는 단어에 인덱스를 추가해주는 token_dict라는 딕셔너리를 생성합니다.  \n",
    "우리가 분석할 문장이 토큰화가 되고, 그 다음에는 인덱스(숫자)로 변경되어서 버트 신경망에 인풋으로 들어게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WhiwaBCIXqv"
   },
   "source": [
    "- BERT의 토큰화는 단어를 분리하는 토큰화 방식입니다. wordpiece(단어조각?) 방식이라고 하는데, 이는 한국어를 형태소로 꼭 변환해야 할 문제를 해결해주며, 의미가 있는 단어는 밀접하게 연관이 되게 하는 장점까지 갖추고 있습니다.\n",
    "- 단어의 첫 시작은 ##가 붙지 않지만, 단어에 포함되면서 단어의 시작이 아닌 부분에는 ##가 붙는 것이 특징입니다.  \n",
    "- 네이버 감성분석에서 했던 것처럼, 한국어 감성분석에서는 새로 토크나이저 클래스를 상속을 받아서, 토크나이저를 재정의 해주어야 합니다.(그렇지 않으면 완전자모분리 현상 발생)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "bertmodel, vocab = get_pytorch_kobert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "88T_cMA4tsk2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "sp  = SentencepieceTokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0dmxrOhJ9vD"
   },
   "source": [
    "토큰화가 잘 되었는지 확인해 봅니다.\n",
    "버트 모형은 문장 앞에 꼭 [CLS]라는 문자가 위치하고, [SEP]라는 문자가 끝에 위치합니다.  \n",
    "[CLS]는 문장의 시작, [SEP]는 문장의 끝을 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "-4EWrSTCMkzk",
    "outputId": "78f01691-a9bb-45c4-885e-de8d16feee45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁한국', '어', '▁토', '큰', '화', '.'] ['▁잘', '되', '니', '▁', '.']\n"
     ]
    }
   ],
   "source": [
    "print(sp(\"한국어 토큰화.\"), tok(\"잘되니.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '▁한국', '어', '▁모델', '을', '▁공유', '합니다', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokList = sp(\"한국어 모델을 공유합니다.\")\n",
    "tokList.insert(0, '[CLS]')\n",
    "tokList.append('[SEP]')\n",
    "print(tokList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token1(text):\n",
    "    tokList = sp(text)\n",
    "    tokList.insert(0, '[CLS]')\n",
    "    tokList.append('[SEP]')\n",
    "    \n",
    "    return tokList\n",
    "\n",
    "def token2(text1, text2):\n",
    "    tokList1 = sp(text1)\n",
    "    tokList2 = sp(text2)\n",
    "    \n",
    "    tokList1.insert(0, '[CLS]')\n",
    "    tokList1.append('[SEP]')\n",
    "    for data in tokList2:\n",
    "        tokList1.append(data)\n",
    "    tokList1.append('[SEP]')\n",
    "    \n",
    "    return tokList1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " '▁자연',\n",
       " '어',\n",
       " '▁처리',\n",
       " '가',\n",
       " '▁뭐',\n",
       " '야',\n",
       " '?',\n",
       " '[SEP]',\n",
       " '▁자연',\n",
       " '어',\n",
       " '▁처리',\n",
       " '가',\n",
       " '▁뭐',\n",
       " '야',\n",
       " '?',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2(\"자연어 처리가 뭐야?\", \"자연어 처리가 뭐야?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = nlp.data.TSVDataset(\"ratings_train.txt@dl=1\", field_indices=[1,2], num_discard_samples=1)\n",
    "dataset_test = nlp.data.TSVDataset(\"ratings_test.txt@dl=1\", field_indices=[1,2], num_discard_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ATISDataset',\n",
       " 'BERTBasicTokenizer',\n",
       " 'BERTSPTokenizer',\n",
       " 'BERTSentenceTransform',\n",
       " 'BERTTokenizer',\n",
       " 'BakerVerb143',\n",
       " 'BiggerAnalogyTestSet',\n",
       " 'CR',\n",
       " 'ClipSequence',\n",
       " 'CoNLL2000',\n",
       " 'CoNLL2001',\n",
       " 'CoNLL2002',\n",
       " 'CoNLL2004',\n",
       " 'ConcatDataset',\n",
       " 'ConstWidthBucket',\n",
       " 'CorpusDataset',\n",
       " 'Counter',\n",
       " 'DataStream',\n",
       " 'DatasetStream',\n",
       " 'ExpWidthBucket',\n",
       " 'Fil9',\n",
       " 'FixedBucketSampler',\n",
       " 'GBWStream',\n",
       " 'GPT2BPEDetokenizer',\n",
       " 'GPT2BPETokenizer',\n",
       " 'GlueCoLA',\n",
       " 'GlueMNLI',\n",
       " 'GlueMRPC',\n",
       " 'GlueQNLI',\n",
       " 'GlueQQP',\n",
       " 'GlueRTE',\n",
       " 'GlueSST2',\n",
       " 'GlueSTSB',\n",
       " 'GlueWNLI',\n",
       " 'GoogleAnalogyTestSet',\n",
       " 'IMDB',\n",
       " 'IWSLT2015',\n",
       " 'JiebaTokenizer',\n",
       " 'LinearWidthBucket',\n",
       " 'MEN',\n",
       " 'MPQA',\n",
       " 'MR',\n",
       " 'NLTKMosesDetokenizer',\n",
       " 'NLTKMosesTokenizer',\n",
       " 'NLTKStanfordSegmenter',\n",
       " 'NumpyDataset',\n",
       " 'PadSequence',\n",
       " 'PrefetchingStream',\n",
       " 'RadinskyMTurk',\n",
       " 'RareWords',\n",
       " 'SNIPSDataset',\n",
       " 'SQuAD',\n",
       " 'SST_1',\n",
       " 'SST_2',\n",
       " 'SUBJ',\n",
       " 'SacreMosesDetokenizer',\n",
       " 'SacreMosesTokenizer',\n",
       " 'SemEval17Task2',\n",
       " 'SentencepieceDetokenizer',\n",
       " 'SentencepieceTokenizer',\n",
       " 'ShardedDataLoader',\n",
       " 'SimLex999',\n",
       " 'SimVerb3500',\n",
       " 'SimpleDataStream',\n",
       " 'SimpleDatasetStream',\n",
       " 'SortedBucketSampler',\n",
       " 'SortedSampler',\n",
       " 'SpacyTokenizer',\n",
       " 'SplitSampler',\n",
       " 'Splitter',\n",
       " 'TREC',\n",
       " 'TSVDataset',\n",
       " 'Text8',\n",
       " 'TextLineDataset',\n",
       " 'UnigramCandidateSampler',\n",
       " 'UniversalDependencies21',\n",
       " 'WMT2014',\n",
       " 'WMT2014BPE',\n",
       " 'WMT2016',\n",
       " 'WMT2016BPE',\n",
       " 'WikiText103',\n",
       " 'WikiText103Raw',\n",
       " 'WikiText2',\n",
       " 'WikiText2Raw',\n",
       " 'WordAnalogyEvaluationDataset',\n",
       " 'WordSim353',\n",
       " 'WordSimilarityEvaluationDataset',\n",
       " 'YangPowersVerb130',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'batchify',\n",
       " 'candidate_sampler',\n",
       " 'concat_sequence',\n",
       " 'conll',\n",
       " 'corpora',\n",
       " 'count_tokens',\n",
       " 'create',\n",
       " 'dataloader',\n",
       " 'dataset',\n",
       " 'glue',\n",
       " 'intent_slot',\n",
       " 'line_splitter',\n",
       " 'list_datasets',\n",
       " 'question_answering',\n",
       " 'register',\n",
       " 'registry',\n",
       " 'sampler',\n",
       " 'sentiment',\n",
       " 'slice_sequence',\n",
       " 'stream',\n",
       " 'train_valid_split',\n",
       " 'transforms',\n",
       " 'translation',\n",
       " 'utils',\n",
       " 'whitespace_splitter',\n",
       " 'word_embedding_evaluation']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(nlp.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on TSVDataset in module gluonnlp.data.dataset object:\n",
      "\n",
      "class TSVDataset(mxnet.gluon.data.dataset.SimpleDataset)\n",
      " |  Common tab separated text dataset that reads text fields based on provided sample splitter\n",
      " |  and field separator.\n",
      " |  \n",
      " |  The returned dataset includes samples, each of which can either be a list of text fields\n",
      " |  if field_separator is specified, or otherwise a single string segment produced by the\n",
      " |  sample_splitter.\n",
      " |  \n",
      " |  Example::\n",
      " |  \n",
      " |      # assume `test.tsv` contains the following content:\n",
      " |      # Id    FirstName       LastName\n",
      " |      # a     Jiheng  Jiang\n",
      " |      # b     Laoban  Zha\n",
      " |      # discard the first line and select the 0th and 2nd fields\n",
      " |      dataset = data.TSVDataset('test.tsv', num_discard_samples=1, field_indices=[0, 2])\n",
      " |      assert dataset[0] == [u'a', u'Jiang']\n",
      " |      assert dataset[1] == [u'b', u'Zha']\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  filename : str or list of str\n",
      " |      Path to the input text file or list of paths to the input text files.\n",
      " |  encoding : str, default 'utf8'\n",
      " |      File encoding format.\n",
      " |  sample_splitter : function, default str.splitlines\n",
      " |      A function that splits the dataset string into samples.\n",
      " |  field_separator : function or None, default Splitter('      ')\n",
      " |      A function that splits each sample string into list of text fields.\n",
      " |      If None, raw samples are returned according to `sample_splitter`.\n",
      " |  num_discard_samples : int, default 0\n",
      " |      Number of samples discarded at the head of the first file.\n",
      " |  field_indices : list of int or None, default None\n",
      " |      If set, for each sample, only fields with provided indices are selected as the output.\n",
      " |      Otherwise all fields are returned.\n",
      " |  allow_missing : bool, default False\n",
      " |      If set to True, no exception will be thrown if the number of fields is smaller than the\n",
      " |      maximum field index provided.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TSVDataset\n",
      " |      mxnet.gluon.data.dataset.SimpleDataset\n",
      " |      mxnet.gluon.data.dataset.Dataset\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, filename, encoding='utf8', sample_splitter=<function line_splitter at 0x000002910E1B8E18>, field_separator=<gluonnlp.data.utils.Splitter object at 0x000002910E2FB2B0>, num_discard_samples=0, field_indices=None, allow_missing=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from mxnet.gluon.data.dataset.SimpleDataset:\n",
      " |  \n",
      " |  __getitem__(self, idx)\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from mxnet.gluon.data.dataset.Dataset:\n",
      " |  \n",
      " |  transform(self, fn, lazy=True)\n",
      " |      Returns a new dataset with each sample transformed by the\n",
      " |      transformer function `fn`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fn : callable\n",
      " |          A transformer function that takes a sample as input and\n",
      " |          returns the transformed sample.\n",
      " |      lazy : bool, default True\n",
      " |          If False, transforms all samples at once. Otherwise,\n",
      " |          transforms each sample on demand. Note that if `fn`\n",
      " |          is stochastic, you must set lazy to True or you will\n",
      " |          get the same result on all epochs.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Dataset\n",
      " |          The transformed dataset.\n",
      " |  \n",
      " |  transform_first(self, fn, lazy=True)\n",
      " |      Returns a new dataset with the first element of each sample\n",
      " |      transformed by the transformer function `fn`.\n",
      " |      \n",
      " |      This is useful, for example, when you only want to transform data\n",
      " |      while keeping label as is.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fn : callable\n",
      " |          A transformer function that takes the first elemtn of a sample\n",
      " |          as input and returns the transformed element.\n",
      " |      lazy : bool, default True\n",
      " |          If False, transforms all samples at once. Otherwise,\n",
      " |          transforms each sample on demand. Note that if `fn`\n",
      " |          is stochastic, you must set lazy to True or you will\n",
      " |          get the same result on all epochs.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Dataset\n",
      " |          The transformed dataset.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from mxnet.gluon.data.dataset.Dataset:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TSVDataset' object has no attribute 'getitem'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-38cee4821084>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mhelp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdataset_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'TSVDataset' object has no attribute 'getitem'"
     ]
    }
   ],
   "source": [
    "help(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class BERTSentenceTransform in module gluonnlp.data.transforms:\n",
      "\n",
      "class BERTSentenceTransform(builtins.object)\n",
      " |  BERT style data transformation.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  tokenizer : BERTTokenizer.\n",
      " |      Tokenizer for the sentences.\n",
      " |  max_seq_length : int.\n",
      " |      Maximum sequence length of the sentences.\n",
      " |  pad : bool, default True\n",
      " |      Whether to pad the sentences to maximum length.\n",
      " |  pair : bool, default True\n",
      " |      Whether to transform sentences or sentence pairs.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __call__(self, line)\n",
      " |      Perform transformation for sequence pairs or single sequences.\n",
      " |      \n",
      " |      The transformation is processed in the following steps:\n",
      " |      - tokenize the input sequences\n",
      " |      - insert [CLS], [SEP] as necessary\n",
      " |      - generate type ids to indicate whether a token belongs to the first\n",
      " |      sequence or the second sequence.\n",
      " |      - generate valid length\n",
      " |      \n",
      " |      For sequence pairs, the input is a tuple of 2 strings:\n",
      " |      text_a, text_b.\n",
      " |      \n",
      " |      Inputs:\n",
      " |          text_a: 'is this jacksonville ?'\n",
      " |          text_b: 'no it is not'\n",
      " |      Tokenization:\n",
      " |          text_a: 'is this jack ##son ##ville ?'\n",
      " |          text_b: 'no it is not .'\n",
      " |      Processed:\n",
      " |          tokens: '[CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]'\n",
      " |          type_ids: 0     0  0    0    0     0       0 0     1  1  1  1   1 1\n",
      " |          valid_length: 14\n",
      " |      \n",
      " |      For single sequences, the input is a tuple of single string:\n",
      " |      text_a.\n",
      " |      \n",
      " |      Inputs:\n",
      " |          text_a: 'the dog is hairy .'\n",
      " |      Tokenization:\n",
      " |          text_a: 'the dog is hairy .'\n",
      " |      Processed:\n",
      " |          text_a: '[CLS] the dog is hairy . [SEP]'\n",
      " |          type_ids: 0     0   0   0  0     0 0\n",
      " |          valid_length: 7\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      line: tuple of str\n",
      " |          Input strings. For sequence pairs, the input is a tuple of 2 strings:\n",
      " |          (text_a, text_b). For single sequences, the input is a tuple of single\n",
      " |          string: (text_a,).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      np.array: input token ids in 'int32', shape (batch_size, seq_length)\n",
      " |      np.array: valid length in 'int32', shape (batch_size,)\n",
      " |      np.array: input token type ids in 'int32', shape (batch_size, seq_length)\n",
      " |  \n",
      " |  __init__(self, tokenizer, max_seq_length, pad=True, pair=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nlp.data.BERTSentenceTransform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module gluonnlp.data.dataset in gluonnlp.data:\n",
      "\n",
      "NAME\n",
      "    gluonnlp.data.dataset\n",
      "\n",
      "DESCRIPTION\n",
      "    NLP Toolkit Dataset API. It allows easy and customizable loading of corpora and dataset files.\n",
      "    Files can be loaded into formats that are immediately ready for training and evaluation.\n",
      "\n",
      "CLASSES\n",
      "    mxnet.gluon.data.dataset.ArrayDataset(mxnet.gluon.data.dataset.Dataset)\n",
      "        NumpyDataset\n",
      "    mxnet.gluon.data.dataset.Dataset(builtins.object)\n",
      "        ConcatDataset\n",
      "    mxnet.gluon.data.dataset.SimpleDataset(mxnet.gluon.data.dataset.Dataset)\n",
      "        CorpusDataset\n",
      "        TSVDataset\n",
      "        TextLineDataset\n",
      "    \n",
      "    class ConcatDataset(mxnet.gluon.data.dataset.Dataset)\n",
      "     |  Dataset that concatenates a list of datasets.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  datasets : list\n",
      "     |      List of datasets.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ConcatDataset\n",
      "     |      mxnet.gluon.data.dataset.Dataset\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, i)\n",
      "     |  \n",
      "     |  __init__(self, datasets)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  transform(self, fn, lazy=True)\n",
      "     |      Returns a new dataset with each sample transformed by the\n",
      "     |      transformer function `fn`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fn : callable\n",
      "     |          A transformer function that takes a sample as input and\n",
      "     |          returns the transformed sample.\n",
      "     |      lazy : bool, default True\n",
      "     |          If False, transforms all samples at once. Otherwise,\n",
      "     |          transforms each sample on demand. Note that if `fn`\n",
      "     |          is stochastic, you must set lazy to True or you will\n",
      "     |          get the same result on all epochs.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Dataset\n",
      "     |          The transformed dataset.\n",
      "     |  \n",
      "     |  transform_first(self, fn, lazy=True)\n",
      "     |      Returns a new dataset with the first element of each sample\n",
      "     |      transformed by the transformer function `fn`.\n",
      "     |      \n",
      "     |      This is useful, for example, when you only want to transform data\n",
      "     |      while keeping label as is.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fn : callable\n",
      "     |          A transformer function that takes the first elemtn of a sample\n",
      "     |          as input and returns the transformed element.\n",
      "     |      lazy : bool, default True\n",
      "     |          If False, transforms all samples at once. Otherwise,\n",
      "     |          transforms each sample on demand. Note that if `fn`\n",
      "     |          is stochastic, you must set lazy to True or you will\n",
      "     |          get the same result on all epochs.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Dataset\n",
      "     |          The transformed dataset.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mxnet.gluon.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class CorpusDataset(mxnet.gluon.data.dataset.SimpleDataset)\n",
      "     |  Common text dataset that reads a whole corpus based on provided sample splitter\n",
      "     |  and word tokenizer.\n",
      "     |  \n",
      "     |  The returned dataset includes samples, each of which can either be a list of tokens if tokenizer\n",
      "     |  is specified, or otherwise a single string segment produced by the sample_splitter.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  filename : str or list of str\n",
      "     |      Path to the input text file or list of paths to the input text files.\n",
      "     |  encoding : str, default 'utf8'\n",
      "     |      File encoding format.\n",
      "     |  flatten : bool, default False\n",
      "     |      Whether to return all samples as flattened tokens. If True, each sample is a token.\n",
      "     |  skip_empty : bool, default True\n",
      "     |      Whether to skip the empty samples produced from sample_splitters. If False, `bos` and `eos`\n",
      "     |      will be added in empty samples.\n",
      "     |  sample_splitter : function, default str.splitlines\n",
      "     |      A function that splits the dataset string into samples.\n",
      "     |  tokenizer : function or None, default str.split\n",
      "     |      A function that splits each sample string into list of tokens. If None, raw samples are\n",
      "     |      returned according to `sample_splitter`.\n",
      "     |  bos : str or None, default None\n",
      "     |      The token to add at the beginning of each sequence. If None, or if tokenizer is not\n",
      "     |      specified, then nothing is added.\n",
      "     |  eos : str or None, default None\n",
      "     |      The token to add at the end of each sequence. If None, or if tokenizer is not\n",
      "     |      specified, then nothing is added.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CorpusDataset\n",
      "     |      mxnet.gluon.data.dataset.SimpleDataset\n",
      "     |      mxnet.gluon.data.dataset.Dataset\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, filename, encoding='utf8', flatten=False, skip_empty=True, sample_splitter=<function line_splitter at 0x000002910E1B8E18>, tokenizer=<function whitespace_splitter at 0x000002910E1B8EA0>, bos=None, eos=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.data.dataset.SimpleDataset:\n",
      "     |  \n",
      "     |  __getitem__(self, idx)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  transform(self, fn, lazy=True)\n",
      "     |      Returns a new dataset with each sample transformed by the\n",
      "     |      transformer function `fn`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fn : callable\n",
      "     |          A transformer function that takes a sample as input and\n",
      "     |          returns the transformed sample.\n",
      "     |      lazy : bool, default True\n",
      "     |          If False, transforms all samples at once. Otherwise,\n",
      "     |          transforms each sample on demand. Note that if `fn`\n",
      "     |          is stochastic, you must set lazy to True or you will\n",
      "     |          get the same result on all epochs.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Dataset\n",
      "     |          The transformed dataset.\n",
      "     |  \n",
      "     |  transform_first(self, fn, lazy=True)\n",
      "     |      Returns a new dataset with the first element of each sample\n",
      "     |      transformed by the transformer function `fn`.\n",
      "     |      \n",
      "     |      This is useful, for example, when you only want to transform data\n",
      "     |      while keeping label as is.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fn : callable\n",
      "     |          A transformer function that takes the first elemtn of a sample\n",
      "     |          as input and returns the transformed element.\n",
      "     |      lazy : bool, default True\n",
      "     |          If False, transforms all samples at once. Otherwise,\n",
      "     |          transforms each sample on demand. Note that if `fn`\n",
      "     |          is stochastic, you must set lazy to True or you will\n",
      "     |          get the same result on all epochs.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Dataset\n",
      "     |          The transformed dataset.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mxnet.gluon.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class NumpyDataset(mxnet.gluon.data.dataset.ArrayDataset)\n",
      "     |  A dataset wrapping over a Numpy binary (.npy, .npz) file.\n",
      "     |  \n",
      "     |  If the file is a .npy file, then a single numpy array is loaded.\n",
      "     |  If the file is a .npz file with multiple arrays, then a list of\n",
      "     |  numpy arrays are loaded, ordered by their key in the archive.\n",
      "     |  \n",
      "     |  Sparse matrix is not yet supported.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  filename : str\n",
      "     |      Path to the .npy or .npz file.\n",
      "     |  \n",
      "     |  Properties\n",
      "     |  ----------\n",
      "     |  keys: list of str or None\n",
      "     |      The list of keys loaded from the .npz file.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      NumpyDataset\n",
      "     |      mxnet.gluon.data.dataset.ArrayDataset\n",
      "     |      mxnet.gluon.data.dataset.Dataset\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, filename)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  get_field(self, field)\n",
      "     |      Return the dataset corresponds to the provided key.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          a = np.ones((2,2))\n",
      "     |          b = np.zeros((2,2))\n",
      "     |          np.savez('data.npz', a=a, b=b)\n",
      "     |          dataset = NumpyDataset('data.npz')\n",
      "     |          data_a = dataset.get_field('a')\n",
      "     |          data_b = dataset.get_field('b')\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      field : str\n",
      "     |          The name of the field to retrieve.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  keys\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.data.dataset.ArrayDataset:\n",
      "     |  \n",
      "     |  __getitem__(self, idx)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  transform(self, fn, lazy=True)\n",
      "     |      Returns a new dataset with each sample transformed by the\n",
      "     |      transformer function `fn`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fn : callable\n",
      "     |          A transformer function that takes a sample as input and\n",
      "     |          returns the transformed sample.\n",
      "     |      lazy : bool, default True\n",
      "     |          If False, transforms all samples at once. Otherwise,\n",
      "     |          transforms each sample on demand. Note that if `fn`\n",
      "     |          is stochastic, you must set lazy to True or you will\n",
      "     |          get the same result on all epochs.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Dataset\n",
      "     |          The transformed dataset.\n",
      "     |  \n",
      "     |  transform_first(self, fn, lazy=True)\n",
      "     |      Returns a new dataset with the first element of each sample\n",
      "     |      transformed by the transformer function `fn`.\n",
      "     |      \n",
      "     |      This is useful, for example, when you only want to transform data\n",
      "     |      while keeping label as is.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fn : callable\n",
      "     |          A transformer function that takes the first elemtn of a sample\n",
      "     |          as input and returns the transformed element.\n",
      "     |      lazy : bool, default True\n",
      "     |          If False, transforms all samples at once. Otherwise,\n",
      "     |          transforms each sample on demand. Note that if `fn`\n",
      "     |          is stochastic, you must set lazy to True or you will\n",
      "     |          get the same result on all epochs.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Dataset\n",
      "     |          The transformed dataset.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mxnet.gluon.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class TSVDataset(mxnet.gluon.data.dataset.SimpleDataset)\n",
      "     |  Common tab separated text dataset that reads text fields based on provided sample splitter\n",
      "     |  and field separator.\n",
      "     |  \n",
      "     |  The returned dataset includes samples, each of which can either be a list of text fields\n",
      "     |  if field_separator is specified, or otherwise a single string segment produced by the\n",
      "     |  sample_splitter.\n",
      "     |  \n",
      "     |  Example::\n",
      "     |  \n",
      "     |      # assume `test.tsv` contains the following content:\n",
      "     |      # Id    FirstName       LastName\n",
      "     |      # a     Jiheng  Jiang\n",
      "     |      # b     Laoban  Zha\n",
      "     |      # discard the first line and select the 0th and 2nd fields\n",
      "     |      dataset = data.TSVDataset('test.tsv', num_discard_samples=1, field_indices=[0, 2])\n",
      "     |      assert dataset[0] == [u'a', u'Jiang']\n",
      "     |      assert dataset[1] == [u'b', u'Zha']\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  filename : str or list of str\n",
      "     |      Path to the input text file or list of paths to the input text files.\n",
      "     |  encoding : str, default 'utf8'\n",
      "     |      File encoding format.\n",
      "     |  sample_splitter : function, default str.splitlines\n",
      "     |      A function that splits the dataset string into samples.\n",
      "     |  field_separator : function or None, default Splitter('      ')\n",
      "     |      A function that splits each sample string into list of text fields.\n",
      "     |      If None, raw samples are returned according to `sample_splitter`.\n",
      "     |  num_discard_samples : int, default 0\n",
      "     |      Number of samples discarded at the head of the first file.\n",
      "     |  field_indices : list of int or None, default None\n",
      "     |      If set, for each sample, only fields with provided indices are selected as the output.\n",
      "     |      Otherwise all fields are returned.\n",
      "     |  allow_missing : bool, default False\n",
      "     |      If set to True, no exception will be thrown if the number of fields is smaller than the\n",
      "     |      maximum field index provided.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TSVDataset\n",
      "     |      mxnet.gluon.data.dataset.SimpleDataset\n",
      "     |      mxnet.gluon.data.dataset.Dataset\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, filename, encoding='utf8', sample_splitter=<function line_splitter at 0x000002910E1B8E18>, field_separator=<gluonnlp.data.utils.Splitter object at 0x000002910E2FB2B0>, num_discard_samples=0, field_indices=None, allow_missing=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.data.dataset.SimpleDataset:\n",
      "     |  \n",
      "     |  __getitem__(self, idx)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  transform(self, fn, lazy=True)\n",
      "     |      Returns a new dataset with each sample transformed by the\n",
      "     |      transformer function `fn`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fn : callable\n",
      "     |          A transformer function that takes a sample as input and\n",
      "     |          returns the transformed sample.\n",
      "     |      lazy : bool, default True\n",
      "     |          If False, transforms all samples at once. Otherwise,\n",
      "     |          transforms each sample on demand. Note that if `fn`\n",
      "     |          is stochastic, you must set lazy to True or you will\n",
      "     |          get the same result on all epochs.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Dataset\n",
      "     |          The transformed dataset.\n",
      "     |  \n",
      "     |  transform_first(self, fn, lazy=True)\n",
      "     |      Returns a new dataset with the first element of each sample\n",
      "     |      transformed by the transformer function `fn`.\n",
      "     |      \n",
      "     |      This is useful, for example, when you only want to transform data\n",
      "     |      while keeping label as is.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fn : callable\n",
      "     |          A transformer function that takes the first elemtn of a sample\n",
      "     |          as input and returns the transformed element.\n",
      "     |      lazy : bool, default True\n",
      "     |          If False, transforms all samples at once. Otherwise,\n",
      "     |          transforms each sample on demand. Note that if `fn`\n",
      "     |          is stochastic, you must set lazy to True or you will\n",
      "     |          get the same result on all epochs.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Dataset\n",
      "     |          The transformed dataset.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mxnet.gluon.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class TextLineDataset(mxnet.gluon.data.dataset.SimpleDataset)\n",
      "     |  Dataset that comprises lines in a file. Each line will be stripped.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  filename : str\n",
      "     |      Path to the input text file.\n",
      "     |  encoding : str, default 'utf8'\n",
      "     |      File encoding format.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TextLineDataset\n",
      "     |      mxnet.gluon.data.dataset.SimpleDataset\n",
      "     |      mxnet.gluon.data.dataset.Dataset\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, filename, encoding='utf8')\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.data.dataset.SimpleDataset:\n",
      "     |  \n",
      "     |  __getitem__(self, idx)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from mxnet.gluon.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  transform(self, fn, lazy=True)\n",
      "     |      Returns a new dataset with each sample transformed by the\n",
      "     |      transformer function `fn`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fn : callable\n",
      "     |          A transformer function that takes a sample as input and\n",
      "     |          returns the transformed sample.\n",
      "     |      lazy : bool, default True\n",
      "     |          If False, transforms all samples at once. Otherwise,\n",
      "     |          transforms each sample on demand. Note that if `fn`\n",
      "     |          is stochastic, you must set lazy to True or you will\n",
      "     |          get the same result on all epochs.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Dataset\n",
      "     |          The transformed dataset.\n",
      "     |  \n",
      "     |  transform_first(self, fn, lazy=True)\n",
      "     |      Returns a new dataset with the first element of each sample\n",
      "     |      transformed by the transformer function `fn`.\n",
      "     |      \n",
      "     |      This is useful, for example, when you only want to transform data\n",
      "     |      while keeping label as is.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fn : callable\n",
      "     |          A transformer function that takes the first elemtn of a sample\n",
      "     |          as input and returns the transformed element.\n",
      "     |      lazy : bool, default True\n",
      "     |          If False, transforms all samples at once. Otherwise,\n",
      "     |          transforms each sample on demand. Note that if `fn`\n",
      "     |          is stochastic, you must set lazy to True or you will\n",
      "     |          get the same result on all epochs.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Dataset\n",
      "     |          The transformed dataset.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from mxnet.gluon.data.dataset.Dataset:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "DATA\n",
      "    __all__ = ['TextLineDataset', 'CorpusDataset', 'ConcatDataset', 'TSVDa...\n",
      "\n",
      "FILE\n",
      "    c:\\users\\deeplearning_4\\anaconda3\\envs\\torch\\lib\\site-packages\\gluonnlp\\data\\dataset.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nlp.data.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCC_Z1TNSODT"
   },
   "source": [
    "token dict의 key 값과 value 값을 바꾼 reverse_token_dict를 정의합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9sFKLjD-v2n"
   },
   "source": [
    "**버트 모형에 들어갈 인풋은 토큰, 세그먼트, 포지션으로 구성됩니다.**  \n",
    "버트에 인풋으로 들어가는 토큰은 문장을 토크나이징 한 후, 인덱스 번호를 매긴 것입니다.  \n",
    "세그먼트는 예를 들어 문장이 두 개가 있다면, 앞의 문장과 뒤의 문장을 구분하는 것입니다.  \n",
    "포지션 임베딩은 단순히 단어의 위치를 말합니다.\n",
    "\n",
    "토큰, 세그먼트, 포지션을 인풋으로 버트 모형에 넣으면 기하학적인 문장 공간으로 임베딩이 됩니다.  \n",
    "그림을 보면 my dog is cute, he likes play ##ing 두 문장이 있는데요  \n",
    "KorQUAD 문제에서는 첫번째 문장이 질문, 두번째 문장이 context가 되고, 이 두 문장이 합쳐져서 하나의 문장으로 들어가게 됩니다.\n",
    "\n",
    "![대체 텍스트](https://i.imgur.com/l9BTao3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oXdjhy0cLlYA"
   },
   "source": [
    "- 사전학습된 버트 모델의 인풋은 문장 토큰화가 숫자로 바뀐 것과, 앞문장인지 뒷문장인지 알려주는 문장 순서 벡터가 들어갑니다. 우리는 문장 하나를 가지고만 훈련할 것이므로 순서 벡터는 모두 0으로 통일합니다.\n",
    "\n",
    "- 그리고 파인튜닝 시에는 문장 안에 일부 단어를 가리는 마스킹은 사용하지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fraw-fe9PL1k"
   },
   "source": [
    "우리가 로드하였던 KorQUAD 데이터를 **버트 모형의 입력에 맞게 변형해주는 함수**를 정의하도록 하겠습니다.\n",
    "\n",
    "함수 내부에 tokenizer.encode 함수가 버트 모형을 토큰화해주고 토큰화 된 단어를 인덱스에 맞게 숫자로 바꿔주게 됩니다.  \n",
    "**[CLS] 질문 [SEP] 문장 [SEP]** 이런 방식으로 질문과 문장이 인풋으로 들어가게 됩니다. SEQ_LEN이 384로 지정되어 있어서 길이가 384가 넘는 인풋은 문장 부분이 잘려서 들어가게 됩니다.  \n",
    "SQUAD 문제에서 문장(context) 내에 text(정답)이 포함된다고 미리 말씀 드렸는데요, 길이가 384가 넘는 인풋인 경우에 context 내에 정답을 포함하고 있는 context가 잘려서 정답을 포함하지 않는 경우가 생깁니다. 이번 실습에서는 이러한 경우의 인덱스를 del_list로 지정해서, 빼도록 하겠습니다. (숙제로 남겨 두겠습니다.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "jYrlZPd3YExo"
   },
   "outputs": [],
   "source": [
    "question = train['question'][0]\n",
    "context = train['context'][0]\n",
    "text = train['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "xjcdonPiY3U9",
    "outputId": "fcecbbc1-e9bf-4080-c401-c08120835a7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 질문\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "2tRbEbSCY4dx",
    "outputId": "9560a9df-9781-409d-fcbf-8dab63022079"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다. 이 시기 바그너는 1838년에 빛 독촉으로 산전수전을 다 걲은 상황이라 좌절과 실망에 가득했으며 메피스토펠레스를 만나는 파우스트의 심경에 공감했다고 한다. 또한 파리에서 아브네크의 지휘로 파리 음악원 관현악단이 연주하는 베토벤의 교향곡 9번을 듣고 깊은 감명을 받았는데, 이것이 이듬해 1월에 파우스트의 서곡으로 쓰여진 이 작품에 조금이라도 영향을 끼쳤으리라는 것은 의심할 여지가 없다. 여기의 라단조 조성의 경우에도 그의 전기에 적혀 있는 것처럼 단순한 정신적 피로나 실의가 반영된 것이 아니라 베토벤의 합창교향곡 조성의 영향을 받은 것을 볼 수 있다. 그렇게 교향곡 작곡을 1839년부터 40년에 걸쳐 파리에서 착수했으나 1악장을 쓴 뒤에 중단했다. 또한 작품의 완성과 동시에 그는 이 서곡(1악장)을 파리 음악원의 연주회에서 연주할 파트보까지 준비하였으나, 실제로는 이루어지지는 않았다. 결국 초연은 4년 반이 지난 후에 드레스덴에서 연주되었고 재연도 이루어졌지만, 이후에 그대로 방치되고 말았다. 그 사이에 그는 리엔치와 방황하는 네덜란드인을 완성하고 탄호이저에도 착수하는 등 분주한 시간을 보냈는데, 그런 바쁜 생활이 이 곡을 잊게 한 것이 아닌가 하는 의견도 있다.'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "ZhMGIFOhY5hz",
    "outputId": "e88afda8-d297-41db-f164-4c9e562cc6e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'교향곡'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "10hBmhcvY68i",
    "outputId": "70064900-5801-4238-b5ee-8739ca9a957d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '▁바', '그', '너', '는', '▁괴', '테', '의', '▁파', '우', '스트', '를', '▁읽', '고', '▁무', '엇', '을', '▁쓰', '고', '자', '▁했', '는', '가', '?', '[SEP]', '▁18', '39', '년', '▁바', '그', '너', '는', '▁괴', '테', '의', '▁파', '우', '스트', '을', '▁처음', '▁읽', '고', '▁그', '▁내용', '에', '▁마음', '이', '▁', '끌', '려', '▁이를', '▁소재', '로', '▁해서', '▁하나', '의', '▁교', '향', '곡', '을', '▁쓰', '려는', '▁뜻을', '▁갖', '는', '다', '.', '▁이', '▁시기', '▁바', '그', '너', '는', '▁18', '38', '년에', '▁빛', '▁독', '촉', '으로', '▁산', '전', '수', '전을', '▁다', '▁', '걲', '은', '▁상황이', '라', '▁좌', '절', '과', '▁실망', '에', '▁가득', '했으며', '▁메', '피스', '토', '펠', '레스', '를', '▁만나', '는', '▁파', '우', '스트', '의', '▁심경', '에', '▁공감', '했다고', '▁한다', '.', '▁또한', '▁파', '리', '에서', '▁아', '브', '네', '크', '의', '▁지휘', '로', '▁파', '리', '▁음악', '원', '▁관', '현', '악', '단', '이', '▁연', '주', '하는', '▁베', '토', '벤', '의', '▁교', '향', '곡', '▁9', '번', '을', '▁듣고', '▁깊은', '▁감', '명을', '▁받았', '는데', ',', '▁이것', '이', '▁이', '듬', '해', '▁1', '월에', '▁파', '우', '스트', '의', '▁서', '곡', '으로', '▁쓰', '여', '진', '▁이', '▁작품', '에', '▁조금', '이라도', '▁영향을', '▁끼', '쳤', '으', '리', '라는', '▁것은', '▁의심', '할', '▁여', '지가', '▁없다', '.', '▁여기', '의', '▁라', '단', '조', '▁조성', '의', '▁경우', '에도', '▁그의', '▁전기', '에', '▁적', '혀', '▁있는', '▁것처럼', '▁단순', '한', '▁정신', '적', '▁피', '로', '나', '▁실', '의', '가', '▁반영', '된', '▁것이', '▁아니라', '▁베', '토', '벤', '의', '▁합', '창', '교', '향', '곡', '▁조성', '의', '▁영향을', '▁받은', '▁것을', '▁볼', '▁수', '▁있다', '.', '▁그렇게', '▁교', '향', '곡', '▁작곡', '을', '▁18', '39', '년부터', '▁40', '년에', '▁걸쳐', '▁파', '리', '에서', '▁착수', '했으나', '▁1', '악', '장을', '▁쓴', '▁뒤', '에', '▁중단', '했다', '.', '▁또한', '▁작품', '의', '▁완성', '과', '▁동시에', '▁그는', '▁이', '▁서', '곡', '(1', '악', '장', ')', '을', '▁파', '리', '▁음악', '원의', '▁연', '주', '회', '에서', '▁연', '주', '할', '▁파', '트', '보', '까지', '▁준비', '하', '였', '으나', ',', '▁실제로', '는', '▁이루', '어', '지', '지는', '▁않았다', '.', '▁결국', '▁초', '연', '은', '▁4', '년', '▁반', '이', '▁지난', '▁후', '에', '▁드레스', '덴', '에서', '▁연', '주', '되었', '고', '▁재', '연', '도', '▁이루', '어', '졌지만', ',', '▁이후', '에', '▁그대로', '▁방', '치', '되고', '▁말', '았다', '.', '▁그', '▁사이에', '▁그는', '▁리', '엔', '치', '와', '▁방', '황', '하는', '▁네', '덜', '란', '드', '인', '을', '▁완성', '하고', '▁탄', '호', '이', '저', '에도', '▁착수', '하는', '▁등', '▁분', '주', '한', '▁시간을', '▁보', '냈', '는데', ',', '▁그런', '▁바', '쁜', '▁생활', '이', '▁이', '▁곡', '을', '▁', '잊', '게', '▁한', '▁것이', '▁아닌', '가', '▁하는', '▁의견', '도', '▁있다', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(token2(question, context))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgOlJH_4ZQpS"
   },
   "source": [
    "우리의 목표는, 질문(question)과 문장(context)를 받아서, 정답(text)를 맞추는 모델을 만드는 것입니다.  \n",
    "정답을 통째로 맞추는 것이 아니라, **토큰화된 것의 맨 앞 단어와, 맨 뒷 단어입니다.**  \n",
    "토큰화된 정답은 ['[CLS]', 'saint', 'bern', '##ade', '##tte', 'sou', '##bir', '##ous', '[SEP]'] 인데, 여기서 **saint**에 해당하는 위치와 **##ous**에 해당하는 위치를 맞추는 버트 모형을 파인튜닝 하려 하는 것입니다.  \n",
    "\n",
    "  그래서 밑에 convert_data 함수에서, 정답(text) 길이만큼 문장(context)를 슬라이딩 하면서 만약에 문장이 정답을 포함하는 위치에 도달하면, 문장에서 정답의 맨 앞이 우리가 예측할 1번째 정답, 정답의 맨 뒤가 우리가 예측할 2번째 정답이 되게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "0rJsxRZDWw4e"
   },
   "outputs": [],
   "source": [
    "def convert_data(data_df):\n",
    "    global tokenizer\n",
    "    indices, segments, target_start, target_end = [], [], [], []\n",
    "    for i in tqdm(range(len(data_df))):\n",
    "        \n",
    "        ids, segment = tokenizer.encode(data_df[QUESTION_COLUMN][i], data_df[DATA_COLUMN][i], max_len=SEQ_LEN)\n",
    "        \n",
    "\n",
    "        text = tokenizer.encode(data_df[TEXT][i])[0]\n",
    "\n",
    "        text_slide_len = len(text[1:-1])\n",
    "        for i in range(1,len(ids)-text_slide_len-1):  \n",
    "            exist_flag = 0\n",
    "            if text[1:-1] == ids[i:i+text_slide_len]:\n",
    "              ans_start = i\n",
    "              ans_end = i + text_slide_len - 1\n",
    "              exist_flag = 1\n",
    "              break\n",
    "        \n",
    "        if exist_flag == 0:\n",
    "          ans_start = SEQ_LEN\n",
    "          ans_end = SEQ_LEN\n",
    "\n",
    "        indices.append(ids)\n",
    "        segments.append(segment)\n",
    "\n",
    "        target_start.append(ans_start)\n",
    "        target_end.append(ans_end)\n",
    "\n",
    "    indices_x = np.array(indices)\n",
    "    segments = np.array(segments)\n",
    "    target_start = np.array(target_start)\n",
    "    target_end = np.array(target_end)\n",
    "    \n",
    "    del_list = np.where(target_start!=SEQ_LEN)[0]\n",
    "\n",
    "    indices_x = indices_x[del_list]\n",
    "    segments = segments[del_list]\n",
    "    target_start = target_start[del_list]\n",
    "    target_end = target_end[del_list]\n",
    "\n",
    "    train_y_0 = keras.utils.to_categorical(target_start, num_classes=SEQ_LEN, dtype='int64')\n",
    "    train_y_1 = keras.utils.to_categorical(target_end, num_classes=SEQ_LEN, dtype='int64')\n",
    "    train_y_cat = [train_y_0, train_y_1]\n",
    "    \n",
    "    return [indices_x, segments], train_y_cat\n",
    "\n",
    "def load_data(pandas_dataframe):\n",
    "    data_df = pandas_dataframe\n",
    "    \n",
    "    \n",
    "    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n",
    "    data_df[QUESTION_COLUMN] = data_df[QUESTION_COLUMN].astype(str)\n",
    "\n",
    "\n",
    "    data_x, data_y = convert_data(data_df)\n",
    "\n",
    "    return data_x, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "rNUYX-Rntsk_",
    "outputId": "2c61d8d5-b68c-44b6-db92-fcc9d3226e22"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 60407/60407 [01:26<00:00, 702.15it/s]\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = load_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "id": "BnNgt5hTtVOY",
    "outputId": "5ca2e21e-34cb-41c5-8e7a-acf623ebe4aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   101,   9318,  78136, ...,  12178,   9011,    102],\n",
       "       [   101,   9318,  78136, ...,   9011, 118783,    102],\n",
       "       [   101,   9318,  78136, ...,   9011, 118783,    102],\n",
       "       ...,\n",
       "       [   101,   9319, 119351, ...,      0,      0,      0],\n",
       "       [   101,    182,  10162, ...,      0,      0,      0],\n",
       "       [   101,  19145,  17289, ...,      0,      0,      0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "ThGgTFRJt5di",
    "outputId": "7414a825-341d-4388-ca1f-e12b5d06b164"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60407, 6)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "EK-AD6ePuFKD",
    "outputId": "deab67fe-69fc-4656-c180-2d8733b4e403"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50609, 384)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0].shape ## 데이터 10000개 소실(데이터 10000개를 추가해주려면 별도 작업 필요)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vnh0ZuikSzz6"
   },
   "source": [
    "#### 이해가 안 가실 수 있는데, 버트 인풋을 문장으로 예를 들어 만들어 보겠습니다.\n",
    "#### 인풋은 총 2개가 들어갑니다\n",
    "- **(토큰)** 첫번째 인풋은 토큰화 된 것이 인덱싱되어 숫자로 변환된 것  \n",
    "\n",
    "- **(세그멘트)** 두번째 인풋은 앞문장인지 뒷문장인지 알려주는 숫자들입니다. 이번 튜토리얼에서는 파인튜닝 과정이라 앞문장 뒷문장 구분을 안하기 때문에 모두 0으로 하였습니다.  \n",
    "\n",
    "- **(포지션)** 단어 순서에 따라서 자동으로 부여됩니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZ23W0s8MCBt"
   },
   "source": [
    "이해가 되셨는지요?  \n",
    "구글 깃허브에서 다운받았던 사전학습된 모델을 colab으로 로드합니다.  \n",
    "Training을 False로 두어서 Bert 모델에서, 마지막 트랜스포머 계층까지만 모델이 로드되게 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8auSqxdHtslD",
    "outputId": "703519f8-ab7c-4a47-b1b2-65215b464012",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        (None, 384)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      (None, 384)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (TokenEmbedding [(None, 384, 768), ( 91812096    Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, 384, 768)     1536        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, 384, 768)     0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, 384, 768)     294912      Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, 384, 768)     0           Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, 384, 768)     1536        Embedding-Dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 384, 768)     2362368     Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-1-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 384, 768)     0           Embedding-Norm[0][0]             \n",
      "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-1-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-2-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-2-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-2-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-2-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-3-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-3-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-3-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-3-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-4-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-4-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-4-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-4-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-5-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-5-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-5-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-5-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-6-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-6-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-6-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-6-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-7-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-7-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-7-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-7-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-8-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-8-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-8-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-8-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-9-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-9-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-9-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 384, 768)     2362368     Encoder-9-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 384, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 384, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 384, 768)     1536        Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward (FeedFor (None, 384, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Dropout  (None, 384, 768)     0           Encoder-10-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Add (Add (None, 384, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
      "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Norm (La (None, 384, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 384, 768)     2362368     Encoder-10-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 384, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 384, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 384, 768)     1536        Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward (FeedFor (None, 384, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Dropout  (None, 384, 768)     0           Encoder-11-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Add (Add (None, 384, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
      "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Norm (La (None, 384, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 384, 768)     2362368     Encoder-11-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 384, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 384, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 384, 768)     1536        Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward (FeedFor (None, 384, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Dropout  (None, 384, 768)     0           Encoder-12-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Add (Add (None, 384, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
      "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Norm (La (None, 384, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n",
      "==================================================================================================\n",
      "Total params: 177,164,544\n",
      "Trainable params: 177,164,544\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layer_num = 12\n",
    "model = load_trained_model_from_checkpoint(\n",
    "    config_path,\n",
    "    checkpoint_path,\n",
    "    training=False,\n",
    "    trainable=True,\n",
    "    seq_len=SEQ_LEN,)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ptok2n0MHoV"
   },
   "source": [
    "모델의 구조를 확인합니다.  \n",
    "총 12층의 트랜스포머 계층이 있음을 확인할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1N8hZvNMMWL"
   },
   "source": [
    "Transfer learning을 위해 Custom Layer를 작성해 줍니다.  \n",
    "NonMasking 함수를 지정해서, Bert 모형의 자체 Masking 된 텐서들을 풀어줘야 합니다.  \n",
    "이번 튜토리얼에서 만약 NonMasking 클래스를 만들지 않는다면, Bert 모형을 훈련할 수 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "H99O5l4X8xyb"
   },
   "outputs": [],
   "source": [
    "class NonMasking(Layer):   \n",
    "    def __init__(self, **kwargs):   \n",
    "        self.supports_masking = True  \n",
    "        super(NonMasking, self).__init__(**kwargs)   \n",
    "  \n",
    "    def build(self, input_shape):   \n",
    "        input_shape = input_shape   \n",
    "  \n",
    "    def compute_mask(self, input, input_mask=None):   \n",
    "        return None   \n",
    "  \n",
    "    def call(self, x, mask=None):   \n",
    "        return x   \n",
    "  \n",
    "    def get_output_shape_for(self, input_shape):   \n",
    "        return input_shape  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0BgB9WtubcgQ"
   },
   "source": [
    "Keras Custom Layer 두 개를 생성합니다.  \n",
    "MyLayer_Start는 정답의 첫 번째 단어를 예측하는 것을 담당하고,  \n",
    "MyLaer_End는 정답의 마지막 단어를 예측하는 것을 담당합니다.  \n",
    "  \n",
    "사실 두 레이어는 동일한 역할을 합니다.  \n",
    "Bert 모형의 마지막 입력을 받아서, (batch_size, 384, 768)의 텐서 모양을 (batch_size, 384, 2)로 만들어주는 텐서를 곱해줍니다.  \n",
    "이 다음에 i) (batch_size, 384), ii) (batch_size, 384)의 아웃풋을 출력할 수 있게 하나의 텐서를 두개로 잘라줍니다.  \n",
    "  \n",
    "왜 끝이 384냐면, 384개의 위치를 예측하기 때문입니다. 단어의 위치의 최대 개수는 384개로 앞서 지정하였습니다.(SEQ_LEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "gOBsah1UgIPq"
   },
   "outputs": [],
   "source": [
    "class MyLayer_Start(Layer):\n",
    "\n",
    "    def __init__(self,seq_len, **kwargs):\n",
    "        \n",
    "        self.seq_len = seq_len\n",
    "        self.supports_masking = True\n",
    "        super(MyLayer_Start, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.W = self.add_weight(name='kernel', \n",
    "                                 shape=(input_shape[2],2),\n",
    "                                 initializer='uniform',\n",
    "                                 trainable=True)\n",
    "        super(MyLayer_Start, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        \n",
    "        x = K.reshape(x, shape=(-1,self.seq_len,K.shape(x)[2]))\n",
    "        x = K.dot(x, self.W)\n",
    "        \n",
    "        x = K.permute_dimensions(x, (2,0,1))\n",
    "\n",
    "        self.start_logits, self.end_logits = x[0], x[1]\n",
    "        \n",
    "        self.start_logits = K.softmax(self.start_logits, axis=-1)\n",
    "        \n",
    "        return self.start_logits\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.seq_len)\n",
    "\n",
    "\n",
    "class MyLayer_End(Layer):\n",
    "  def __init__(self,seq_len, **kwargs):\n",
    "        \n",
    "        self.seq_len = seq_len\n",
    "        self.supports_masking = True\n",
    "        super(MyLayer_End, self).__init__(**kwargs)\n",
    "  \n",
    "  def build(self, input_shape):\n",
    "        \n",
    "        self.W = self.add_weight(name='kernel', \n",
    "                                 shape=(input_shape[2], 2),\n",
    "                                 initializer='uniform',\n",
    "                                 trainable=True)\n",
    "        super(MyLayer_End, self).build(input_shape)\n",
    "\n",
    "  \n",
    "  def call(self, x):\n",
    "\n",
    "        \n",
    "        x = K.reshape(x, shape=(-1,self.seq_len,K.shape(x)[2]))\n",
    "        x = K.dot(x, self.W)\n",
    "        x = K.permute_dimensions(x, (2,0,1))\n",
    "        \n",
    "        self.start_logits, self.end_logits = x[0], x[1]\n",
    "        \n",
    "        self.end_logits = K.softmax(self.end_logits, axis=-1)\n",
    "        \n",
    "        return self.end_logits\n",
    "\n",
    "  def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3uYTT6WYgiBG"
   },
   "source": [
    "BERT 모델을 출력하는 함수를 지정합니다.  \n",
    "start_answer, end_answer를 예측하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "NcbOzpEb0wxU"
   },
   "outputs": [],
   "source": [
    "from keras.layers import merge, dot, concatenate\n",
    "from keras import metrics\n",
    "def get_bert_finetuning_model(model):\n",
    "  inputs = model.inputs[:2]\n",
    "  dense = model.output\n",
    "  x = NonMasking()(dense)\n",
    "  outputs_start = MyLayer_Start(SEQ_LEN)(x)\n",
    "  outputs_end = MyLayer_End(SEQ_LEN)(x)\n",
    "  bert_model = keras.models.Model(inputs, [outputs_start, outputs_end])\n",
    "  bert_model.compile(\n",
    "      optimizer=RAdam(learning_rate=LR, decay=0.0001),\n",
    "      loss='categorical_crossentropy',\n",
    "      metrics=['accuracy'])\n",
    "  \n",
    "  return bert_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2LAk6d5dm4A"
   },
   "source": [
    "**모델의 FLOW를 확인해 보도록 하겠습니다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "scWw12ysbPZ9",
    "outputId": "77f673c3-12e6-4d0f-f82c-0abe4f437f6e"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-2edeccf6b592>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mSVG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_bert_finetuning_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m65\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dot'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'svg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tensor_1.15.0\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCluster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dashed'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensor_1.15.0\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpydot\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         raise ImportError(\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[1;34m'Failed to import `pydot`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[1;34m'Please install `pydot`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             'For example with `pip install pydot`.')\n",
      "\u001b[1;31mImportError\u001b[0m: Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`."
     ]
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(get_bert_finetuning_model(model), dpi=65).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gLLayijHNEjz"
   },
   "source": [
    "훈련을 시작합니다.  \n",
    "1epoch을 훈련해 보고, 결과를 확인하고 훈련을 다시 시작할 예정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-7On1hY3I7o1",
    "outputId": "e5409f47-0ce8-491a-c3e6-099a0a9c7e76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        (None, 384)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      (None, 384)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (TokenEmbedding [(None, 384, 768), ( 91812096    Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, 384, 768)     1536        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, 384, 768)     0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, 384, 768)     294912      Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, 384, 768)     0           Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, 384, 768)     1536        Embedding-Dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 384, 768)     2362368     Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-1-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 384, 768)     0           Embedding-Norm[0][0]             \n",
      "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-1-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-2-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-2-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-2-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-2-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-3-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-3-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-3-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-3-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-4-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-4-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-4-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-4-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-5-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-5-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-5-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-5-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-6-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-6-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-6-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-6-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-7-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-7-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-7-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-7-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-8-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-8-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-8-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-8-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-9-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-9-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-9-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 384, 768)     2362368     Encoder-9-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 384, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 384, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 384, 768)     1536        Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward (FeedFor (None, 384, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Dropout  (None, 384, 768)     0           Encoder-10-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Add (Add (None, 384, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
      "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Norm (La (None, 384, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 384, 768)     2362368     Encoder-10-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 384, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 384, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 384, 768)     1536        Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward (FeedFor (None, 384, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Dropout  (None, 384, 768)     0           Encoder-11-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Add (Add (None, 384, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
      "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Norm (La (None, 384, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 384, 768)     2362368     Encoder-11-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 384, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 384, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 384, 768)     1536        Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward (FeedFor (None, 384, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Dropout  (None, 384, 768)     0           Encoder-12-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Add (Add (None, 384, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
      "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Norm (La (None, 384, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "non_masking_1 (NonMasking)      (None, 384, 768)     0           Encoder-12-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "my_layer__start_1 (MyLayer_Star (None, 384)          1536        non_masking_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "my_layer__end_1 (MyLayer_End)   (None, 384)          1536        non_masking_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 177,167,616\n",
      "Trainable params: 177,167,616\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48078 samples, validate on 2531 samples\n",
      "Epoch 1/1\n",
      "48078/48078 [==============================] - 4372s 91ms/step - loss: 1.7078 - my_layer__start_1_loss: 0.8058 - my_layer__end_1_loss: 0.9021 - my_layer__start_1_accuracy: 0.7764 - my_layer__end_1_accuracy: 0.7571 - val_loss: 1.1800 - val_my_layer__start_1_loss: 0.5452 - val_my_layer__end_1_loss: 0.6344 - val_my_layer__start_1_accuracy: 0.8435 - val_my_layer__end_1_accuracy: 0.8202\n"
     ]
    }
   ],
   "source": [
    "sess = K.get_session()\n",
    "uninitialized_variables = set([i.decode('ascii') for i in sess.run(tf.report_uninitialized_variables())])\n",
    "init = tf.variables_initializer([v for v in tf.global_variables() if v.name.split(':')[0] in uninitialized_variables])\n",
    "sess.run(init)\n",
    "\n",
    "bert_model = get_bert_finetuning_model(model)\n",
    "bert_model.summary()\n",
    "history = bert_model.fit(train_x, train_y, batch_size=BATCH_SIZE, validation_split=0.05, shuffle=False, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oORqbeov28xL"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "08t_ActBWabf",
    "outputId": "f79466c6-414a-4b39-cd49-c69d02d422aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        (None, 384)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      (None, 384)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (TokenEmbedding [(None, 384, 768), ( 91812096    Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, 384, 768)     1536        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, 384, 768)     0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, 384, 768)     294912      Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, 384, 768)     0           Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, 384, 768)     1536        Embedding-Dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 384, 768)     2362368     Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-1-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 384, 768)     0           Embedding-Norm[0][0]             \n",
      "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-1-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-2-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-2-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-2-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-2-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-3-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-3-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-3-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-3-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-4-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-4-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-4-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-4-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-5-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-5-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-5-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-5-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-6-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-6-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-6-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-6-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-7-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-7-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-7-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-7-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-8-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-8-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-8-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 384, 768)     2362368     Encoder-8-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-9-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 384, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 384, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward (FeedForw (None, 384, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Dropout ( (None, 384, 768)     0           Encoder-9-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Add (Add) (None, 384, 768)     0           Encoder-9-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Norm (Lay (None, 384, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 384, 768)     2362368     Encoder-9-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 384, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 384, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 384, 768)     1536        Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward (FeedFor (None, 384, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Dropout  (None, 384, 768)     0           Encoder-10-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Add (Add (None, 384, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
      "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Norm (La (None, 384, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 384, 768)     2362368     Encoder-10-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 384, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 384, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 384, 768)     1536        Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward (FeedFor (None, 384, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Dropout  (None, 384, 768)     0           Encoder-11-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Add (Add (None, 384, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
      "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Norm (La (None, 384, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 384, 768)     2362368     Encoder-11-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 384, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 384, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 384, 768)     1536        Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward (FeedFor (None, 384, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Dropout  (None, 384, 768)     0           Encoder-12-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Add (Add (None, 384, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
      "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Norm (La (None, 384, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "non_masking_2 (NonMasking)      (None, 384, 768)     0           Encoder-12-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "my_layer__start_2 (MyLayer_Star (None, 384)          1536        non_masking_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "my_layer__end_2 (MyLayer_End)   (None, 384)          1536        non_masking_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 177,167,616\n",
      "Trainable params: 177,167,616\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_model = get_bert_finetuning_model(model)\n",
    "bert_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xC96iEmbhKZM"
   },
   "source": [
    "BERT MODEL을 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "E3pc5zhjCet-"
   },
   "outputs": [],
   "source": [
    "bert_model.save_weights(\"korquad_wordpiece.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHmMOi6bhPxm"
   },
   "source": [
    "버트 모형을 다시 훈련합니다.  \n",
    "이번에는 validation_split을 입력하지 않아서 전체 데이터가 훈련 되도록 만들어 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "98LafkcmWAc6",
    "outputId": "fa66b7fd-f203-4c92-cc9b-67ee637c0628"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "50609/50609 [==============================] - 4605s 91ms/step - loss: 0.9107 - my_layer__start_1_loss: 0.4158 - my_layer__end_1_loss: 0.4949 - my_layer__start_1_accuracy: 0.8747 - my_layer__end_1_accuracy: 0.8588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1512dfa4630>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.compile(optimizer=RAdam(learning_rate=0.00003, decay=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "bert_model.fit(train_x, train_y, batch_size=BATCH_SIZE, shuffle=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "h0xs7diprDw1"
   },
   "outputs": [],
   "source": [
    "bert_model.save_weights(\"korquad_wordpiece_2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "154p7E_ihh2b"
   },
   "source": [
    "버트 모형을 한번 더 훈련시켜 줍니다. learning_rate을 0.00001로 바꿔 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "qnZ0bdoXCJVr"
   },
   "outputs": [],
   "source": [
    "bert_model.compile(optimizer=RAdam(learning_rate=0.00001, decay=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "WkGimQRChdMZ"
   },
   "outputs": [],
   "source": [
    "bert_model.save_weights(\"korquad_wordpiece_3.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-HySrkKNV_e"
   },
   "source": [
    "재사용을 위해 bert_model을 지드라이브에 저장해줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0ZgfR6MRIul"
   },
   "source": [
    "버트 모형을 로드해줍니다. 이미 로드하였던 모델에 계수들만 살짝 얹혀 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "DwMLCYp0TzTv"
   },
   "outputs": [],
   "source": [
    "bert_model = get_bert_finetuning_model(model)\n",
    "bert_model.load_weights(\"korquad_wordpiece_3.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YeXe8E-0i1si"
   },
   "source": [
    "Test data set에 대한 bert_input을 만들어 줍니다.  \n",
    "Train data set과는 다르게 label을 생성하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "q_WdnjmMYZ-N"
   },
   "outputs": [],
   "source": [
    "def convert_pred_data(question, doc):\n",
    "    global tokenizer\n",
    "    indices, segments = [], []\n",
    "    ids, segment = tokenizer.encode(question, doc, max_len=SEQ_LEN)\n",
    "    indices.append(ids)\n",
    "    segments.append(segment)\n",
    "    indices_x = np.array(indices)\n",
    "    segments = np.array(segments)\n",
    "    return [indices_x, segments]\n",
    "\n",
    "def load_pred_data(question, doc):\n",
    "    data_x = convert_pred_data(question, doc)\n",
    "    return data_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4LmVp-5lOnR"
   },
   "source": [
    "질문과 문장을 받아 답을 알려주는 함수를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Engs2SIlW0SP"
   },
   "outputs": [],
   "source": [
    "def predict_letter(question, doc):\n",
    "  \n",
    "  test_input = load_pred_data(question, doc)\n",
    "  test_start, test_end = bert_model.predict(test_input)\n",
    "  \n",
    "  indexes = tokenizer.encode(question, doc, max_len=SEQ_LEN)[0]\n",
    "  start = np.argmax(test_start, axis=1).item()\n",
    "  end = np.argmax(test_end, axis=1).item()\n",
    "  start_tok = indexes[start]\n",
    "  end_tok = indexes[end]\n",
    "  print(\"Question : \", question)\n",
    "  \n",
    "  print(\"-\"*50)\n",
    "  print(\"Context : \", end = \" \")\n",
    "  \n",
    "  def split_text(text, n):\n",
    "    for line in text.splitlines():\n",
    "        while len(line) > n:\n",
    "           x, line = line[:n], line[n:]\n",
    "           yield x\n",
    "        yield line\n",
    "\n",
    "  \n",
    "\n",
    "  for line in split_text(doc, 150):\n",
    "    print(line)\n",
    "\n",
    "  print(\"-\"*50)\n",
    "  print(\"ANSWER : \", end = \" \")\n",
    "  print(\"\\n\")\n",
    "  sentences = []\n",
    "  \n",
    "  for i in range(start, end+1):\n",
    "    token_based_word = reverse_token_dict[indexes[i]]\n",
    "    sentences.append(token_based_word)\n",
    "    print(token_based_word, end= \" \")\n",
    "  \n",
    "  print(\"\\n\")\n",
    "  print(\"Untokenized Answer : \", end = \"\")\n",
    "  for w in sentences:\n",
    "    if w.startswith(\"##\"):\n",
    "      w = w.replace(\"##\", \"\")\n",
    "    else:\n",
    "      w = \" \" + w\n",
    "    \n",
    "    print(w, end=\"\")\n",
    "  print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBRodQAqlXf7"
   },
   "source": [
    "KorQUAD 데이터 셋에서 test 용도로 쓰이는 dev 파일을 PANDAS DATAFRAME 형식으로 불러오는 함수를 정의합니다.  \n",
    "train 데이터와 모양이 약간 다르기 때문에, 함수를 새로 정의해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "6FpWAQR1ZqGt"
   },
   "outputs": [],
   "source": [
    "def squad_json_to_dataframe_dev(input_file_path, record_path = ['data','paragraphs','qas','answers'],\n",
    "                           verbose = 1):\n",
    "    \"\"\"\n",
    "    input_file_path: path to the squad json file.\n",
    "    record_path: path to deepest level in json file default value is\n",
    "    ['data','paragraphs','qas','answers']\n",
    "    verbose: 0 to suppress it default is 1\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(\"Reading the json file\")    \n",
    "    file = json.loads(open(input_file_path).read())\n",
    "    if verbose:\n",
    "        print(\"processing...\")\n",
    "    # parsing different level's in the json file\n",
    "    js = pd.io.json.json_normalize(file , record_path )\n",
    "    m = pd.io.json.json_normalize(file, record_path[:-1] )\n",
    "    r = pd.io.json.json_normalize(file,record_path[:-2])\n",
    "    \n",
    "    #combining it into single dataframe\n",
    "    idx = np.repeat(r['context'].values, r.qas.str.len())\n",
    "    m['context'] = idx\n",
    "    main = m[['id','question','context','answers']].set_index('id').reset_index()\n",
    "    main['c_id'] = main['context'].factorize()[0]\n",
    "    if verbose:\n",
    "        print(\"shape of the dataframe is {}\".format(main.shape))\n",
    "        print(\"Done\")\n",
    "    return main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "qMVFr75nZq9G",
    "outputId": "be772854-b979-46d3-c009-c87eaef38a80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the json file\n",
      "processing...\n",
      "shape of the dataframe is (5774, 5)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'KorQuAD_v1.0_dev.json'\n",
    "record_path = ['data','paragraphs','qas','answers']\n",
    "verbose = 0\n",
    "dev = squad_json_to_dataframe_dev(input_file_path=input_file_path,record_path=record_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QSzFOnPmv4g"
   },
   "source": [
    "TEST DATA가 잘 불려왔는지 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "id": "tluhycV8ZxqF",
    "outputId": "78db5d56-ed19-47b3-8aa0-2500644ff8c6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answers</th>\n",
       "      <th>c_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6548850-0-0</td>\n",
       "      <td>임종석이 여의도 농민 폭력 시위를 주도한 혐의로 지명수배 된 날은?</td>\n",
       "      <td>1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...</td>\n",
       "      <td>[{'text': '1989년 2월 15일', 'answer_start': 0}]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6548850-0-1</td>\n",
       "      <td>1989년 6월 30일 평양축전에 대표로 파견 된 인물은?</td>\n",
       "      <td>1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...</td>\n",
       "      <td>[{'text': '임수경', 'answer_start': 125}]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6548853-0-0</td>\n",
       "      <td>임종석이 여의도 농민 폭력 시위를 주도한 혐의로 지명수배된 연도는?</td>\n",
       "      <td>1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...</td>\n",
       "      <td>[{'text': '1989년', 'answer_start': 0}]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6548853-0-1</td>\n",
       "      <td>임종석을 검거한 장소는 경희대 내 어디인가?</td>\n",
       "      <td>1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...</td>\n",
       "      <td>[{'text': '학생회관 건물 계단', 'answer_start': 365}]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6548853-0-2</td>\n",
       "      <td>임종석이 조사를 받은 뒤 인계된 곳은 어딘가?</td>\n",
       "      <td>1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...</td>\n",
       "      <td>[{'text': '서울지방경찰청 공안분실', 'answer_start': 457}]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5769</th>\n",
       "      <td>6511152-4-0</td>\n",
       "      <td>중동 지역에서 갤럭시 S7 엣지가 폭발하는 사건이 발생한 년도는?</td>\n",
       "      <td>2016년 9월 4일 중동 지역에서 갤럭시 S7 엣지가 폭발하는 사건이 발생했다. ...</td>\n",
       "      <td>[{'text': '2016년', 'answer_start': 0}]</td>\n",
       "      <td>959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5770</th>\n",
       "      <td>6511152-4-1</td>\n",
       "      <td>갤럭시 S7엣지를 만든 회사는?</td>\n",
       "      <td>2016년 9월 4일 중동 지역에서 갤럭시 S7 엣지가 폭발하는 사건이 발생했다. ...</td>\n",
       "      <td>[{'text': '삼성전자', 'answer_start': 83}]</td>\n",
       "      <td>959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5771</th>\n",
       "      <td>6511152-4-2</td>\n",
       "      <td>2016년 9월 4일 갤럭시 S7엣지가 폭발한 사건이 발생한 지역은?</td>\n",
       "      <td>2016년 9월 4일 중동 지역에서 갤럭시 S7 엣지가 폭발하는 사건이 발생했다. ...</td>\n",
       "      <td>[{'text': '중동 지역', 'answer_start': 12}]</td>\n",
       "      <td>959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5772</th>\n",
       "      <td>6535617-4-0</td>\n",
       "      <td>갤럭시 노트 7은 출시 며칠만에 기기 결함으로 터지기 시작하였나?</td>\n",
       "      <td>2016년 9월 4일 중동 지역에서 갤럭시 S7 엣지가 폭발하는 사건이 발생했다. ...</td>\n",
       "      <td>[{'text': '18일', 'answer_start': 286}]</td>\n",
       "      <td>959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5773</th>\n",
       "      <td>6535617-4-1</td>\n",
       "      <td>2016년에 갤럭시 S7 엣지가 폭발한 사건은 어느 지역에서 일어났는가?</td>\n",
       "      <td>2016년 9월 4일 중동 지역에서 갤럭시 S7 엣지가 폭발하는 사건이 발생했다. ...</td>\n",
       "      <td>[{'text': '중동 지역', 'answer_start': 12}]</td>\n",
       "      <td>959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5774 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                  question  \\\n",
       "0     6548850-0-0     임종석이 여의도 농민 폭력 시위를 주도한 혐의로 지명수배 된 날은?   \n",
       "1     6548850-0-1          1989년 6월 30일 평양축전에 대표로 파견 된 인물은?   \n",
       "2     6548853-0-0     임종석이 여의도 농민 폭력 시위를 주도한 혐의로 지명수배된 연도는?   \n",
       "3     6548853-0-1                  임종석을 검거한 장소는 경희대 내 어디인가?   \n",
       "4     6548853-0-2                 임종석이 조사를 받은 뒤 인계된 곳은 어딘가?   \n",
       "...           ...                                       ...   \n",
       "5769  6511152-4-0      중동 지역에서 갤럭시 S7 엣지가 폭발하는 사건이 발생한 년도는?   \n",
       "5770  6511152-4-1                         갤럭시 S7엣지를 만든 회사는?   \n",
       "5771  6511152-4-2    2016년 9월 4일 갤럭시 S7엣지가 폭발한 사건이 발생한 지역은?   \n",
       "5772  6535617-4-0      갤럭시 노트 7은 출시 며칠만에 기기 결함으로 터지기 시작하였나?   \n",
       "5773  6535617-4-1  2016년에 갤럭시 S7 엣지가 폭발한 사건은 어느 지역에서 일어났는가?   \n",
       "\n",
       "                                                context  \\\n",
       "0     1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...   \n",
       "1     1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...   \n",
       "2     1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...   \n",
       "3     1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...   \n",
       "4     1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률...   \n",
       "...                                                 ...   \n",
       "5769  2016년 9월 4일 중동 지역에서 갤럭시 S7 엣지가 폭발하는 사건이 발생했다. ...   \n",
       "5770  2016년 9월 4일 중동 지역에서 갤럭시 S7 엣지가 폭발하는 사건이 발생했다. ...   \n",
       "5771  2016년 9월 4일 중동 지역에서 갤럭시 S7 엣지가 폭발하는 사건이 발생했다. ...   \n",
       "5772  2016년 9월 4일 중동 지역에서 갤럭시 S7 엣지가 폭발하는 사건이 발생했다. ...   \n",
       "5773  2016년 9월 4일 중동 지역에서 갤럭시 S7 엣지가 폭발하는 사건이 발생했다. ...   \n",
       "\n",
       "                                              answers  c_id  \n",
       "0       [{'text': '1989년 2월 15일', 'answer_start': 0}]     0  \n",
       "1              [{'text': '임수경', 'answer_start': 125}]     0  \n",
       "2              [{'text': '1989년', 'answer_start': 0}]     0  \n",
       "3       [{'text': '학생회관 건물 계단', 'answer_start': 365}]     0  \n",
       "4     [{'text': '서울지방경찰청 공안분실', 'answer_start': 457}]     0  \n",
       "...                                               ...   ...  \n",
       "5769           [{'text': '2016년', 'answer_start': 0}]   959  \n",
       "5770           [{'text': '삼성전자', 'answer_start': 83}]   959  \n",
       "5771          [{'text': '중동 지역', 'answer_start': 12}]   959  \n",
       "5772           [{'text': '18일', 'answer_start': 286}]   959  \n",
       "5773          [{'text': '중동 지역', 'answer_start': 12}]   959  \n",
       "\n",
       "[5774 rows x 5 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9614q2jmcq-"
   },
   "source": [
    "테스트 데이터에 대해서 결과를 확인합니다.  \n",
    "훈련에 사용하지 않은 테스트 데이터에 대한 예측을 제법 잘 수행하는 것을 보실 수 있겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IBmiDNInax0z",
    "outputId": "1c6193d9-41e8-4a3f-f9c2-46f523ad20a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question :  반류마루가 미야코 만 해전에서 폭풍우를 만나 대기하고 있던 항구의 이름은 무엇인가?\n",
      "--------------------------------------------------\n",
      "Context :  일련의 하코다테 전쟁은 적아 쌍방의 문서에 마쓰오카 바키치 함장의 능란한 조함 능력과 냉정한 지휘만이 기록되어 있다. 함포 사격으로 마쓰마에 성을 공격하여 엄호한 이후, 1869년 메이지 2년 3월 25일 미야코 만 해전에서는 폭풍우를 만나 요함과 헤어졌을 때에 만날 \n",
      "약속했던 하치노헤 항에서 대기하고 있었기 때문에 참전에는 이르지 못했다. 이 폭풍우 때도 “함장 마쓰오카 바키치는 배를 조정하는 명수로 로프 하나 손상되지 않았다”고 타고 있던 하야시 다다스가 남긴 바 있다. 이 귀로에서 신정부 군의 철갑함의 추격을 받았다. 기관 능력\n",
      "의 차이로 인한 속도차 때문에 도주가 불가능하다고 판단하고 맞장 공격을 하겠다고 전투 준비를 했지만, 철갑선의 사정거리에 들어간 순간에 순풍이 불기 시작하여 추격을 뿌리치고 하코다테로 돌아올 수 있었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "하 ##치 ##노 ##헤 항 \n",
      "\n",
      "Untokenized Answer :  하치노헤 항\n",
      "\n",
      "real answer :  [{'text': '하치노헤', 'answer_start': 155}]\n",
      "\n",
      "Question :  노아의 방주에 대해 기록하고있는 복음서는 무엇인가?\n",
      "--------------------------------------------------\n",
      "Context :  노아는 하나님의 명령에 따라 배를 만들고 가족과 정결한 짐승 암수 일곱 마리씩, 부정한 짐승 암수 한 마리씩(혹은 두 마리씩; 사본에 따라 다름), 그리고 새 암수 일곱 마리씩을 싣고 밀어닥친 홍수를 피하였다. 모든 사람들이 타락한 생활에 빠져 있어 하나님이 홍수로 심\n",
      "판하려 할 때 홀로 바르게 살던 노아는 하나님의 특별한 계시로 홍수가 올 것을 미리 알게 된다. 그는 길이 300 규빗, 너비 50 규빗, 높이 30 규빗(고대의 1규빗은 팔꿈치에서 가운데 손가락끝까지의 길이로 약 45~46cm를 가리킴), 상 ·중 ·하 3층으로 된 \n",
      "방주를 만들어 8명의 가족과, 한 쌍씩의 여러 동물을 데리고 이 방주에 탄다. 대홍수를 만나 모든 생물(물고기 제외)이 전멸하고 말았지만, 이 방주에 탔던 노아의 가족과 동물들은 살아 남았다고 한다.〈창세기〉 6장 14~16절에 보면 길이 300규빗 (약 135m), \n",
      "폭 50 규빗 (약 22.5m), 높이 30 규빗 (약 13.5m)인 이 배는 지붕과 문을 달고 배 안은 3층으로 만들어져 있었다. 선체(船體)는 고페르나무(잣나무)로 되고 안쪽에는 역청(아스팔트와 비슷한 성분)을 칠하여 굳혔다고 기록하고 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "하 ##나 ##님 \n",
      "\n",
      "Untokenized Answer :  하나님\n",
      "\n",
      "real answer :  [{'text': '창세기', 'answer_start': 412}]\n",
      "\n",
      "Question :  현재의 생물다양성은 대략 몇 종 인가?\n",
      "--------------------------------------------------\n",
      "Context :  기독교 성경 내용에는 모든 종들을 방주에 태운다고 이야기하고 있으나, 어류나 수중 생물에 대해서는 언급하지 않았다. 이것을 신학적 의미로만 받아들이면 괜찮은 문제이나, 이 현상이 실제로 일어났다고 가정할 경우,이는 종 간 생존 환경의 차이에 대해서 간과하고 있다. 수중\n",
      " 생물이라 하더라도 종에 따라 생존할 수 있는 환경은 각각 다른 것이며, 40일 이내에 현존하는 가장 높은 산인 에베레스트 산도 잠기게 할 정도의 폭우로 인해 담수와 염수가 급작스럽게 섞일 경우, 급격한 삼투압 변화로 인해 대부분의 수생생물들이 폐사하게 되며, 결과적으\n",
      "로 육지 뿐 아니라 바다와 강의 모든 생태계가 파괴된다. 이후 5천년이라는 지극히 짧은 세월 동안 지구상의 동식물이 모두 페름기 대멸종 또는 K-T 대멸종에 준하는 대량절멸에 가까운 상태에서부터 시작하여 현재의 대략 870만(±120만)종에 달하는 생물다양성을 획득하려\n",
      "면 모든 생물들이 각 세대마다 종분화가 일어나야 할 만큼 엄청난 속도로 진화 및 번식이 (멸종 없이) 이루어져야만 가능한 일이다. (이와 관련하여 창조과학회 측에서는 북극곰의 예시를 통해 가지고 있던 특성이 없어지는 것이 진화가 아니라고 주장하지만, 통상적으로 알려진 \n",
      "바와 같이 생물학에서는 이미 존재하는 특성이 없어지는 현상, 즉 퇴화 역시 진화의 정의에 포함된다.) 즉, 노아의 홍수가 실재하는 사건이었다면 진화적 종분화가 현재까지 알려진 것과 비교할 수 없이 엄청난 속도로 이루어져야만 현재 지구의 생물다양성을 설명할 수 있다. 게\n",
      "다가 이것은 현재의 생물종 멸종 속도를 전혀 고려하지 않았다. 다시 말해, 노아의 홍수가 실재하는 전지구적인 사건이기 위해서는 최소 캄브리아기 대폭발 수준의 폭발적인 진화적 종분화가 1-2억년이 아니라 최대 3-4천년 이내에 이루어졌어야만 현생 지구의 생물다양성에 대한\n",
      " 설명이 가능해진다. 그보다 더 중요한 것은, 각 동물들이 차지하는 영역과 먹이사슬에서의 위치, 375일 동안 먹이도 없이 밀폐된 공간으로 인해 받을 스트레스 등 생태적 지위에 대한 고려가 전혀 없다는 점이다. 또한 바다에서 생존이 불가능한 생물종까지 숫자에 포함되었다\n",
      "는 점에서 논란이 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "870 ##만 \n",
      "\n",
      "Untokenized Answer :  870만\n",
      "\n",
      "real answer :  [{'text': '870만', 'answer_start': 421}]\n",
      "\n",
      "Question :  노아의 방주가 안정적인 구조였다고 주장하는 집단은 어디인가?\n",
      "--------------------------------------------------\n",
      "Context :  창조과학회에서는 또한 노아의 방주가 안정적인 구조였다고 주장하지만, 이와는 달리 노아의 방주는 항해가 불가능한 설계에 가깝다. 실제로 창조과학에서 주장하는 방주의 크기와 철제 부품을 사용하지 않은 목재 선박 중에서 가장 큰 수준의 선박들을 비교하면 배수량이 두배 이상 \n",
      "차이난다. 그리고 목재 선박은 강도 상의 문제 때문에 통상 길이 100m, 배수량 2000톤 정도가 한계로 여겨져 왔다. 창조과학회에서는 노아의 방주의 안정성을 실험하기 위한 연구가 있다고 주장하기도 하나, 그 자체의 불합리성에 대한 비판을 받고 있으며, 관련 주요 연\n",
      "구자는 지질학 석사학위, 생물학 학사학위를 가진 초등학교 교사로서, 주류 학계의 학회나 저널 등에 발표한 적이 없으며 또한 정당한 피어 리뷰에 의해 검증받지 않았다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "창 ##조 ##과 ##학 ##회 \n",
      "\n",
      "Untokenized Answer :  창조과학회\n",
      "\n",
      "real answer :  [{'text': '창조과학회', 'answer_start': 0}]\n",
      "\n",
      "Question :  알렉산더 헤이그는 어느 대통령의 밑에서 국무장관을 지냈는가?\n",
      "--------------------------------------------------\n",
      "Context :  알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr., 1924년 12월 2일 ~ 2010년 2월 20일)는 미국의 국무 장관을 지낸 미국의 군인, 관료 및 정치인이다. 로널드 레이건 대통령 밑에서 국무장관을 지냈으며, 리처드 닉슨과 제럴\n",
      "드 포드 대통령 밑에서 백악관 비서실장을 지냈다. 또한 그는 미국 군대에서 2번째로 높은 직위인 미국 육군 부참모 총장과 나토 및 미국 군대의 유럽연합군 최고사령관이었다. 한국 전쟁 시절 더글러스 맥아더 유엔군 사령관의 참모로 직접 참전하였으며, 로널드 레이건 정부 출\n",
      "범당시 초대 국무장관직을 맡아 1980년대 대한민국과 미국의 관계를 조율해 왔다. 저서로 회고록 《경고:현실주의, 레이건과 외교 정책》(1984년 발간)이 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "로 ##널 ##드 레 ##이 ##건 \n",
      "\n",
      "Untokenized Answer :  로널드 레이건\n",
      "\n",
      "real answer :  [{'text': '로널드 레이건 대통령', 'answer_start': 112}]\n",
      "\n",
      "Question :  레이건 대통령의 조언자들을 헤이그는 무엇이라고 묘사하였나?\n",
      "--------------------------------------------------\n",
      "Context :  그의 편에 헤이그는 지구촌의 논점들의 국내적 정치 노력들에 관해서만 근심한 레이건의 가까운 조언자들을 \"외교 정책의 아마추어\"로 묘사하였다. 1982년 6월 25일 결국적으로 온 그의 국무장관으로서 사임은 불가능한 상황이 된 것을 끝냈다. 헤이그는 개인적 생활로 돌아갔\n",
      "다가 1988년 대통령 선거를 위한 공화당 후보직을 안정시키는 시도를 하는 데 충분하게 정계로 돌아갔으나 후보직을 이기는 데 성원을 가지지 않았다. 그는 외교 정책 논쟁들에 연설자로서 활동적으로 남아있었으나 그의 전념은 정치에서 개인적 생활로 옮겨졌다. 그는 World\n",
      "wide Associates Inc.의 국제적 상담 회사에 의하여 기용되었고, 그 기구의 의장과 회장이 되었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "외 ##교 정 ##책 ##의 아 ##마 ##추 ##어 \n",
      "\n",
      "Untokenized Answer :  외교 정책의 아마추어\n",
      "\n",
      "real answer :  [{'text': '외교 정책의 아마추어', 'answer_start': 58}]\n",
      "\n",
      "Question :  에노모토 해군인 반류마루가 주력함이 되었던 전쟁은?\n",
      "--------------------------------------------------\n",
      "Context :  1868년 게이오 4년 4월 11일 에도 성 무혈 개성을 한 이후 신정부 군에게 양도가 약속되어 있었다. 그러나 해군 부총재, 에노모토 다케아키가 기상 불량 등을 이유로 이를 연기한 후에 결국 인도를 거부했다. 도쿠가와 요시노부를 슨푸 번에 이송할 때의 태운 함선으로 \n",
      "사용한 후, 8월 19일 자정 (20일)에는 마쓰오카 바키치를 함장으로 카이요마루, 가이텐마루, 신소쿠마루, 간린마루 등과 함께 막부 해군이 정박하고 있던 시나가와 해역을 탈출했다. 그 때 태풍에 휘말려 침몰직전이 되었지만, 1개월만에 에노모토 해군과 합류하였다. 에조\n",
      "치에 건너가 하코다테 전쟁에서는 에노모토(하코다테 정부) 해군의 주력함이 되었다. 영국이 기증했을 때 엠퍼러(Emperor, 기증 당시 일본의 수장은 황제가 아니라 쇼군으로 인식되고 있었기 때문에 장군을 지칭)로 명명하고 있음에서 알 수 있듯이, 쇼군용 유람 요트로 기\n",
      "증되었다고 생각되지만, 세상이 그것을 허락하지 않았다. 아이러니하게도, 군함에 통합되어 실제로 쇼군이 첫 좌승한 것이 대정봉환 이후 슨푸 번에 이송되었을 때였다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "하 ##코 ##다 ##테 전쟁 \n",
      "\n",
      "Untokenized Answer :  하코다테 전쟁\n",
      "\n",
      "real answer :  [{'text': '하코다테 전쟁', 'answer_start': 307}]\n",
      "\n",
      "Question :  임종석이 여의도 농민 폭력 시위를 주도한 혐의로 지명수배 된 날은?\n",
      "--------------------------------------------------\n",
      "Context :  1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률위반)으로 지명수배되었다. 1989년 3월 12일 서울지방검찰청 공안부는 임종석의 사전구속영장을 발부받았다. 같은 해 6월 30일 평양축전에 임수경을 대표로 파견하여 국가보안법위반 혐의가\n",
      " 추가되었다. 경찰은 12월 18일~20일 사이 서울 경희대학교에서 임종석이 성명 발표를 추진하고 있다는 첩보를 입수했고, 12월 18일 오전 7시 40분 경 가스총과 전자봉으로 무장한 특공조 및 대공과 직원 12명 등 22명의 사복 경찰을 승용차 8대에 나누어 경희대\n",
      "학교에 투입했다. 1989년 12월 18일 오전 8시 15분 경 서울청량리경찰서는 호위 학생 5명과 함께 경희대학교 학생회관 건물 계단을 내려오는 임종석을 발견, 검거해 구속을 집행했다. 임종석은 청량리경찰서에서 약 1시간 동안 조사를 받은 뒤 오전 9시 50분 경 서\n",
      "울 장안동의 서울지방경찰청 공안분실로 인계되었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "1989년 2월 15일 \n",
      "\n",
      "Untokenized Answer :  1989년 2월 15일\n",
      "\n",
      "real answer :  [{'text': '1989년 2월 15일', 'answer_start': 0}]\n",
      "\n",
      "Question :  헤이그가 사적생활을 하다가 정계로 돌아갔던 해는 언제인가?\n",
      "--------------------------------------------------\n",
      "Context :  그의 편에 헤이그는 지구촌의 논점들의 국내적 정치 노력들에 관해서만 근심한 레이건의 가까운 조언자들을 \"외교 정책의 아마추어\"로 묘사하였다. 1982년 6월 25일 결국적으로 온 그의 국무장관으로서 사임은 불가능한 상황이 된 것을 끝냈다. 헤이그는 개인적 생활로 돌아갔\n",
      "다가 1988년 대통령 선거를 위한 공화당 후보직을 안정시키는 시도를 하는 데 충분하게 정계로 돌아갔으나 후보직을 이기는 데 성원을 가지지 않았다. 그는 외교 정책 논쟁들에 연설자로서 활동적으로 남아있었으나 그의 전념은 정치에서 개인적 생활로 옮겨졌다. 그는 World\n",
      "wide Associates Inc.의 국제적 상담 회사에 의하여 기용되었고, 그 기구의 의장과 회장이 되었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "1988년 \n",
      "\n",
      "Untokenized Answer :  1988년\n",
      "\n",
      "real answer :  [{'text': '1988년', 'answer_start': 153}]\n",
      "\n",
      "Question :  알렉산더 헤이그가 나온 대학교는?\n",
      "--------------------------------------------------\n",
      "Context :  노터데임 대학교에서 2년간 합리적으로 심각한 공부를 한 후 헤이그는 1944년 미국 육군사관학교로 임명을 획득하여 자신의 어린 시절을 군사 경력의 야망으로 알아챘다. 그 경력은 헤이그의 학문적 경연이 암시하려고 한것보다 더욱 극적이었으며 그는 1947년 310의 동기병\n",
      "에서 217번째 사관으로서 졸업하였다. 22세의 소위로 헤이그는 처음에 캔자스 주 포트라일리에서 정통 제병 연합부대로, 그러고나서 켄터키 주 포트녹스에 있는 기갑 훈련소로 갔다. 그후에 그는 제1 기병 사단으로 선임되고 그러고나서 일본에서 점령군의 임무와 기력이 없는 \n",
      "훈련을 하였다. 그는 1950년 5월 한번 자신의 사령관 알론조 폭스 장군의 딸 퍼트리샤 앤토이넷 폭스와 결혼하여 슬하 3명의 자식을 두었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "노 ##터 ##데 ##임 대학교 \n",
      "\n",
      "Untokenized Answer :  노터데임 대학교\n",
      "\n",
      "real answer :  [{'text': '노터데임 대학교', 'answer_start': 0}]\n",
      "\n",
      "Question :  법무부 장관을 제쳐놓고 민정수석이 개정안을 설명하는 게 이해가 안 된다고 지적한 경희대 석좌교수 이름은?\n",
      "--------------------------------------------------\n",
      "Context :  \"내각과 장관들이 소외되고 대통령비서실의 권한이 너무 크다\", \"행보가 비서 본연의 역할을 벗어난다\"는 의견이 제기되었다. 대표적인 예가 10차 개헌안 발표이다. 원로 헌법학자인 허영 경희대 석좌교수는 정부의 헌법개정안 준비 과정에 대해 \"청와대 비서실이 아닌 국무회의\n",
      " 중심으로 이뤄졌어야 했다\"고 지적했다. '국무회의의 심의를 거쳐야 한다'(제89조)는 헌법 규정에 충실하지 않았다는 것이다. 그러면서 \"법무부 장관을 제쳐놓고 민정수석이 개정안을 설명하는 게 이해가 안 된다\"고 지적했다. 민정수석은 국회의원에 대해 책임지는 법무부 장\n",
      "관도 아니고, 국민에 대해 책임지는 사람도 아니기 때문에 정당성이 없고, 단지 대통령의 신임이 있을 뿐이라는 것이다. 또한 국무총리 선출 방식에 대한 기자의 질문에 \"문 대통령도 취임 전에 국무총리에게 실질적 권한을 주겠다고 했지만 그러지 못하고 있다. 대통령비서실장만\n",
      "도 못한 권한을 행사하고 있다.\"고 답변했다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "허 ##영 \n",
      "\n",
      "Untokenized Answer :  허영\n",
      "\n",
      "real answer :  [{'text': '허영', 'answer_start': 100}]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question :  역사학과 과학의 발달로 홍수지질학은 어떤 과학으로 남게 되었는가?\n",
      "--------------------------------------------------\n",
      "Context :  역사학과 과학의 발달이 더뎠던 고대사회에서는, 성경이 단순한 교리적인 부분 뿐 아니라 역사책으로서의 권위도 높았기에 노아의 방주를 역사적인 존재로서 다루고 있었다. 이는 제칠일안식교에서 비롯된 의사과학의 한 종류인 유사지질학인 홍수지질학과 같은 것에 영향을 주었으며, \n",
      "과거 신학에서는 이러한 근본주의적 해석을 받아들여 역사와 사회적인 모든 부분에 있어 성경을 교과서로 채택할 것을 촉구했다. 이러한 홍수지질학을 주장했던 유사지질학자들은 성경에 나오는 노아의 홍수가 어딘가에 그 흔적이 남아 있을것이라고 주장하며 노아의 방주를 찾기 위한 \n",
      "노력을 했다고 주장한다. 이들은 같은 메소포타미아 지방의 신화인 이슬람교 경전이나 길가메쉬 서사시등의 신화를 들어서 이를 근거라고 주장하기도 했다. 그러나 이러한 전통적 근본주의적 시각은 과거에는 상당히 힘을 얻었으나, 역사학과 과학의 발달에 따라 힘을 잃게 되었고, \n",
      "홍수지질학은 유사과학으로서 남게 되었다. 현대에는 뒤의 실존논란에서 다루는 것처럼 이러한 근본주의적 해석은 비과학적인 해석으로 여기는 것이 일반적이지만, 남침례교로 대표되는 극보수주의계열 기독교에서는 아직도 이것이 받아들여지고 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "유 ##사 ##과 ##학 \n",
      "\n",
      "Untokenized Answer :  유사과학\n",
      "\n",
      "real answer :  [{'text': '유사과학', 'answer_start': 457}]\n",
      "\n",
      "Question :  현대에 노아의 방주에 대학 근본주의적 해석은 어떻게 여겨지는가?\n",
      "--------------------------------------------------\n",
      "Context :  역사학과 과학의 발달이 더뎠던 고대사회에서는, 성경이 단순한 교리적인 부분 뿐 아니라 역사책으로서의 권위도 높았기에 노아의 방주를 역사적인 존재로서 다루고 있었다. 이는 제칠일안식교에서 비롯된 의사과학의 한 종류인 유사지질학인 홍수지질학과 같은 것에 영향을 주었으며, \n",
      "과거 신학에서는 이러한 근본주의적 해석을 받아들여 역사와 사회적인 모든 부분에 있어 성경을 교과서로 채택할 것을 촉구했다. 이러한 홍수지질학을 주장했던 유사지질학자들은 성경에 나오는 노아의 홍수가 어딘가에 그 흔적이 남아 있을것이라고 주장하며 노아의 방주를 찾기 위한 \n",
      "노력을 했다고 주장한다. 이들은 같은 메소포타미아 지방의 신화인 이슬람교 경전이나 길가메쉬 서사시등의 신화를 들어서 이를 근거라고 주장하기도 했다. 그러나 이러한 전통적 근본주의적 시각은 과거에는 상당히 힘을 얻었으나, 역사학과 과학의 발달에 따라 힘을 잃게 되었고, \n",
      "홍수지질학은 유사과학으로서 남게 되었다. 현대에는 뒤의 실존논란에서 다루는 것처럼 이러한 근본주의적 해석은 비과학적인 해석으로 여기는 것이 일반적이지만, 남침례교로 대표되는 극보수주의계열 기독교에서는 아직도 이것이 받아들여지고 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "비 ##과 ##학적 ##인 해 ##석 \n",
      "\n",
      "Untokenized Answer :  비과학적인 해석\n",
      "\n",
      "real answer :  [{'text': '비과학적인 해석', 'answer_start': 510}]\n",
      "\n",
      "Question :  노아의 방주의 실존에 대한 의문을 제기한 학문은?\n",
      "--------------------------------------------------\n",
      "Context :  역사학과 과학이 발달하지 않았던 과거 전통 신학계에서는 근본주의적 시각을 받아들여 노아의 방주를 역사적 사실로 기술하려 했으며, 이러한 관점은 아직도 과학과 역사학에 어두운 보수적 근본주의계열의 개신교에서만 받아들여지고 있다. 하지만 역사학과 과학의 발달로 인해, 노아\n",
      "의 방주의 실존에 대한 의문이 제기가 되고, 세계적 홍수가 존재할 수 없음이 밝혀짐에 따라 현대 신학계에서는 비록 노아의 홍수가 과학적으로 실존하지는 않았지만 그 자체의 의미는 신학적으로 매우 중요하며, 이에 대한 해석은 다양하게 이루어지고 있으며, 대부분의 기독교(가\n",
      "톨릭, 개신교를 포함한 대부분)에서는 노아의 방주는 상징적 의미로 받아들여진다. 그러므로 과학과는 상관없이 신학적으로 노아의 방주 자체의 의미는 중요하게 해석된다고 한다\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "역 ##사 ##학과 과 ##학 \n",
      "\n",
      "Untokenized Answer :  역사학과 과학\n",
      "\n",
      "real answer :  [{'text': '역사학과 과학', 'answer_start': 131}]\n",
      "\n",
      "Question :  2012년 중국에서 노아의 방주가 발견되었다는 보도를 한 방송사는 어디인가?\n",
      "--------------------------------------------------\n",
      "Context :  일반적으로 터키의 아라랏 산의 경우, 실제 성경 속에 등장하는 아라랏 산은 지금 아라랏이라 불리는 하나의 산이 아니라 당시 아라랏이라고 불리던 광대한 지역의 산들을 모두 가리키는 표현이라는 주장도 나와 있으며, 또한 목재로 만들어진 방주가 현재까지 남아있을 수는 없다는\n",
      " 비판도 받고 있다. 예를 들어, 1955년 프랑스의 탐험가인 Fernand Navarra가 발견한 목재 파편의 경우, 스페인의 임업 연구소에서 목재의 특성을 토대로 5000년 전의 것이라고 밝히긴 했으나 그 신빙성에 문제점이 있었고 후에 방사성 동위원소 측정법 등의 \n",
      "첨단 과학의 도움을 받은 5개 연구소에서 모두 기원 이후의 시기로 연대를 측정했다. 2009년 뿐 아니라 거의 수년에 한번씩 어디선가 노아의 방주를 발견했다는 주장들이 제시되었지만, 심지어 같은 창조과학을 주장하는 사람들에게조차 비판받을 정도였다. 노아의 방주가 다른 \n",
      "여러 지방에서 발견되었다는 주장이 있으나 너무나 다양한 지방(중국, 터키, 인도 등)에 걸쳐있고, 그 주장도 각각 제각각이므로 신빙성이 없다. 예를 들자면, 중국 BTV에서는 2012년에 중국에서 노아의 방주가 발견되었다는 보도를 하였는데, 이것은 창조과학회에서 주장하\n",
      "는 장소와는 전혀 다른곳이기도 하며, 화석화가 진행되지 않은 나무의 존재등으로 가짜임이 밝혀졌다. 때때로 일부 \"학자\"라 칭하는 사람들이 이를 찾기 위해 노력한다고 주장하지만, 이는 학계에서 유사지질학으로 평가되고 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "중국 b ##t ##v \n",
      "\n",
      "Untokenized Answer :  중국 btv\n",
      "\n",
      "real answer :  [{'text': 'BTV', 'answer_start': 541}]\n",
      "\n",
      "Question :  중국에서 2012년 발견되었다고 주장한 노아의 방주는 화석화가 진행되지 않은 무엇때문에 가짜임이 밝혀졌는가?\n",
      "--------------------------------------------------\n",
      "Context :  일반적으로 터키의 아라랏 산의 경우, 실제 성경 속에 등장하는 아라랏 산은 지금 아라랏이라 불리는 하나의 산이 아니라 당시 아라랏이라고 불리던 광대한 지역의 산들을 모두 가리키는 표현이라는 주장도 나와 있으며, 또한 목재로 만들어진 방주가 현재까지 남아있을 수는 없다는\n",
      " 비판도 받고 있다. 예를 들어, 1955년 프랑스의 탐험가인 Fernand Navarra가 발견한 목재 파편의 경우, 스페인의 임업 연구소에서 목재의 특성을 토대로 5000년 전의 것이라고 밝히긴 했으나 그 신빙성에 문제점이 있었고 후에 방사성 동위원소 측정법 등의 \n",
      "첨단 과학의 도움을 받은 5개 연구소에서 모두 기원 이후의 시기로 연대를 측정했다. 2009년 뿐 아니라 거의 수년에 한번씩 어디선가 노아의 방주를 발견했다는 주장들이 제시되었지만, 심지어 같은 창조과학을 주장하는 사람들에게조차 비판받을 정도였다. 노아의 방주가 다른 \n",
      "여러 지방에서 발견되었다는 주장이 있으나 너무나 다양한 지방(중국, 터키, 인도 등)에 걸쳐있고, 그 주장도 각각 제각각이므로 신빙성이 없다. 예를 들자면, 중국 BTV에서는 2012년에 중국에서 노아의 방주가 발견되었다는 보도를 하였는데, 이것은 창조과학회에서 주장하\n",
      "는 장소와는 전혀 다른곳이기도 하며, 화석화가 진행되지 않은 나무의 존재등으로 가짜임이 밝혀졌다. 때때로 일부 \"학자\"라 칭하는 사람들이 이를 찾기 위해 노력한다고 주장하지만, 이는 학계에서 유사지질학으로 평가되고 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "제 ##각 ##각 \n",
      "\n",
      "Untokenized Answer :  제각각\n",
      "\n",
      "real answer :  [{'text': '나무', 'answer_start': 634}]\n",
      "\n",
      "Question :  알렉산더 헤이그는 레이건의 조언자들을 무엇이라고 묘사하였는가?\n",
      "--------------------------------------------------\n",
      "Context :  그의 편에 헤이그는 지구촌의 논점들의 국내적 정치 노력들에 관해서만 근심한 레이건의 가까운 조언자들을 \"외교 정책의 아마추어\"로 묘사하였다. 1982년 6월 25일 결국적으로 온 그의 국무장관으로서 사임은 불가능한 상황이 된 것을 끝냈다. 헤이그는 개인적 생활로 돌아갔\n",
      "다가 1988년 대통령 선거를 위한 공화당 후보직을 안정시키는 시도를 하는 데 충분하게 정계로 돌아갔으나 후보직을 이기는 데 성원을 가지지 않았다. 그는 외교 정책 논쟁들에 연설자로서 활동적으로 남아있었으나 그의 전념은 정치에서 개인적 생활로 옮겨졌다. 그는 World\n",
      "wide Associates Inc.의 국제적 상담 회사에 의하여 기용되었고, 그 기구의 의장과 회장이 되었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "외 ##교 정 ##책 ##의 아 ##마 ##추 ##어 \n",
      "\n",
      "Untokenized Answer :  외교 정책의 아마추어\n",
      "\n",
      "real answer :  [{'text': '외교 정책의 아마추어', 'answer_start': 58}]\n",
      "\n",
      "Question :  가지고 있는 특성이 없어지는 것은 진화가 아니라는 창조과학회의 주장의 예시는?\n",
      "--------------------------------------------------\n",
      "Context :  기독교 성경 내용에는 모든 종들을 방주에 태운다고 이야기하고 있으나, 어류나 수중 생물에 대해서는 언급하지 않았다. 이것을 신학적 의미로만 받아들이면 괜찮은 문제이나, 이 현상이 실제로 일어났다고 가정할 경우,이는 종 간 생존 환경의 차이에 대해서 간과하고 있다. 수중\n",
      " 생물이라 하더라도 종에 따라 생존할 수 있는 환경은 각각 다른 것이며, 40일 이내에 현존하는 가장 높은 산인 에베레스트 산도 잠기게 할 정도의 폭우로 인해 담수와 염수가 급작스럽게 섞일 경우, 급격한 삼투압 변화로 인해 대부분의 수생생물들이 폐사하게 되며, 결과적으\n",
      "로 육지 뿐 아니라 바다와 강의 모든 생태계가 파괴된다. 이후 5천년이라는 지극히 짧은 세월 동안 지구상의 동식물이 모두 페름기 대멸종 또는 K-T 대멸종에 준하는 대량절멸에 가까운 상태에서부터 시작하여 현재의 대략 870만(±120만)종에 달하는 생물다양성을 획득하려\n",
      "면 모든 생물들이 각 세대마다 종분화가 일어나야 할 만큼 엄청난 속도로 진화 및 번식이 (멸종 없이) 이루어져야만 가능한 일이다. (이와 관련하여 창조과학회 측에서는 북극곰의 예시를 통해 가지고 있던 특성이 없어지는 것이 진화가 아니라고 주장하지만, 통상적으로 알려진 \n",
      "바와 같이 생물학에서는 이미 존재하는 특성이 없어지는 현상, 즉 퇴화 역시 진화의 정의에 포함된다.) 즉, 노아의 홍수가 실재하는 사건이었다면 진화적 종분화가 현재까지 알려진 것과 비교할 수 없이 엄청난 속도로 이루어져야만 현재 지구의 생물다양성을 설명할 수 있다. 게\n",
      "다가 이것은 현재의 생물종 멸종 속도를 전혀 고려하지 않았다. 다시 말해, 노아의 홍수가 실재하는 전지구적인 사건이기 위해서는 최소 캄브리아기 대폭발 수준의 폭발적인 진화적 종분화가 1-2억년이 아니라 최대 3-4천년 이내에 이루어졌어야만 현생 지구의 생물다양성에 대한\n",
      " 설명이 가능해진다. 그보다 더 중요한 것은, 각 동물들이 차지하는 영역과 먹이사슬에서의 위치, 375일 동안 먹이도 없이 밀폐된 공간으로 인해 받을 스트레스 등 생태적 지위에 대한 고려가 전혀 없다는 점이다. 또한 바다에서 생존이 불가능한 생물종까지 숫자에 포함되었다\n",
      "는 점에서 논란이 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "북 ##극 ##곰 \n",
      "\n",
      "Untokenized Answer :  북극곰\n",
      "\n",
      "real answer :  [{'text': '북극곰', 'answer_start': 543}]\n",
      "\n",
      "Question :  1955년 목재의 파편을 발견한 프랑스의 탐험가 이름은?\n",
      "--------------------------------------------------\n",
      "Context :  일반적으로 터키의 아라랏 산의 경우, 실제 성경 속에 등장하는 아라랏 산은 지금 아라랏이라 불리는 하나의 산이 아니라 당시 아라랏이라고 불리던 광대한 지역의 산들을 모두 가리키는 표현이라는 주장도 나와 있으며, 또한 목재로 만들어진 방주가 현재까지 남아있을 수는 없다는\n",
      " 비판도 받고 있다. 예를 들어, 1955년 프랑스의 탐험가인 Fernand Navarra가 발견한 목재 파편의 경우, 스페인의 임업 연구소에서 목재의 특성을 토대로 5000년 전의 것이라고 밝히긴 했으나 그 신빙성에 문제점이 있었고 후에 방사성 동위원소 측정법 등의 \n",
      "첨단 과학의 도움을 받은 5개 연구소에서 모두 기원 이후의 시기로 연대를 측정했다. 2009년 뿐 아니라 거의 수년에 한번씩 어디선가 노아의 방주를 발견했다는 주장들이 제시되었지만, 심지어 같은 창조과학을 주장하는 사람들에게조차 비판받을 정도였다. 노아의 방주가 다른 \n",
      "여러 지방에서 발견되었다는 주장이 있으나 너무나 다양한 지방(중국, 터키, 인도 등)에 걸쳐있고, 그 주장도 각각 제각각이므로 신빙성이 없다. 예를 들자면, 중국 BTV에서는 2012년에 중국에서 노아의 방주가 발견되었다는 보도를 하였는데, 이것은 창조과학회에서 주장하\n",
      "는 장소와는 전혀 다른곳이기도 하며, 화석화가 진행되지 않은 나무의 존재등으로 가짜임이 밝혀졌다. 때때로 일부 \"학자\"라 칭하는 사람들이 이를 찾기 위해 노력한다고 주장하지만, 이는 학계에서 유사지질학으로 평가되고 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "fer ##nan ##d nav ##arra \n",
      "\n",
      "Untokenized Answer :  fernand navarra\n",
      "\n",
      "real answer :  [{'text': 'Fernand Navarra', 'answer_start': 185}]\n",
      "\n",
      "Question :  헤이그가 정계로 다시 돌아간 년도는?\n",
      "--------------------------------------------------\n",
      "Context :  그의 편에 헤이그는 지구촌의 논점들의 국내적 정치 노력들에 관해서만 근심한 레이건의 가까운 조언자들을 \"외교 정책의 아마추어\"로 묘사하였다. 1982년 6월 25일 결국적으로 온 그의 국무장관으로서 사임은 불가능한 상황이 된 것을 끝냈다. 헤이그는 개인적 생활로 돌아갔\n",
      "다가 1988년 대통령 선거를 위한 공화당 후보직을 안정시키는 시도를 하는 데 충분하게 정계로 돌아갔으나 후보직을 이기는 데 성원을 가지지 않았다. 그는 외교 정책 논쟁들에 연설자로서 활동적으로 남아있었으나 그의 전념은 정치에서 개인적 생활로 옮겨졌다. 그는 World\n",
      "wide Associates Inc.의 국제적 상담 회사에 의하여 기용되었고, 그 기구의 의장과 회장이 되었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "1988년 \n",
      "\n",
      "Untokenized Answer :  1988년\n",
      "\n",
      "real answer :  [{'text': '1988년', 'answer_start': 153}]\n",
      "\n",
      "Question :  쇼군이 반류마루에 좌승한 것은?\n",
      "--------------------------------------------------\n",
      "Context :  1868년 게이오 4년 4월 11일 에도 성 무혈 개성을 한 이후 신정부 군에게 양도가 약속되어 있었다. 그러나 해군 부총재, 에노모토 다케아키가 기상 불량 등을 이유로 이를 연기한 후에 결국 인도를 거부했다. 도쿠가와 요시노부를 슨푸 번에 이송할 때의 태운 함선으로 \n",
      "사용한 후, 8월 19일 자정 (20일)에는 마쓰오카 바키치를 함장으로 카이요마루, 가이텐마루, 신소쿠마루, 간린마루 등과 함께 막부 해군이 정박하고 있던 시나가와 해역을 탈출했다. 그 때 태풍에 휘말려 침몰직전이 되었지만, 1개월만에 에노모토 해군과 합류하였다. 에조\n",
      "치에 건너가 하코다테 전쟁에서는 에노모토(하코다테 정부) 해군의 주력함이 되었다. 영국이 기증했을 때 엠퍼러(Emperor, 기증 당시 일본의 수장은 황제가 아니라 쇼군으로 인식되고 있었기 때문에 장군을 지칭)로 명명하고 있음에서 알 수 있듯이, 쇼군용 유람 요트로 기\n",
      "증되었다고 생각되지만, 세상이 그것을 허락하지 않았다. 아이러니하게도, 군함에 통합되어 실제로 쇼군이 첫 좌승한 것이 대정봉환 이후 슨푸 번에 이송되었을 때였다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "하 ##코 ##다 ##테 전쟁 ##에서는 에 ##노 ##모토 ( 하 ##코 ##다 ##테 정 ##부 ) 해 ##군의 주 ##력 ##함 ##이 되었다 . 영국 ##이 기 ##증 ##했 ##을 때 엠 ##퍼 ##러 ( emperor , 기 ##증 당시 일본의 수 ##장은 황 ##제가 아니라 쇼 ##군 ##으로 인 ##식 ##되고 있 ##었 ##기 때문에 장 ##군을 지 ##칭 ) 로 명 ##명 ##하고 있 ##음 ##에서 알 수 있 ##듯 ##이 , 쇼 ##군 ##용 유 ##람 요 ##트 ##로 기 ##증 ##되었다 ##고 생 ##각 ##되지 ##만 , 세 ##상이 그 ##것을 허 ##락 ##하지 않았다 . 아 ##이 ##러 ##니 ##하게 ##도 , 군 ##함 ##에 통 ##합 ##되어 실 ##제로 쇼 ##군이 첫 좌 ##승 ##한 것이 대 ##정 ##봉 ##환 \n",
      "\n",
      "Untokenized Answer :  하코다테 전쟁에서는 에노모토 ( 하코다테 정부 ) 해군의 주력함이 되었다 . 영국이 기증했을 때 엠퍼러 ( emperor , 기증 당시 일본의 수장은 황제가 아니라 쇼군으로 인식되고 있었기 때문에 장군을 지칭 ) 로 명명하고 있음에서 알 수 있듯이 , 쇼군용 유람 요트로 기증되었다고 생각되지만 , 세상이 그것을 허락하지 않았다 . 아이러니하게도 , 군함에 통합되어 실제로 쇼군이 첫 좌승한 것이 대정봉환\n",
      "\n",
      "real answer :  [{'text': '슨푸 번에 이송되었을 때', 'answer_start': 524}]\n",
      "\n",
      "Question :  유사지질학자들이 노아의 홍수를 증명하기 위해 성경 이외에 근거라고 주장한 것들은?\n",
      "--------------------------------------------------\n",
      "Context :  역사학과 과학의 발달이 더뎠던 고대사회에서는, 성경이 단순한 교리적인 부분 뿐 아니라 역사책으로서의 권위도 높았기에 노아의 방주를 역사적인 존재로서 다루고 있었다. 이는 제칠일안식교에서 비롯된 의사과학의 한 종류인 유사지질학인 홍수지질학과 같은 것에 영향을 주었으며, \n",
      "과거 신학에서는 이러한 근본주의적 해석을 받아들여 역사와 사회적인 모든 부분에 있어 성경을 교과서로 채택할 것을 촉구했다. 이러한 홍수지질학을 주장했던 유사지질학자들은 성경에 나오는 노아의 홍수가 어딘가에 그 흔적이 남아 있을것이라고 주장하며 노아의 방주를 찾기 위한 \n",
      "노력을 했다고 주장한다. 이들은 같은 메소포타미아 지방의 신화인 이슬람교 경전이나 길가메쉬 서사시등의 신화를 들어서 이를 근거라고 주장하기도 했다. 그러나 이러한 전통적 근본주의적 시각은 과거에는 상당히 힘을 얻었으나, 역사학과 과학의 발달에 따라 힘을 잃게 되었고, \n",
      "홍수지질학은 유사과학으로서 남게 되었다. 현대에는 뒤의 실존논란에서 다루는 것처럼 이러한 근본주의적 해석은 비과학적인 해석으로 여기는 것이 일반적이지만, 남침례교로 대표되는 극보수주의계열 기독교에서는 아직도 이것이 받아들여지고 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "근 ##본 ##주의 ##적 해 ##석 \n",
      "\n",
      "Untokenized Answer :  근본주의적 해석\n",
      "\n",
      "real answer :  [{'text': '이슬람교 경전이나 길가메쉬 서사시', 'answer_start': 336}]\n",
      "\n",
      "Question :  반류마루가 미야코 만 해전당시 폭풍우를 만나 요함과 헤어졌을 때에 만날 약속하여 하치노헤 항에서 대기한 날짜는 언제인가?\n",
      "--------------------------------------------------\n",
      "Context :  일련의 하코다테 전쟁은 적아 쌍방의 문서에 마쓰오카 바키치 함장의 능란한 조함 능력과 냉정한 지휘만이 기록되어 있다. 함포 사격으로 마쓰마에 성을 공격하여 엄호한 이후, 1869년 메이지 2년 3월 25일 미야코 만 해전에서는 폭풍우를 만나 요함과 헤어졌을 때에 만날 \n",
      "약속했던 하치노헤 항에서 대기하고 있었기 때문에 참전에는 이르지 못했다. 이 폭풍우 때도 “함장 마쓰오카 바키치는 배를 조정하는 명수로 로프 하나 손상되지 않았다”고 타고 있던 하야시 다다스가 남긴 바 있다. 이 귀로에서 신정부 군의 철갑함의 추격을 받았다. 기관 능력\n",
      "의 차이로 인한 속도차 때문에 도주가 불가능하다고 판단하고 맞장 공격을 하겠다고 전투 준비를 했지만, 철갑선의 사정거리에 들어간 순간에 순풍이 불기 시작하여 추격을 뿌리치고 하코다테로 돌아올 수 있었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1869 ##년 메 ##이지 2년 3월 25일 \n",
      "\n",
      "Untokenized Answer :  1869년 메이지 2년 3월 25일\n",
      "\n",
      "real answer :  [{'text': '1869년 메이지 2년 3월 25일', 'answer_start': 95}]\n",
      "\n",
      "Question :  헤이그가 군에서 퇴역한 년도는 몇년도입니까?\n",
      "--------------------------------------------------\n",
      "Context :  헤이그는 닉슨 대통령이 그를 사성 장군과 육군 부참모로 진급시킬 때 집중 광선과 논쟁으로 들어갔다. 헤이그를 군사의 최상으로 밀어넣은 닉슨의 행동은 대통령의 남자들을 다양한 연방 대리법에서 권한의 직우들로 놓은 노력과 함께 일치였다. 하지만 그는 곧 백악관으로 돌아가 \n",
      "1973년부터 1974년까지 대통령 특별 보좌관을 지냈다. 워터게이트 사건이 일어난지 한달 후, 헤이그는 포위된 닉슨 대통령을 위한 치명적 역할을 하였다. 그일은 8월 닉슨의 사임과 제럴드 포드의 대통령으로 계승으로 이끈 협상들에서 헤이그가 수단이었던 우연이 아니었다.\n",
      " 곧 후에 헤이그는 미국 유럽 연합군 최고사령부의 최고 사령관으로 임명되었다. 그는 나토에서 다음 5년을 보내고 1979년 군에서 퇴역하여 미국 기술 주식 회사의 우두머리가 되었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "1979 ##년 \n",
      "\n",
      "Untokenized Answer :  1979년\n",
      "\n",
      "real answer :  [{'text': '1979년', 'answer_start': 363}]\n",
      "\n",
      "Question :  헤이그를 기용한 국제적 상담 회사의 이름은 무엇입니까?\n",
      "--------------------------------------------------\n",
      "Context :  그의 편에 헤이그는 지구촌의 논점들의 국내적 정치 노력들에 관해서만 근심한 레이건의 가까운 조언자들을 \"외교 정책의 아마추어\"로 묘사하였다. 1982년 6월 25일 결국적으로 온 그의 국무장관으로서 사임은 불가능한 상황이 된 것을 끝냈다. 헤이그는 개인적 생활로 돌아갔\n",
      "다가 1988년 대통령 선거를 위한 공화당 후보직을 안정시키는 시도를 하는 데 충분하게 정계로 돌아갔으나 후보직을 이기는 데 성원을 가지지 않았다. 그는 외교 정책 논쟁들에 연설자로서 활동적으로 남아있었으나 그의 전념은 정치에서 개인적 생활로 옮겨졌다. 그는 World\n",
      "wide Associates Inc.의 국제적 상담 회사에 의하여 기용되었고, 그 기구의 의장과 회장이 되었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "worldwide associate ##s in ##c . \n",
      "\n",
      "Untokenized Answer :  worldwide associates inc .\n",
      "\n",
      "real answer :  [{'text': 'Worldwide Associates Inc', 'answer_start': 295}]\n",
      "\n",
      "Question :  알렉산더 헤이그와 1950년 5월 결혼한 상대의 이름은 무엇인가?\n",
      "--------------------------------------------------\n",
      "Context :  노터데임 대학교에서 2년간 합리적으로 심각한 공부를 한 후 헤이그는 1944년 미국 육군사관학교로 임명을 획득하여 자신의 어린 시절을 군사 경력의 야망으로 알아챘다. 그 경력은 헤이그의 학문적 경연이 암시하려고 한것보다 더욱 극적이었으며 그는 1947년 310의 동기병\n",
      "에서 217번째 사관으로서 졸업하였다. 22세의 소위로 헤이그는 처음에 캔자스 주 포트라일리에서 정통 제병 연합부대로, 그러고나서 켄터키 주 포트녹스에 있는 기갑 훈련소로 갔다. 그후에 그는 제1 기병 사단으로 선임되고 그러고나서 일본에서 점령군의 임무와 기력이 없는 \n",
      "훈련을 하였다. 그는 1950년 5월 한번 자신의 사령관 알론조 폭스 장군의 딸 퍼트리샤 앤토이넷 폭스와 결혼하여 슬하 3명의 자식을 두었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "퍼 ##트 ##리 ##샤 앤 ##토 ##이 ##넷 폭 ##스 \n",
      "\n",
      "Untokenized Answer :  퍼트리샤 앤토이넷 폭스\n",
      "\n",
      "real answer :  [{'text': '퍼트리샤 앤토이넷 폭스', 'answer_start': 345}]\n",
      "\n",
      "Question :  알렉산더 헤이그가 1984년 발간한 회고록의 제목은 무엇인가?\n",
      "--------------------------------------------------\n",
      "Context :  알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr., 1924년 12월 2일 ~ 2010년 2월 20일)는 미국의 국무 장관을 지낸 미국의 군인, 관료 및 정치인이다. 로널드 레이건 대통령 밑에서 국무장관을 지냈으며, 리처드 닉슨과 제럴\n",
      "드 포드 대통령 밑에서 백악관 비서실장을 지냈다. 또한 그는 미국 군대에서 2번째로 높은 직위인 미국 육군 부참모 총장과 나토 및 미국 군대의 유럽연합군 최고사령관이었다. 한국 전쟁 시절 더글러스 맥아더 유엔군 사령관의 참모로 직접 참전하였으며, 로널드 레이건 정부 출\n",
      "범당시 초대 국무장관직을 맡아 1980년대 대한민국과 미국의 관계를 조율해 왔다. 저서로 회고록 《경고:현실주의, 레이건과 외교 정책》(1984년 발간)이 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "경 ##고 : 현 ##실 ##주의 , 레 ##이 ##건 ##과 외 ##교 정 ##책 \n",
      "\n",
      "Untokenized Answer :  경고 : 현실주의 , 레이건과 외교 정책\n",
      "\n",
      "real answer :  [{'text': '경고:현실주의, 레이건과 외교 정책', 'answer_start': 355}]\n",
      "\n",
      "Question :  제칠일안식교에서 비롯된 의사과학의 한 종류인 유사지질학의 이름은 무엇인가?\n",
      "--------------------------------------------------\n",
      "Context :  역사학과 과학의 발달이 더뎠던 고대사회에서는, 성경이 단순한 교리적인 부분 뿐 아니라 역사책으로서의 권위도 높았기에 노아의 방주를 역사적인 존재로서 다루고 있었다. 이는 제칠일안식교에서 비롯된 의사과학의 한 종류인 유사지질학인 홍수지질학과 같은 것에 영향을 주었으며, \n",
      "과거 신학에서는 이러한 근본주의적 해석을 받아들여 역사와 사회적인 모든 부분에 있어 성경을 교과서로 채택할 것을 촉구했다. 이러한 홍수지질학을 주장했던 유사지질학자들은 성경에 나오는 노아의 홍수가 어딘가에 그 흔적이 남아 있을것이라고 주장하며 노아의 방주를 찾기 위한 \n",
      "노력을 했다고 주장한다. 이들은 같은 메소포타미아 지방의 신화인 이슬람교 경전이나 길가메쉬 서사시등의 신화를 들어서 이를 근거라고 주장하기도 했다. 그러나 이러한 전통적 근본주의적 시각은 과거에는 상당히 힘을 얻었으나, 역사학과 과학의 발달에 따라 힘을 잃게 되었고, \n",
      "홍수지질학은 유사과학으로서 남게 되었다. 현대에는 뒤의 실존논란에서 다루는 것처럼 이러한 근본주의적 해석은 비과학적인 해석으로 여기는 것이 일반적이지만, 남침례교로 대표되는 극보수주의계열 기독교에서는 아직도 이것이 받아들여지고 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "홍 ##수 ##지 ##질 ##학과 \n",
      "\n",
      "Untokenized Answer :  홍수지질학과\n",
      "\n",
      "real answer :  [{'text': '홍수지질학', 'answer_start': 127}]\n",
      "\n",
      "Question :  1868년 게이오 4년 4월 11일 반류마루는 누구에게 양도되기로 약속되었는가?\n",
      "--------------------------------------------------\n",
      "Context :  1868년 게이오 4년 4월 11일 에도 성 무혈 개성을 한 이후 신정부 군에게 양도가 약속되어 있었다. 그러나 해군 부총재, 에노모토 다케아키가 기상 불량 등을 이유로 이를 연기한 후에 결국 인도를 거부했다. 도쿠가와 요시노부를 슨푸 번에 이송할 때의 태운 함선으로 \n",
      "사용한 후, 8월 19일 자정 (20일)에는 마쓰오카 바키치를 함장으로 카이요마루, 가이텐마루, 신소쿠마루, 간린마루 등과 함께 막부 해군이 정박하고 있던 시나가와 해역을 탈출했다. 그 때 태풍에 휘말려 침몰직전이 되었지만, 1개월만에 에노모토 해군과 합류하였다. 에조\n",
      "치에 건너가 하코다테 전쟁에서는 에노모토(하코다테 정부) 해군의 주력함이 되었다. 영국이 기증했을 때 엠퍼러(Emperor, 기증 당시 일본의 수장은 황제가 아니라 쇼군으로 인식되고 있었기 때문에 장군을 지칭)로 명명하고 있음에서 알 수 있듯이, 쇼군용 유람 요트로 기\n",
      "증되었다고 생각되지만, 세상이 그것을 허락하지 않았다. 아이러니하게도, 군함에 통합되어 실제로 쇼군이 첫 좌승한 것이 대정봉환 이후 슨푸 번에 이송되었을 때였다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "신 ##정 ##부 군 \n",
      "\n",
      "Untokenized Answer :  신정부 군\n",
      "\n",
      "real answer :  [{'text': '신정부 군', 'answer_start': 37}]\n",
      "\n",
      "Question :  1규빗을 미터법으로 환산하면 얼마인가?\n",
      "--------------------------------------------------\n",
      "Context :  노아는 하나님의 명령에 따라 배를 만들고 가족과 정결한 짐승 암수 일곱 마리씩, 부정한 짐승 암수 한 마리씩(혹은 두 마리씩; 사본에 따라 다름), 그리고 새 암수 일곱 마리씩을 싣고 밀어닥친 홍수를 피하였다. 모든 사람들이 타락한 생활에 빠져 있어 하나님이 홍수로 심\n",
      "판하려 할 때 홀로 바르게 살던 노아는 하나님의 특별한 계시로 홍수가 올 것을 미리 알게 된다. 그는 길이 300 규빗, 너비 50 규빗, 높이 30 규빗(고대의 1규빗은 팔꿈치에서 가운데 손가락끝까지의 길이로 약 45~46cm를 가리킴), 상 ·중 ·하 3층으로 된 \n",
      "방주를 만들어 8명의 가족과, 한 쌍씩의 여러 동물을 데리고 이 방주에 탄다. 대홍수를 만나 모든 생물(물고기 제외)이 전멸하고 말았지만, 이 방주에 탔던 노아의 가족과 동물들은 살아 남았다고 한다.〈창세기〉 6장 14~16절에 보면 길이 300규빗 (약 135m), \n",
      "폭 50 규빗 (약 22.5m), 높이 30 규빗 (약 13.5m)인 이 배는 지붕과 문을 달고 배 안은 3층으로 만들어져 있었다. 선체(船體)는 고페르나무(잣나무)로 되고 안쪽에는 역청(아스팔트와 비슷한 성분)을 칠하여 굳혔다고 기록하고 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "300 규 ##빗 \n",
      "\n",
      "Untokenized Answer :  300 규빗\n",
      "\n",
      "real answer :  [{'text': '45~46cm', 'answer_start': 270}]\n",
      "\n",
      "Question :  노아의 방주에 안쪽에 발라 굳힌 것은?\n",
      "--------------------------------------------------\n",
      "Context :  노아는 하나님의 명령에 따라 배를 만들고 가족과 정결한 짐승 암수 일곱 마리씩, 부정한 짐승 암수 한 마리씩(혹은 두 마리씩; 사본에 따라 다름), 그리고 새 암수 일곱 마리씩을 싣고 밀어닥친 홍수를 피하였다. 모든 사람들이 타락한 생활에 빠져 있어 하나님이 홍수로 심\n",
      "판하려 할 때 홀로 바르게 살던 노아는 하나님의 특별한 계시로 홍수가 올 것을 미리 알게 된다. 그는 길이 300 규빗, 너비 50 규빗, 높이 30 규빗(고대의 1규빗은 팔꿈치에서 가운데 손가락끝까지의 길이로 약 45~46cm를 가리킴), 상 ·중 ·하 3층으로 된 \n",
      "방주를 만들어 8명의 가족과, 한 쌍씩의 여러 동물을 데리고 이 방주에 탄다. 대홍수를 만나 모든 생물(물고기 제외)이 전멸하고 말았지만, 이 방주에 탔던 노아의 가족과 동물들은 살아 남았다고 한다.〈창세기〉 6장 14~16절에 보면 길이 300규빗 (약 135m), \n",
      "폭 50 규빗 (약 22.5m), 높이 30 규빗 (약 13.5m)인 이 배는 지붕과 문을 달고 배 안은 3층으로 만들어져 있었다. 선체(船體)는 고페르나무(잣나무)로 되고 안쪽에는 역청(아스팔트와 비슷한 성분)을 칠하여 굳혔다고 기록하고 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "역 ##청 \n",
      "\n",
      "Untokenized Answer :  역청\n",
      "\n",
      "real answer :  [{'text': '역청', 'answer_start': 552}]\n",
      "\n",
      "Question :  군함에 통합되어 실제로 쇼군이 엠퍼러에 첫 좌승한것은 대정봉환 이후 어디에 이송되었을 때인가?\n",
      "--------------------------------------------------\n",
      "Context :  1868년 게이오 4년 4월 11일 에도 성 무혈 개성을 한 이후 신정부 군에게 양도가 약속되어 있었다. 그러나 해군 부총재, 에노모토 다케아키가 기상 불량 등을 이유로 이를 연기한 후에 결국 인도를 거부했다. 도쿠가와 요시노부를 슨푸 번에 이송할 때의 태운 함선으로 \n",
      "사용한 후, 8월 19일 자정 (20일)에는 마쓰오카 바키치를 함장으로 카이요마루, 가이텐마루, 신소쿠마루, 간린마루 등과 함께 막부 해군이 정박하고 있던 시나가와 해역을 탈출했다. 그 때 태풍에 휘말려 침몰직전이 되었지만, 1개월만에 에노모토 해군과 합류하였다. 에조\n",
      "치에 건너가 하코다테 전쟁에서는 에노모토(하코다테 정부) 해군의 주력함이 되었다. 영국이 기증했을 때 엠퍼러(Emperor, 기증 당시 일본의 수장은 황제가 아니라 쇼군으로 인식되고 있었기 때문에 장군을 지칭)로 명명하고 있음에서 알 수 있듯이, 쇼군용 유람 요트로 기\n",
      "증되었다고 생각되지만, 세상이 그것을 허락하지 않았다. 아이러니하게도, 군함에 통합되어 실제로 쇼군이 첫 좌승한 것이 대정봉환 이후 슨푸 번에 이송되었을 때였다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "슨 ##푸 번 \n",
      "\n",
      "Untokenized Answer :  슨푸 번\n",
      "\n",
      "real answer :  [{'text': '슨푸 번', 'answer_start': 524}]\n",
      "\n",
      "Question :  노아의 방주 안정성을 실험하기 위한 연구가 있다고 주장하는 단체는?\n",
      "--------------------------------------------------\n",
      "Context :  창조과학회에서는 또한 노아의 방주가 안정적인 구조였다고 주장하지만, 이와는 달리 노아의 방주는 항해가 불가능한 설계에 가깝다. 실제로 창조과학에서 주장하는 방주의 크기와 철제 부품을 사용하지 않은 목재 선박 중에서 가장 큰 수준의 선박들을 비교하면 배수량이 두배 이상 \n",
      "차이난다. 그리고 목재 선박은 강도 상의 문제 때문에 통상 길이 100m, 배수량 2000톤 정도가 한계로 여겨져 왔다. 창조과학회에서는 노아의 방주의 안정성을 실험하기 위한 연구가 있다고 주장하기도 하나, 그 자체의 불합리성에 대한 비판을 받고 있으며, 관련 주요 연\n",
      "구자는 지질학 석사학위, 생물학 학사학위를 가진 초등학교 교사로서, 주류 학계의 학회나 저널 등에 발표한 적이 없으며 또한 정당한 피어 리뷰에 의해 검증받지 않았다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "창 ##조 ##과 ##학 ##회 \n",
      "\n",
      "Untokenized Answer :  창조과학회\n",
      "\n",
      "real answer :  [{'text': '창조과학회', 'answer_start': 218}]\n",
      "\n",
      "Question :  알렉산더 헤이그는 퍼트리샤 앤토이넷 폭스와 결혼해 몇 명의 자녀를 두었는가?\n",
      "--------------------------------------------------\n",
      "Context :  노터데임 대학교에서 2년간 합리적으로 심각한 공부를 한 후 헤이그는 1944년 미국 육군사관학교로 임명을 획득하여 자신의 어린 시절을 군사 경력의 야망으로 알아챘다. 그 경력은 헤이그의 학문적 경연이 암시하려고 한것보다 더욱 극적이었으며 그는 1947년 310의 동기병\n",
      "에서 217번째 사관으로서 졸업하였다. 22세의 소위로 헤이그는 처음에 캔자스 주 포트라일리에서 정통 제병 연합부대로, 그러고나서 켄터키 주 포트녹스에 있는 기갑 훈련소로 갔다. 그후에 그는 제1 기병 사단으로 선임되고 그러고나서 일본에서 점령군의 임무와 기력이 없는 \n",
      "훈련을 하였다. 그는 1950년 5월 한번 자신의 사령관 알론조 폭스 장군의 딸 퍼트리샤 앤토이넷 폭스와 결혼하여 슬하 3명의 자식을 두었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "3 ##명의 \n",
      "\n",
      "Untokenized Answer :  3명의\n",
      "\n",
      "real answer :  [{'text': '3명', 'answer_start': 367}]\n",
      "\n",
      "Question :  로널드 레이건 정부 출범 당시 알렉산더 헤이그는 어떤 직책을 맡았는가?\n",
      "--------------------------------------------------\n",
      "Context :  알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr., 1924년 12월 2일 ~ 2010년 2월 20일)는 미국의 국무 장관을 지낸 미국의 군인, 관료 및 정치인이다. 로널드 레이건 대통령 밑에서 국무장관을 지냈으며, 리처드 닉슨과 제럴\n",
      "드 포드 대통령 밑에서 백악관 비서실장을 지냈다. 또한 그는 미국 군대에서 2번째로 높은 직위인 미국 육군 부참모 총장과 나토 및 미국 군대의 유럽연합군 최고사령관이었다. 한국 전쟁 시절 더글러스 맥아더 유엔군 사령관의 참모로 직접 참전하였으며, 로널드 레이건 정부 출\n",
      "범당시 초대 국무장관직을 맡아 1980년대 대한민국과 미국의 관계를 조율해 왔다. 저서로 회고록 《경고:현실주의, 레이건과 외교 정책》(1984년 발간)이 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "초대 국 ##무 ##장 ##관 ##직 \n",
      "\n",
      "Untokenized Answer :  초대 국무장관직\n",
      "\n",
      "real answer :  [{'text': '초대 국무장관직', 'answer_start': 304}]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question :  미국 군대에서 두번째로 높은 직위는?\n",
      "--------------------------------------------------\n",
      "Context :  알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr., 1924년 12월 2일 ~ 2010년 2월 20일)는 미국의 국무 장관을 지낸 미국의 군인, 관료 및 정치인이다. 로널드 레이건 대통령 밑에서 국무장관을 지냈으며, 리처드 닉슨과 제럴\n",
      "드 포드 대통령 밑에서 백악관 비서실장을 지냈다. 또한 그는 미국 군대에서 2번째로 높은 직위인 미국 육군 부참모 총장과 나토 및 미국 군대의 유럽연합군 최고사령관이었다. 한국 전쟁 시절 더글러스 맥아더 유엔군 사령관의 참모로 직접 참전하였으며, 로널드 레이건 정부 출\n",
      "범당시 초대 국무장관직을 맡아 1980년대 대한민국과 미국의 관계를 조율해 왔다. 저서로 회고록 《경고:현실주의, 레이건과 외교 정책》(1984년 발간)이 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "미국 육 ##군 부 ##참 ##모 총 ##장 \n",
      "\n",
      "Untokenized Answer :  미국 육군 부참모 총장\n",
      "\n",
      "real answer :  [{'text': '미국 육군 부참모 총장', 'answer_start': 204}]\n",
      "\n",
      "Question :  노아의 방주는 총 몇층으로 되어 있었는가?\n",
      "--------------------------------------------------\n",
      "Context :  노아는 하나님의 명령에 따라 배를 만들고 가족과 정결한 짐승 암수 일곱 마리씩, 부정한 짐승 암수 한 마리씩(혹은 두 마리씩; 사본에 따라 다름), 그리고 새 암수 일곱 마리씩을 싣고 밀어닥친 홍수를 피하였다. 모든 사람들이 타락한 생활에 빠져 있어 하나님이 홍수로 심\n",
      "판하려 할 때 홀로 바르게 살던 노아는 하나님의 특별한 계시로 홍수가 올 것을 미리 알게 된다. 그는 길이 300 규빗, 너비 50 규빗, 높이 30 규빗(고대의 1규빗은 팔꿈치에서 가운데 손가락끝까지의 길이로 약 45~46cm를 가리킴), 상 ·중 ·하 3층으로 된 \n",
      "방주를 만들어 8명의 가족과, 한 쌍씩의 여러 동물을 데리고 이 방주에 탄다. 대홍수를 만나 모든 생물(물고기 제외)이 전멸하고 말았지만, 이 방주에 탔던 노아의 가족과 동물들은 살아 남았다고 한다.〈창세기〉 6장 14~16절에 보면 길이 300규빗 (약 135m), \n",
      "폭 50 규빗 (약 22.5m), 높이 30 규빗 (약 13.5m)인 이 배는 지붕과 문을 달고 배 안은 3층으로 만들어져 있었다. 선체(船體)는 고페르나무(잣나무)로 되고 안쪽에는 역청(아스팔트와 비슷한 성분)을 칠하여 굳혔다고 기록하고 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "3 ##층 \n",
      "\n",
      "Untokenized Answer :  3층\n",
      "\n",
      "real answer :  [{'text': '3층', 'answer_start': 293}]\n",
      "\n",
      "Question :  철갑선의 사정거리에 들어간 순간에 순풍이 불기 시작하여 추격을 뿌리치고 어디로 돌아올 수 있었는가?\n",
      "--------------------------------------------------\n",
      "Context :  일련의 하코다테 전쟁은 적아 쌍방의 문서에 마쓰오카 바키치 함장의 능란한 조함 능력과 냉정한 지휘만이 기록되어 있다. 함포 사격으로 마쓰마에 성을 공격하여 엄호한 이후, 1869년 메이지 2년 3월 25일 미야코 만 해전에서는 폭풍우를 만나 요함과 헤어졌을 때에 만날 \n",
      "약속했던 하치노헤 항에서 대기하고 있었기 때문에 참전에는 이르지 못했다. 이 폭풍우 때도 “함장 마쓰오카 바키치는 배를 조정하는 명수로 로프 하나 손상되지 않았다”고 타고 있던 하야시 다다스가 남긴 바 있다. 이 귀로에서 신정부 군의 철갑함의 추격을 받았다. 기관 능력\n",
      "의 차이로 인한 속도차 때문에 도주가 불가능하다고 판단하고 맞장 공격을 하겠다고 전투 준비를 했지만, 철갑선의 사정거리에 들어간 순간에 순풍이 불기 시작하여 추격을 뿌리치고 하코다테로 돌아올 수 있었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "하 ##코 ##다 ##테 \n",
      "\n",
      "Untokenized Answer :  하코다테\n",
      "\n",
      "real answer :  [{'text': '하코다테', 'answer_start': 397}]\n",
      "\n",
      "Question :  하나님의 명령에 배를 만들고 가족과 짐승들을 배에 태워 홍수를 피한 사람은 누구인가?\n",
      "--------------------------------------------------\n",
      "Context :  노아는 하나님의 명령에 따라 배를 만들고 가족과 정결한 짐승 암수 일곱 마리씩, 부정한 짐승 암수 한 마리씩(혹은 두 마리씩; 사본에 따라 다름), 그리고 새 암수 일곱 마리씩을 싣고 밀어닥친 홍수를 피하였다. 모든 사람들이 타락한 생활에 빠져 있어 하나님이 홍수로 심\n",
      "판하려 할 때 홀로 바르게 살던 노아는 하나님의 특별한 계시로 홍수가 올 것을 미리 알게 된다. 그는 길이 300 규빗, 너비 50 규빗, 높이 30 규빗(고대의 1규빗은 팔꿈치에서 가운데 손가락끝까지의 길이로 약 45~46cm를 가리킴), 상 ·중 ·하 3층으로 된 \n",
      "방주를 만들어 8명의 가족과, 한 쌍씩의 여러 동물을 데리고 이 방주에 탄다. 대홍수를 만나 모든 생물(물고기 제외)이 전멸하고 말았지만, 이 방주에 탔던 노아의 가족과 동물들은 살아 남았다고 한다.〈창세기〉 6장 14~16절에 보면 길이 300규빗 (약 135m), \n",
      "폭 50 규빗 (약 22.5m), 높이 30 규빗 (약 13.5m)인 이 배는 지붕과 문을 달고 배 안은 3층으로 만들어져 있었다. 선체(船體)는 고페르나무(잣나무)로 되고 안쪽에는 역청(아스팔트와 비슷한 성분)을 칠하여 굳혔다고 기록하고 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "노 ##아 \n",
      "\n",
      "Untokenized Answer :  노아\n",
      "\n",
      "real answer :  [{'text': '노아', 'answer_start': 0}]\n",
      "\n",
      "Question :  미국 군대 내 두번째로 높은 직위는 무엇인가?\n",
      "--------------------------------------------------\n",
      "Context :  알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr., 1924년 12월 2일 ~ 2010년 2월 20일)는 미국의 국무 장관을 지낸 미국의 군인, 관료 및 정치인이다. 로널드 레이건 대통령 밑에서 국무장관을 지냈으며, 리처드 닉슨과 제럴\n",
      "드 포드 대통령 밑에서 백악관 비서실장을 지냈다. 또한 그는 미국 군대에서 2번째로 높은 직위인 미국 육군 부참모 총장과 나토 및 미국 군대의 유럽연합군 최고사령관이었다. 한국 전쟁 시절 더글러스 맥아더 유엔군 사령관의 참모로 직접 참전하였으며, 로널드 레이건 정부 출\n",
      "범당시 초대 국무장관직을 맡아 1980년대 대한민국과 미국의 관계를 조율해 왔다. 저서로 회고록 《경고:현실주의, 레이건과 외교 정책》(1984년 발간)이 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "미국 육 ##군 부 ##참 ##모 총 ##장 \n",
      "\n",
      "Untokenized Answer :  미국 육군 부참모 총장\n",
      "\n",
      "real answer :  [{'text': '미국 육군 부참모 총장', 'answer_start': 204}]\n",
      "\n",
      "Question :  임종석이 조사를 받은 뒤 인계된 곳은 어딘가?\n",
      "--------------------------------------------------\n",
      "Context :  1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률위반)으로 지명수배되었다. 1989년 3월 12일 서울지방검찰청 공안부는 임종석의 사전구속영장을 발부받았다. 같은 해 6월 30일 평양축전에 임수경을 대표로 파견하여 국가보안법위반 혐의가\n",
      " 추가되었다. 경찰은 12월 18일~20일 사이 서울 경희대학교에서 임종석이 성명 발표를 추진하고 있다는 첩보를 입수했고, 12월 18일 오전 7시 40분 경 가스총과 전자봉으로 무장한 특공조 및 대공과 직원 12명 등 22명의 사복 경찰을 승용차 8대에 나누어 경희대\n",
      "학교에 투입했다. 1989년 12월 18일 오전 8시 15분 경 서울청량리경찰서는 호위 학생 5명과 함께 경희대학교 학생회관 건물 계단을 내려오는 임종석을 발견, 검거해 구속을 집행했다. 임종석은 청량리경찰서에서 약 1시간 동안 조사를 받은 뒤 오전 9시 50분 경 서\n",
      "울 장안동의 서울지방경찰청 공안분실로 인계되었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "서울 ##지 ##방 ##경 ##찰 ##청 공 ##안 ##분 ##실 \n",
      "\n",
      "Untokenized Answer :  서울지방경찰청 공안분실\n",
      "\n",
      "real answer :  [{'text': '서울지방경찰청 공안분실', 'answer_start': 457}]\n",
      "\n",
      "Question :  알렉산더 메이그스 헤이그의 생년월일은?\n",
      "--------------------------------------------------\n",
      "Context :  알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr., 1924년 12월 2일 ~ 2010년 2월 20일)는 미국의 국무 장관을 지낸 미국의 군인, 관료 및 정치인이다. 로널드 레이건 대통령 밑에서 국무장관을 지냈으며, 리처드 닉슨과 제럴\n",
      "드 포드 대통령 밑에서 백악관 비서실장을 지냈다. 또한 그는 미국 군대에서 2번째로 높은 직위인 미국 육군 부참모 총장과 나토 및 미국 군대의 유럽연합군 최고사령관이었다. 한국 전쟁 시절 더글러스 맥아더 유엔군 사령관의 참모로 직접 참전하였으며, 로널드 레이건 정부 출\n",
      "범당시 초대 국무장관직을 맡아 1980년대 대한민국과 미국의 관계를 조율해 왔다. 저서로 회고록 《경고:현실주의, 레이건과 외교 정책》(1984년 발간)이 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "1924 ##년 12월 2일 \n",
      "\n",
      "Untokenized Answer :  1924년 12월 2일\n",
      "\n",
      "real answer :  [{'text': '1924년 12월 2일', 'answer_start': 48}]\n",
      "\n",
      "Question :  담수와 염수가 급작스럽게 섞일 경우 대부분의 수생생물이 폐사하는 원인은?\n",
      "--------------------------------------------------\n",
      "Context :  기독교 성경 내용에는 모든 종들을 방주에 태운다고 이야기하고 있으나, 어류나 수중 생물에 대해서는 언급하지 않았다. 이것을 신학적 의미로만 받아들이면 괜찮은 문제이나, 이 현상이 실제로 일어났다고 가정할 경우,이는 종 간 생존 환경의 차이에 대해서 간과하고 있다. 수중\n",
      " 생물이라 하더라도 종에 따라 생존할 수 있는 환경은 각각 다른 것이며, 40일 이내에 현존하는 가장 높은 산인 에베레스트 산도 잠기게 할 정도의 폭우로 인해 담수와 염수가 급작스럽게 섞일 경우, 급격한 삼투압 변화로 인해 대부분의 수생생물들이 폐사하게 되며, 결과적으\n",
      "로 육지 뿐 아니라 바다와 강의 모든 생태계가 파괴된다. 이후 5천년이라는 지극히 짧은 세월 동안 지구상의 동식물이 모두 페름기 대멸종 또는 K-T 대멸종에 준하는 대량절멸에 가까운 상태에서부터 시작하여 현재의 대략 870만(±120만)종에 달하는 생물다양성을 획득하려\n",
      "면 모든 생물들이 각 세대마다 종분화가 일어나야 할 만큼 엄청난 속도로 진화 및 번식이 (멸종 없이) 이루어져야만 가능한 일이다. (이와 관련하여 창조과학회 측에서는 북극곰의 예시를 통해 가지고 있던 특성이 없어지는 것이 진화가 아니라고 주장하지만, 통상적으로 알려진 \n",
      "바와 같이 생물학에서는 이미 존재하는 특성이 없어지는 현상, 즉 퇴화 역시 진화의 정의에 포함된다.) 즉, 노아의 홍수가 실재하는 사건이었다면 진화적 종분화가 현재까지 알려진 것과 비교할 수 없이 엄청난 속도로 이루어져야만 현재 지구의 생물다양성을 설명할 수 있다. 게\n",
      "다가 이것은 현재의 생물종 멸종 속도를 전혀 고려하지 않았다. 다시 말해, 노아의 홍수가 실재하는 전지구적인 사건이기 위해서는 최소 캄브리아기 대폭발 수준의 폭발적인 진화적 종분화가 1-2억년이 아니라 최대 3-4천년 이내에 이루어졌어야만 현생 지구의 생물다양성에 대한\n",
      " 설명이 가능해진다. 그보다 더 중요한 것은, 각 동물들이 차지하는 영역과 먹이사슬에서의 위치, 375일 동안 먹이도 없이 밀폐된 공간으로 인해 받을 스트레스 등 생태적 지위에 대한 고려가 전혀 없다는 점이다. 또한 바다에서 생존이 불가능한 생물종까지 숫자에 포함되었다\n",
      "는 점에서 논란이 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "급 ##격 ##한 삼 ##투 ##압 변 ##화 \n",
      "\n",
      "Untokenized Answer :  급격한 삼투압 변화\n",
      "\n",
      "real answer :  [{'text': '급격한 삼투압 변화', 'answer_start': 260}]\n",
      "\n",
      "Question :  유사지질학인 홍수지질학이 근원은?\n",
      "--------------------------------------------------\n",
      "Context :  역사학과 과학의 발달이 더뎠던 고대사회에서는, 성경이 단순한 교리적인 부분 뿐 아니라 역사책으로서의 권위도 높았기에 노아의 방주를 역사적인 존재로서 다루고 있었다. 이는 제칠일안식교에서 비롯된 의사과학의 한 종류인 유사지질학인 홍수지질학과 같은 것에 영향을 주었으며, \n",
      "과거 신학에서는 이러한 근본주의적 해석을 받아들여 역사와 사회적인 모든 부분에 있어 성경을 교과서로 채택할 것을 촉구했다. 이러한 홍수지질학을 주장했던 유사지질학자들은 성경에 나오는 노아의 홍수가 어딘가에 그 흔적이 남아 있을것이라고 주장하며 노아의 방주를 찾기 위한 \n",
      "노력을 했다고 주장한다. 이들은 같은 메소포타미아 지방의 신화인 이슬람교 경전이나 길가메쉬 서사시등의 신화를 들어서 이를 근거라고 주장하기도 했다. 그러나 이러한 전통적 근본주의적 시각은 과거에는 상당히 힘을 얻었으나, 역사학과 과학의 발달에 따라 힘을 잃게 되었고, \n",
      "홍수지질학은 유사과학으로서 남게 되었다. 현대에는 뒤의 실존논란에서 다루는 것처럼 이러한 근본주의적 해석은 비과학적인 해석으로 여기는 것이 일반적이지만, 남침례교로 대표되는 극보수주의계열 기독교에서는 아직도 이것이 받아들여지고 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "제 ##칠 ##일 ##안 ##식 ##교 \n",
      "\n",
      "Untokenized Answer :  제칠일안식교\n",
      "\n",
      "real answer :  [{'text': '제칠일안식교', 'answer_start': 95}]\n",
      "\n",
      "Question :  헤이그는 나토에서 얼마나 있었습니까?\n",
      "--------------------------------------------------\n",
      "Context :  헤이그는 닉슨 대통령이 그를 사성 장군과 육군 부참모로 진급시킬 때 집중 광선과 논쟁으로 들어갔다. 헤이그를 군사의 최상으로 밀어넣은 닉슨의 행동은 대통령의 남자들을 다양한 연방 대리법에서 권한의 직우들로 놓은 노력과 함께 일치였다. 하지만 그는 곧 백악관으로 돌아가 \n",
      "1973년부터 1974년까지 대통령 특별 보좌관을 지냈다. 워터게이트 사건이 일어난지 한달 후, 헤이그는 포위된 닉슨 대통령을 위한 치명적 역할을 하였다. 그일은 8월 닉슨의 사임과 제럴드 포드의 대통령으로 계승으로 이끈 협상들에서 헤이그가 수단이었던 우연이 아니었다.\n",
      " 곧 후에 헤이그는 미국 유럽 연합군 최고사령부의 최고 사령관으로 임명되었다. 그는 나토에서 다음 5년을 보내고 1979년 군에서 퇴역하여 미국 기술 주식 회사의 우두머리가 되었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "5 ##년 \n",
      "\n",
      "Untokenized Answer :  5년\n",
      "\n",
      "real answer :  [{'text': '5년', 'answer_start': 355}]\n",
      "\n",
      "Question :  육군사관학교에서 졸업한 헤이그가 제일 처음 소위로 발령받은 부대는 무엇이었나?\n",
      "--------------------------------------------------\n",
      "Context :  노터데임 대학교에서 2년간 합리적으로 심각한 공부를 한 후 헤이그는 1944년 미국 육군사관학교로 임명을 획득하여 자신의 어린 시절을 군사 경력의 야망으로 알아챘다. 그 경력은 헤이그의 학문적 경연이 암시하려고 한것보다 더욱 극적이었으며 그는 1947년 310의 동기병\n",
      "에서 217번째 사관으로서 졸업하였다. 22세의 소위로 헤이그는 처음에 캔자스 주 포트라일리에서 정통 제병 연합부대로, 그러고나서 켄터키 주 포트녹스에 있는 기갑 훈련소로 갔다. 그후에 그는 제1 기병 사단으로 선임되고 그러고나서 일본에서 점령군의 임무와 기력이 없는 \n",
      "훈련을 하였다. 그는 1950년 5월 한번 자신의 사령관 알론조 폭스 장군의 딸 퍼트리샤 앤토이넷 폭스와 결혼하여 슬하 3명의 자식을 두었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "정 ##통 제 ##병 \n",
      "\n",
      "Untokenized Answer :  정통 제병\n",
      "\n",
      "real answer :  [{'text': '정통 제병 연합부대', 'answer_start': 204}]\n",
      "\n",
      "Question :  로널드 레이건 대통령 밑에서 일한 국무 장관은 누구인가?\n",
      "--------------------------------------------------\n",
      "Context :  알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr., 1924년 12월 2일 ~ 2010년 2월 20일)는 미국의 국무 장관을 지낸 미국의 군인, 관료 및 정치인이다. 로널드 레이건 대통령 밑에서 국무장관을 지냈으며, 리처드 닉슨과 제럴\n",
      "드 포드 대통령 밑에서 백악관 비서실장을 지냈다. 또한 그는 미국 군대에서 2번째로 높은 직위인 미국 육군 부참모 총장과 나토 및 미국 군대의 유럽연합군 최고사령관이었다. 한국 전쟁 시절 더글러스 맥아더 유엔군 사령관의 참모로 직접 참전하였으며, 로널드 레이건 정부 출\n",
      "범당시 초대 국무장관직을 맡아 1980년대 대한민국과 미국의 관계를 조율해 왔다. 저서로 회고록 《경고:현실주의, 레이건과 외교 정책》(1984년 발간)이 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "알 ##렉 ##산 ##더 메 ##이 ##그 ##스 헤 ##이 ##그 \n",
      "\n",
      "Untokenized Answer :  알렉산더 메이그스 헤이그\n",
      "\n",
      "real answer :  [{'text': '알렉산더 메이그스 헤이그 2세', 'answer_start': 0}]\n",
      "\n",
      "Question :  목재 선박의 배수량의 한계는 얼마인가?\n",
      "--------------------------------------------------\n",
      "Context :  창조과학회에서는 또한 노아의 방주가 안정적인 구조였다고 주장하지만, 이와는 달리 노아의 방주는 항해가 불가능한 설계에 가깝다. 실제로 창조과학에서 주장하는 방주의 크기와 철제 부품을 사용하지 않은 목재 선박 중에서 가장 큰 수준의 선박들을 비교하면 배수량이 두배 이상 \n",
      "차이난다. 그리고 목재 선박은 강도 상의 문제 때문에 통상 길이 100m, 배수량 2000톤 정도가 한계로 여겨져 왔다. 창조과학회에서는 노아의 방주의 안정성을 실험하기 위한 연구가 있다고 주장하기도 하나, 그 자체의 불합리성에 대한 비판을 받고 있으며, 관련 주요 연\n",
      "구자는 지질학 석사학위, 생물학 학사학위를 가진 초등학교 교사로서, 주류 학계의 학회나 저널 등에 발표한 적이 없으며 또한 정당한 피어 리뷰에 의해 검증받지 않았다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "2000 ##톤 \n",
      "\n",
      "Untokenized Answer :  2000톤\n",
      "\n",
      "real answer :  [{'text': '2000톤', 'answer_start': 196}]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question :  목재로 만들어진 선박은 강도 상의 통상 길이 몇m가 한계인가?\n",
      "--------------------------------------------------\n",
      "Context :  창조과학회에서는 또한 노아의 방주가 안정적인 구조였다고 주장하지만, 이와는 달리 노아의 방주는 항해가 불가능한 설계에 가깝다. 실제로 창조과학에서 주장하는 방주의 크기와 철제 부품을 사용하지 않은 목재 선박 중에서 가장 큰 수준의 선박들을 비교하면 배수량이 두배 이상 \n",
      "차이난다. 그리고 목재 선박은 강도 상의 문제 때문에 통상 길이 100m, 배수량 2000톤 정도가 한계로 여겨져 왔다. 창조과학회에서는 노아의 방주의 안정성을 실험하기 위한 연구가 있다고 주장하기도 하나, 그 자체의 불합리성에 대한 비판을 받고 있으며, 관련 주요 연\n",
      "구자는 지질학 석사학위, 생물학 학사학위를 가진 초등학교 교사로서, 주류 학계의 학회나 저널 등에 발표한 적이 없으며 또한 정당한 피어 리뷰에 의해 검증받지 않았다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "100m \n",
      "\n",
      "Untokenized Answer :  100m\n",
      "\n",
      "real answer :  [{'text': '100m', 'answer_start': 186}]\n",
      "\n",
      "Question :  1950년 헤이그와 결혼한 여자의 이름은?\n",
      "--------------------------------------------------\n",
      "Context :  노터데임 대학교에서 2년간 합리적으로 심각한 공부를 한 후 헤이그는 1944년 미국 육군사관학교로 임명을 획득하여 자신의 어린 시절을 군사 경력의 야망으로 알아챘다. 그 경력은 헤이그의 학문적 경연이 암시하려고 한것보다 더욱 극적이었으며 그는 1947년 310의 동기병\n",
      "에서 217번째 사관으로서 졸업하였다. 22세의 소위로 헤이그는 처음에 캔자스 주 포트라일리에서 정통 제병 연합부대로, 그러고나서 켄터키 주 포트녹스에 있는 기갑 훈련소로 갔다. 그후에 그는 제1 기병 사단으로 선임되고 그러고나서 일본에서 점령군의 임무와 기력이 없는 \n",
      "훈련을 하였다. 그는 1950년 5월 한번 자신의 사령관 알론조 폭스 장군의 딸 퍼트리샤 앤토이넷 폭스와 결혼하여 슬하 3명의 자식을 두었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "퍼 ##트 ##리 ##샤 앤 ##토 ##이 ##넷 폭 ##스 \n",
      "\n",
      "Untokenized Answer :  퍼트리샤 앤토이넷 폭스\n",
      "\n",
      "real answer :  [{'text': '퍼트리샤 앤토이넷 폭스', 'answer_start': 345}]\n",
      "\n",
      "Question :  알렉산더 헤이그가 미국 육군사관학교로 임명받은 해는 언제인가?\n",
      "--------------------------------------------------\n",
      "Context :  노터데임 대학교에서 2년간 합리적으로 심각한 공부를 한 후 헤이그는 1944년 미국 육군사관학교로 임명을 획득하여 자신의 어린 시절을 군사 경력의 야망으로 알아챘다. 그 경력은 헤이그의 학문적 경연이 암시하려고 한것보다 더욱 극적이었으며 그는 1947년 310의 동기병\n",
      "에서 217번째 사관으로서 졸업하였다. 22세의 소위로 헤이그는 처음에 캔자스 주 포트라일리에서 정통 제병 연합부대로, 그러고나서 켄터키 주 포트녹스에 있는 기갑 훈련소로 갔다. 그후에 그는 제1 기병 사단으로 선임되고 그러고나서 일본에서 점령군의 임무와 기력이 없는 \n",
      "훈련을 하였다. 그는 1950년 5월 한번 자신의 사령관 알론조 폭스 장군의 딸 퍼트리샤 앤토이넷 폭스와 결혼하여 슬하 3명의 자식을 두었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "1944 ##년 \n",
      "\n",
      "Untokenized Answer :  1944년\n",
      "\n",
      "real answer :  [{'text': '1944년', 'answer_start': 38}]\n",
      "\n",
      "Question :  급작스러운 폭우로 담수와 염수가 섞일 경우 삼투압 변화로 폐사하는 생물류는?\n",
      "--------------------------------------------------\n",
      "Context :  기독교 성경 내용에는 모든 종들을 방주에 태운다고 이야기하고 있으나, 어류나 수중 생물에 대해서는 언급하지 않았다. 이것을 신학적 의미로만 받아들이면 괜찮은 문제이나, 이 현상이 실제로 일어났다고 가정할 경우,이는 종 간 생존 환경의 차이에 대해서 간과하고 있다. 수중\n",
      " 생물이라 하더라도 종에 따라 생존할 수 있는 환경은 각각 다른 것이며, 40일 이내에 현존하는 가장 높은 산인 에베레스트 산도 잠기게 할 정도의 폭우로 인해 담수와 염수가 급작스럽게 섞일 경우, 급격한 삼투압 변화로 인해 대부분의 수생생물들이 폐사하게 되며, 결과적으\n",
      "로 육지 뿐 아니라 바다와 강의 모든 생태계가 파괴된다. 이후 5천년이라는 지극히 짧은 세월 동안 지구상의 동식물이 모두 페름기 대멸종 또는 K-T 대멸종에 준하는 대량절멸에 가까운 상태에서부터 시작하여 현재의 대략 870만(±120만)종에 달하는 생물다양성을 획득하려\n",
      "면 모든 생물들이 각 세대마다 종분화가 일어나야 할 만큼 엄청난 속도로 진화 및 번식이 (멸종 없이) 이루어져야만 가능한 일이다. (이와 관련하여 창조과학회 측에서는 북극곰의 예시를 통해 가지고 있던 특성이 없어지는 것이 진화가 아니라고 주장하지만, 통상적으로 알려진 \n",
      "바와 같이 생물학에서는 이미 존재하는 특성이 없어지는 현상, 즉 퇴화 역시 진화의 정의에 포함된다.) 즉, 노아의 홍수가 실재하는 사건이었다면 진화적 종분화가 현재까지 알려진 것과 비교할 수 없이 엄청난 속도로 이루어져야만 현재 지구의 생물다양성을 설명할 수 있다. 게\n",
      "다가 이것은 현재의 생물종 멸종 속도를 전혀 고려하지 않았다. 다시 말해, 노아의 홍수가 실재하는 전지구적인 사건이기 위해서는 최소 캄브리아기 대폭발 수준의 폭발적인 진화적 종분화가 1-2억년이 아니라 최대 3-4천년 이내에 이루어졌어야만 현생 지구의 생물다양성에 대한\n",
      " 설명이 가능해진다. 그보다 더 중요한 것은, 각 동물들이 차지하는 영역과 먹이사슬에서의 위치, 375일 동안 먹이도 없이 밀폐된 공간으로 인해 받을 스트레스 등 생태적 지위에 대한 고려가 전혀 없다는 점이다. 또한 바다에서 생존이 불가능한 생물종까지 숫자에 포함되었다\n",
      "는 점에서 논란이 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "수 ##생 ##생 ##물 \n",
      "\n",
      "Untokenized Answer :  수생생물\n",
      "\n",
      "real answer :  [{'text': '수생생물', 'answer_start': 280}]\n",
      "\n",
      "Question :  1868년 당시 일본의 해군 부총재는?\n",
      "--------------------------------------------------\n",
      "Context :  1868년 게이오 4년 4월 11일 에도 성 무혈 개성을 한 이후 신정부 군에게 양도가 약속되어 있었다. 그러나 해군 부총재, 에노모토 다케아키가 기상 불량 등을 이유로 이를 연기한 후에 결국 인도를 거부했다. 도쿠가와 요시노부를 슨푸 번에 이송할 때의 태운 함선으로 \n",
      "사용한 후, 8월 19일 자정 (20일)에는 마쓰오카 바키치를 함장으로 카이요마루, 가이텐마루, 신소쿠마루, 간린마루 등과 함께 막부 해군이 정박하고 있던 시나가와 해역을 탈출했다. 그 때 태풍에 휘말려 침몰직전이 되었지만, 1개월만에 에노모토 해군과 합류하였다. 에조\n",
      "치에 건너가 하코다테 전쟁에서는 에노모토(하코다테 정부) 해군의 주력함이 되었다. 영국이 기증했을 때 엠퍼러(Emperor, 기증 당시 일본의 수장은 황제가 아니라 쇼군으로 인식되고 있었기 때문에 장군을 지칭)로 명명하고 있음에서 알 수 있듯이, 쇼군용 유람 요트로 기\n",
      "증되었다고 생각되지만, 세상이 그것을 허락하지 않았다. 아이러니하게도, 군함에 통합되어 실제로 쇼군이 첫 좌승한 것이 대정봉환 이후 슨푸 번에 이송되었을 때였다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "에 ##노 ##모토 다 ##케 ##아 ##키 \n",
      "\n",
      "Untokenized Answer :  에노모토 다케아키\n",
      "\n",
      "real answer :  [{'text': '에노모토 다케아키', 'answer_start': 71}]\n",
      "\n",
      "Question :  미야코 만 해전에서 아쓰오카 바키치 함장이 폭풍우를 만난 년도는?\n",
      "--------------------------------------------------\n",
      "Context :  일련의 하코다테 전쟁은 적아 쌍방의 문서에 마쓰오카 바키치 함장의 능란한 조함 능력과 냉정한 지휘만이 기록되어 있다. 함포 사격으로 마쓰마에 성을 공격하여 엄호한 이후, 1869년 메이지 2년 3월 25일 미야코 만 해전에서는 폭풍우를 만나 요함과 헤어졌을 때에 만날 \n",
      "약속했던 하치노헤 항에서 대기하고 있었기 때문에 참전에는 이르지 못했다. 이 폭풍우 때도 “함장 마쓰오카 바키치는 배를 조정하는 명수로 로프 하나 손상되지 않았다”고 타고 있던 하야시 다다스가 남긴 바 있다. 이 귀로에서 신정부 군의 철갑함의 추격을 받았다. 기관 능력\n",
      "의 차이로 인한 속도차 때문에 도주가 불가능하다고 판단하고 맞장 공격을 하겠다고 전투 준비를 했지만, 철갑선의 사정거리에 들어간 순간에 순풍이 불기 시작하여 추격을 뿌리치고 하코다테로 돌아올 수 있었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "1869 ##년 \n",
      "\n",
      "Untokenized Answer :  1869년\n",
      "\n",
      "real answer :  [{'text': '1869년', 'answer_start': 95}]\n",
      "\n",
      "Question :  전통 신학계의 근본주의적 시작을 여전히 받아들여 노아의 방주를 역사적 사실로 인식하는 집단은?\n",
      "--------------------------------------------------\n",
      "Context :  역사학과 과학이 발달하지 않았던 과거 전통 신학계에서는 근본주의적 시각을 받아들여 노아의 방주를 역사적 사실로 기술하려 했으며, 이러한 관점은 아직도 과학과 역사학에 어두운 보수적 근본주의계열의 개신교에서만 받아들여지고 있다. 하지만 역사학과 과학의 발달로 인해, 노아\n",
      "의 방주의 실존에 대한 의문이 제기가 되고, 세계적 홍수가 존재할 수 없음이 밝혀짐에 따라 현대 신학계에서는 비록 노아의 홍수가 과학적으로 실존하지는 않았지만 그 자체의 의미는 신학적으로 매우 중요하며, 이에 대한 해석은 다양하게 이루어지고 있으며, 대부분의 기독교(가\n",
      "톨릭, 개신교를 포함한 대부분)에서는 노아의 방주는 상징적 의미로 받아들여진다. 그러므로 과학과는 상관없이 신학적으로 노아의 방주 자체의 의미는 중요하게 해석된다고 한다\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "개 ##신 ##교 \n",
      "\n",
      "Untokenized Answer :  개신교\n",
      "\n",
      "real answer :  [{'text': '보수적 근본주의계열의 개신교', 'answer_start': 97}]\n",
      "\n",
      "Question :  헤이그가 군대에서 퇴역한 년도는?\n",
      "--------------------------------------------------\n",
      "Context :  헤이그는 닉슨 대통령이 그를 사성 장군과 육군 부참모로 진급시킬 때 집중 광선과 논쟁으로 들어갔다. 헤이그를 군사의 최상으로 밀어넣은 닉슨의 행동은 대통령의 남자들을 다양한 연방 대리법에서 권한의 직우들로 놓은 노력과 함께 일치였다. 하지만 그는 곧 백악관으로 돌아가 \n",
      "1973년부터 1974년까지 대통령 특별 보좌관을 지냈다. 워터게이트 사건이 일어난지 한달 후, 헤이그는 포위된 닉슨 대통령을 위한 치명적 역할을 하였다. 그일은 8월 닉슨의 사임과 제럴드 포드의 대통령으로 계승으로 이끈 협상들에서 헤이그가 수단이었던 우연이 아니었다.\n",
      " 곧 후에 헤이그는 미국 유럽 연합군 최고사령부의 최고 사령관으로 임명되었다. 그는 나토에서 다음 5년을 보내고 1979년 군에서 퇴역하여 미국 기술 주식 회사의 우두머리가 되었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "1979 ##년 \n",
      "\n",
      "Untokenized Answer :  1979년\n",
      "\n",
      "real answer :  [{'text': '1979년', 'answer_start': 363}]\n",
      "\n",
      "Question :  목재 선박의 배수량 한계는?\n",
      "--------------------------------------------------\n",
      "Context :  창조과학회에서는 또한 노아의 방주가 안정적인 구조였다고 주장하지만, 이와는 달리 노아의 방주는 항해가 불가능한 설계에 가깝다. 실제로 창조과학에서 주장하는 방주의 크기와 철제 부품을 사용하지 않은 목재 선박 중에서 가장 큰 수준의 선박들을 비교하면 배수량이 두배 이상 \n",
      "차이난다. 그리고 목재 선박은 강도 상의 문제 때문에 통상 길이 100m, 배수량 2000톤 정도가 한계로 여겨져 왔다. 창조과학회에서는 노아의 방주의 안정성을 실험하기 위한 연구가 있다고 주장하기도 하나, 그 자체의 불합리성에 대한 비판을 받고 있으며, 관련 주요 연\n",
      "구자는 지질학 석사학위, 생물학 학사학위를 가진 초등학교 교사로서, 주류 학계의 학회나 저널 등에 발표한 적이 없으며 또한 정당한 피어 리뷰에 의해 검증받지 않았다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "2000 ##톤 \n",
      "\n",
      "Untokenized Answer :  2000톤\n",
      "\n",
      "real answer :  [{'text': '2000톤', 'answer_start': 196}]\n",
      "\n",
      "Question :  고대사회에서 성경은 교리를 다루는 책일 뿐만 아니라 어떤 책으로도 권위가 상당했는가?\n",
      "--------------------------------------------------\n",
      "Context :  역사학과 과학의 발달이 더뎠던 고대사회에서는, 성경이 단순한 교리적인 부분 뿐 아니라 역사책으로서의 권위도 높았기에 노아의 방주를 역사적인 존재로서 다루고 있었다. 이는 제칠일안식교에서 비롯된 의사과학의 한 종류인 유사지질학인 홍수지질학과 같은 것에 영향을 주었으며, \n",
      "과거 신학에서는 이러한 근본주의적 해석을 받아들여 역사와 사회적인 모든 부분에 있어 성경을 교과서로 채택할 것을 촉구했다. 이러한 홍수지질학을 주장했던 유사지질학자들은 성경에 나오는 노아의 홍수가 어딘가에 그 흔적이 남아 있을것이라고 주장하며 노아의 방주를 찾기 위한 \n",
      "노력을 했다고 주장한다. 이들은 같은 메소포타미아 지방의 신화인 이슬람교 경전이나 길가메쉬 서사시등의 신화를 들어서 이를 근거라고 주장하기도 했다. 그러나 이러한 전통적 근본주의적 시각은 과거에는 상당히 힘을 얻었으나, 역사학과 과학의 발달에 따라 힘을 잃게 되었고, \n",
      "홍수지질학은 유사과학으로서 남게 되었다. 현대에는 뒤의 실존논란에서 다루는 것처럼 이러한 근본주의적 해석은 비과학적인 해석으로 여기는 것이 일반적이지만, 남침례교로 대표되는 극보수주의계열 기독교에서는 아직도 이것이 받아들여지고 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "역 ##사 ##책 \n",
      "\n",
      "Untokenized Answer :  역사책\n",
      "\n",
      "real answer :  [{'text': '역사책', 'answer_start': 48}]\n",
      "\n",
      "Question :  목재 선박은 강도상의 문제로 통상 길이 몇m가 한계인가?\n",
      "--------------------------------------------------\n",
      "Context :  창조과학회에서는 또한 노아의 방주가 안정적인 구조였다고 주장하지만, 이와는 달리 노아의 방주는 항해가 불가능한 설계에 가깝다. 실제로 창조과학에서 주장하는 방주의 크기와 철제 부품을 사용하지 않은 목재 선박 중에서 가장 큰 수준의 선박들을 비교하면 배수량이 두배 이상 \n",
      "차이난다. 그리고 목재 선박은 강도 상의 문제 때문에 통상 길이 100m, 배수량 2000톤 정도가 한계로 여겨져 왔다. 창조과학회에서는 노아의 방주의 안정성을 실험하기 위한 연구가 있다고 주장하기도 하나, 그 자체의 불합리성에 대한 비판을 받고 있으며, 관련 주요 연\n",
      "구자는 지질학 석사학위, 생물학 학사학위를 가진 초등학교 교사로서, 주류 학계의 학회나 저널 등에 발표한 적이 없으며 또한 정당한 피어 리뷰에 의해 검증받지 않았다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "100m \n",
      "\n",
      "Untokenized Answer :  100m\n",
      "\n",
      "real answer :  [{'text': '100m', 'answer_start': 186}]\n",
      "\n",
      "Question :  1868년 게이오 4년 8월 19일 자정 반류마루가 탈출한 해역은 어디인가?\n",
      "--------------------------------------------------\n",
      "Context :  1868년 게이오 4년 4월 11일 에도 성 무혈 개성을 한 이후 신정부 군에게 양도가 약속되어 있었다. 그러나 해군 부총재, 에노모토 다케아키가 기상 불량 등을 이유로 이를 연기한 후에 결국 인도를 거부했다. 도쿠가와 요시노부를 슨푸 번에 이송할 때의 태운 함선으로 \n",
      "사용한 후, 8월 19일 자정 (20일)에는 마쓰오카 바키치를 함장으로 카이요마루, 가이텐마루, 신소쿠마루, 간린마루 등과 함께 막부 해군이 정박하고 있던 시나가와 해역을 탈출했다. 그 때 태풍에 휘말려 침몰직전이 되었지만, 1개월만에 에노모토 해군과 합류하였다. 에조\n",
      "치에 건너가 하코다테 전쟁에서는 에노모토(하코다테 정부) 해군의 주력함이 되었다. 영국이 기증했을 때 엠퍼러(Emperor, 기증 당시 일본의 수장은 황제가 아니라 쇼군으로 인식되고 있었기 때문에 장군을 지칭)로 명명하고 있음에서 알 수 있듯이, 쇼군용 유람 요트로 기\n",
      "증되었다고 생각되지만, 세상이 그것을 허락하지 않았다. 아이러니하게도, 군함에 통합되어 실제로 쇼군이 첫 좌승한 것이 대정봉환 이후 슨푸 번에 이송되었을 때였다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "시 ##나 ##가와 해 ##역 \n",
      "\n",
      "Untokenized Answer :  시나가와 해역\n",
      "\n",
      "real answer :  [{'text': '시나가와', 'answer_start': 237}]\n",
      "\n",
      "Question :  헤이그의 부인은 누구인가?\n",
      "--------------------------------------------------\n",
      "Context :  노터데임 대학교에서 2년간 합리적으로 심각한 공부를 한 후 헤이그는 1944년 미국 육군사관학교로 임명을 획득하여 자신의 어린 시절을 군사 경력의 야망으로 알아챘다. 그 경력은 헤이그의 학문적 경연이 암시하려고 한것보다 더욱 극적이었으며 그는 1947년 310의 동기병\n",
      "에서 217번째 사관으로서 졸업하였다. 22세의 소위로 헤이그는 처음에 캔자스 주 포트라일리에서 정통 제병 연합부대로, 그러고나서 켄터키 주 포트녹스에 있는 기갑 훈련소로 갔다. 그후에 그는 제1 기병 사단으로 선임되고 그러고나서 일본에서 점령군의 임무와 기력이 없는 \n",
      "훈련을 하였다. 그는 1950년 5월 한번 자신의 사령관 알론조 폭스 장군의 딸 퍼트리샤 앤토이넷 폭스와 결혼하여 슬하 3명의 자식을 두었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "퍼 ##트 ##리 ##샤 앤 ##토 ##이 ##넷 폭 ##스 \n",
      "\n",
      "Untokenized Answer :  퍼트리샤 앤토이넷 폭스\n",
      "\n",
      "real answer :  [{'text': '퍼트리샤 앤토이넷 폭스', 'answer_start': 345}]\n",
      "\n",
      "Question :  임종석을 검거한 장소는 경희대 내 어디인가?\n",
      "--------------------------------------------------\n",
      "Context :  1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률위반)으로 지명수배되었다. 1989년 3월 12일 서울지방검찰청 공안부는 임종석의 사전구속영장을 발부받았다. 같은 해 6월 30일 평양축전에 임수경을 대표로 파견하여 국가보안법위반 혐의가\n",
      " 추가되었다. 경찰은 12월 18일~20일 사이 서울 경희대학교에서 임종석이 성명 발표를 추진하고 있다는 첩보를 입수했고, 12월 18일 오전 7시 40분 경 가스총과 전자봉으로 무장한 특공조 및 대공과 직원 12명 등 22명의 사복 경찰을 승용차 8대에 나누어 경희대\n",
      "학교에 투입했다. 1989년 12월 18일 오전 8시 15분 경 서울청량리경찰서는 호위 학생 5명과 함께 경희대학교 학생회관 건물 계단을 내려오는 임종석을 발견, 검거해 구속을 집행했다. 임종석은 청량리경찰서에서 약 1시간 동안 조사를 받은 뒤 오전 9시 50분 경 서\n",
      "울 장안동의 서울지방경찰청 공안분실로 인계되었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "경 ##희 ##대학교 학 ##생 ##회 ##관 \n",
      "\n",
      "Untokenized Answer :  경희대학교 학생회관\n",
      "\n",
      "real answer :  [{'text': '학생회관 건물 계단', 'answer_start': 365}]\n",
      "\n",
      "Question :  1989년 6월 30일 평양축전에 대표로 파견 된 인물은?\n",
      "--------------------------------------------------\n",
      "Context :  1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률위반)으로 지명수배되었다. 1989년 3월 12일 서울지방검찰청 공안부는 임종석의 사전구속영장을 발부받았다. 같은 해 6월 30일 평양축전에 임수경을 대표로 파견하여 국가보안법위반 혐의가\n",
      " 추가되었다. 경찰은 12월 18일~20일 사이 서울 경희대학교에서 임종석이 성명 발표를 추진하고 있다는 첩보를 입수했고, 12월 18일 오전 7시 40분 경 가스총과 전자봉으로 무장한 특공조 및 대공과 직원 12명 등 22명의 사복 경찰을 승용차 8대에 나누어 경희대\n",
      "학교에 투입했다. 1989년 12월 18일 오전 8시 15분 경 서울청량리경찰서는 호위 학생 5명과 함께 경희대학교 학생회관 건물 계단을 내려오는 임종석을 발견, 검거해 구속을 집행했다. 임종석은 청량리경찰서에서 약 1시간 동안 조사를 받은 뒤 오전 9시 50분 경 서\n",
      "울 장안동의 서울지방경찰청 공안분실로 인계되었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "임 ##수 ##경 \n",
      "\n",
      "Untokenized Answer :  임수경\n",
      "\n",
      "real answer :  [{'text': '임수경', 'answer_start': 125}]\n",
      "\n",
      "Question :  노아의 방주의 실존에 대한 의문이 제기되고 세계적 홍수가 없었다는 것이 밝혀지게된 이유는?\n",
      "--------------------------------------------------\n",
      "Context :  역사학과 과학이 발달하지 않았던 과거 전통 신학계에서는 근본주의적 시각을 받아들여 노아의 방주를 역사적 사실로 기술하려 했으며, 이러한 관점은 아직도 과학과 역사학에 어두운 보수적 근본주의계열의 개신교에서만 받아들여지고 있다. 하지만 역사학과 과학의 발달로 인해, 노아\n",
      "의 방주의 실존에 대한 의문이 제기가 되고, 세계적 홍수가 존재할 수 없음이 밝혀짐에 따라 현대 신학계에서는 비록 노아의 홍수가 과학적으로 실존하지는 않았지만 그 자체의 의미는 신학적으로 매우 중요하며, 이에 대한 해석은 다양하게 이루어지고 있으며, 대부분의 기독교(가\n",
      "톨릭, 개신교를 포함한 대부분)에서는 노아의 방주는 상징적 의미로 받아들여진다. 그러므로 과학과는 상관없이 신학적으로 노아의 방주 자체의 의미는 중요하게 해석된다고 한다\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "역 ##사 ##학과 과 ##학 ##의 발 ##달 \n",
      "\n",
      "Untokenized Answer :  역사학과 과학의 발달\n",
      "\n",
      "real answer :  [{'text': '역사학과 과학의 발달', 'answer_start': 131}]\n",
      "\n",
      "Question :  헤이그가 정계로 돌아간 년도는 몇년도입니까?\n",
      "--------------------------------------------------\n",
      "Context :  그의 편에 헤이그는 지구촌의 논점들의 국내적 정치 노력들에 관해서만 근심한 레이건의 가까운 조언자들을 \"외교 정책의 아마추어\"로 묘사하였다. 1982년 6월 25일 결국적으로 온 그의 국무장관으로서 사임은 불가능한 상황이 된 것을 끝냈다. 헤이그는 개인적 생활로 돌아갔\n",
      "다가 1988년 대통령 선거를 위한 공화당 후보직을 안정시키는 시도를 하는 데 충분하게 정계로 돌아갔으나 후보직을 이기는 데 성원을 가지지 않았다. 그는 외교 정책 논쟁들에 연설자로서 활동적으로 남아있었으나 그의 전념은 정치에서 개인적 생활로 옮겨졌다. 그는 World\n",
      "wide Associates Inc.의 국제적 상담 회사에 의하여 기용되었고, 그 기구의 의장과 회장이 되었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "1988년 \n",
      "\n",
      "Untokenized Answer :  1988년\n",
      "\n",
      "real answer :  [{'text': '1988년', 'answer_start': 153}]\n",
      "\n",
      "Question :  노아의 홍수가 실재한다면 진화적 종분화가 얼마 만에 이루어져야하는가?\n",
      "--------------------------------------------------\n",
      "Context :  기독교 성경 내용에는 모든 종들을 방주에 태운다고 이야기하고 있으나, 어류나 수중 생물에 대해서는 언급하지 않았다. 이것을 신학적 의미로만 받아들이면 괜찮은 문제이나, 이 현상이 실제로 일어났다고 가정할 경우,이는 종 간 생존 환경의 차이에 대해서 간과하고 있다. 수중\n",
      " 생물이라 하더라도 종에 따라 생존할 수 있는 환경은 각각 다른 것이며, 40일 이내에 현존하는 가장 높은 산인 에베레스트 산도 잠기게 할 정도의 폭우로 인해 담수와 염수가 급작스럽게 섞일 경우, 급격한 삼투압 변화로 인해 대부분의 수생생물들이 폐사하게 되며, 결과적으\n",
      "로 육지 뿐 아니라 바다와 강의 모든 생태계가 파괴된다. 이후 5천년이라는 지극히 짧은 세월 동안 지구상의 동식물이 모두 페름기 대멸종 또는 K-T 대멸종에 준하는 대량절멸에 가까운 상태에서부터 시작하여 현재의 대략 870만(±120만)종에 달하는 생물다양성을 획득하려\n",
      "면 모든 생물들이 각 세대마다 종분화가 일어나야 할 만큼 엄청난 속도로 진화 및 번식이 (멸종 없이) 이루어져야만 가능한 일이다. (이와 관련하여 창조과학회 측에서는 북극곰의 예시를 통해 가지고 있던 특성이 없어지는 것이 진화가 아니라고 주장하지만, 통상적으로 알려진 \n",
      "바와 같이 생물학에서는 이미 존재하는 특성이 없어지는 현상, 즉 퇴화 역시 진화의 정의에 포함된다.) 즉, 노아의 홍수가 실재하는 사건이었다면 진화적 종분화가 현재까지 알려진 것과 비교할 수 없이 엄청난 속도로 이루어져야만 현재 지구의 생물다양성을 설명할 수 있다. 게\n",
      "다가 이것은 현재의 생물종 멸종 속도를 전혀 고려하지 않았다. 다시 말해, 노아의 홍수가 실재하는 전지구적인 사건이기 위해서는 최소 캄브리아기 대폭발 수준의 폭발적인 진화적 종분화가 1-2억년이 아니라 최대 3-4천년 이내에 이루어졌어야만 현생 지구의 생물다양성에 대한\n",
      " 설명이 가능해진다. 그보다 더 중요한 것은, 각 동물들이 차지하는 영역과 먹이사슬에서의 위치, 375일 동안 먹이도 없이 밀폐된 공간으로 인해 받을 스트레스 등 생태적 지위에 대한 고려가 전혀 없다는 점이다. 또한 바다에서 생존이 불가능한 생물종까지 숫자에 포함되었다\n",
      "는 점에서 논란이 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "870 ##만 \n",
      "\n",
      "Untokenized Answer :  870만\n",
      "\n",
      "real answer :  [{'text': '3-4천년', 'answer_start': 866}]\n",
      "\n",
      "Question :  노아의 방주는 무엇으로 만들었기 때문에 현재까지 남아 있는 것이 불가능한가?\n",
      "--------------------------------------------------\n",
      "Context :  일반적으로 터키의 아라랏 산의 경우, 실제 성경 속에 등장하는 아라랏 산은 지금 아라랏이라 불리는 하나의 산이 아니라 당시 아라랏이라고 불리던 광대한 지역의 산들을 모두 가리키는 표현이라는 주장도 나와 있으며, 또한 목재로 만들어진 방주가 현재까지 남아있을 수는 없다는\n",
      " 비판도 받고 있다. 예를 들어, 1955년 프랑스의 탐험가인 Fernand Navarra가 발견한 목재 파편의 경우, 스페인의 임업 연구소에서 목재의 특성을 토대로 5000년 전의 것이라고 밝히긴 했으나 그 신빙성에 문제점이 있었고 후에 방사성 동위원소 측정법 등의 \n",
      "첨단 과학의 도움을 받은 5개 연구소에서 모두 기원 이후의 시기로 연대를 측정했다. 2009년 뿐 아니라 거의 수년에 한번씩 어디선가 노아의 방주를 발견했다는 주장들이 제시되었지만, 심지어 같은 창조과학을 주장하는 사람들에게조차 비판받을 정도였다. 노아의 방주가 다른 \n",
      "여러 지방에서 발견되었다는 주장이 있으나 너무나 다양한 지방(중국, 터키, 인도 등)에 걸쳐있고, 그 주장도 각각 제각각이므로 신빙성이 없다. 예를 들자면, 중국 BTV에서는 2012년에 중국에서 노아의 방주가 발견되었다는 보도를 하였는데, 이것은 창조과학회에서 주장하\n",
      "는 장소와는 전혀 다른곳이기도 하며, 화석화가 진행되지 않은 나무의 존재등으로 가짜임이 밝혀졌다. 때때로 일부 \"학자\"라 칭하는 사람들이 이를 찾기 위해 노력한다고 주장하지만, 이는 학계에서 유사지질학으로 평가되고 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "목 ##재 \n",
      "\n",
      "Untokenized Answer :  목재\n",
      "\n",
      "real answer :  [{'text': '목재', 'answer_start': 121}]\n",
      "\n",
      "Question :  임종석이 1989년 2월 15일에 지명수배 받은 혐의는 어떤 시위를 주도했다는 것인가?\n",
      "--------------------------------------------------\n",
      "Context :  1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률위반)으로 지명수배되었다. 1989년 3월 12일 서울지방검찰청 공안부는 임종석의 사전구속영장을 발부받았다. 같은 해 6월 30일 평양축전에 임수경을 대표로 파견하여 국가보안법위반 혐의가\n",
      " 추가되었다. 경찰은 12월 18일~20일 사이 서울 경희대학교에서 임종석이 성명 발표를 추진하고 있다는 첩보를 입수했고, 12월 18일 오전 7시 40분 경 가스총과 전자봉으로 무장한 특공조 및 대공과 직원 12명 등 22명의 사복 경찰을 승용차 8대에 나누어 경희대\n",
      "학교에 투입했다. 1989년 12월 18일 오전 8시 15분 경 서울청량리경찰서는 호위 학생 5명과 함께 경희대학교 학생회관 건물 계단을 내려오는 임종석을 발견, 검거해 구속을 집행했다. 임종석은 청량리경찰서에서 약 1시간 동안 조사를 받은 뒤 오전 9시 50분 경 서\n",
      "울 장안동의 서울지방경찰청 공안분실로 인계되었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "여 ##의 ##도 농 ##민 폭 ##력 \n",
      "\n",
      "Untokenized Answer :  여의도 농민 폭력\n",
      "\n",
      "real answer :  [{'text': '여의도 농민 폭력 시위', 'answer_start': 13}]\n",
      "\n",
      "Question :  알렉산더 헤이그를 사성 장군과 육군 부참모로 진급시킨 대통령은 누구인가?\n",
      "--------------------------------------------------\n",
      "Context :  헤이그는 닉슨 대통령이 그를 사성 장군과 육군 부참모로 진급시킬 때 집중 광선과 논쟁으로 들어갔다. 헤이그를 군사의 최상으로 밀어넣은 닉슨의 행동은 대통령의 남자들을 다양한 연방 대리법에서 권한의 직우들로 놓은 노력과 함께 일치였다. 하지만 그는 곧 백악관으로 돌아가 \n",
      "1973년부터 1974년까지 대통령 특별 보좌관을 지냈다. 워터게이트 사건이 일어난지 한달 후, 헤이그는 포위된 닉슨 대통령을 위한 치명적 역할을 하였다. 그일은 8월 닉슨의 사임과 제럴드 포드의 대통령으로 계승으로 이끈 협상들에서 헤이그가 수단이었던 우연이 아니었다.\n",
      " 곧 후에 헤이그는 미국 유럽 연합군 최고사령부의 최고 사령관으로 임명되었다. 그는 나토에서 다음 5년을 보내고 1979년 군에서 퇴역하여 미국 기술 주식 회사의 우두머리가 되었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "닉 ##슨 \n",
      "\n",
      "Untokenized Answer :  닉슨\n",
      "\n",
      "real answer :  [{'text': '닉슨 대통령', 'answer_start': 5}]\n",
      "\n",
      "Question :  마쓰오카 바키치함장의 능력과 지휘과 기록된 기록되어 남은 전쟁은?\n",
      "--------------------------------------------------\n",
      "Context :  일련의 하코다테 전쟁은 적아 쌍방의 문서에 마쓰오카 바키치 함장의 능란한 조함 능력과 냉정한 지휘만이 기록되어 있다. 함포 사격으로 마쓰마에 성을 공격하여 엄호한 이후, 1869년 메이지 2년 3월 25일 미야코 만 해전에서는 폭풍우를 만나 요함과 헤어졌을 때에 만날 \n",
      "약속했던 하치노헤 항에서 대기하고 있었기 때문에 참전에는 이르지 못했다. 이 폭풍우 때도 “함장 마쓰오카 바키치는 배를 조정하는 명수로 로프 하나 손상되지 않았다”고 타고 있던 하야시 다다스가 남긴 바 있다. 이 귀로에서 신정부 군의 철갑함의 추격을 받았다. 기관 능력\n",
      "의 차이로 인한 속도차 때문에 도주가 불가능하다고 판단하고 맞장 공격을 하겠다고 전투 준비를 했지만, 철갑선의 사정거리에 들어간 순간에 순풍이 불기 시작하여 추격을 뿌리치고 하코다테로 돌아올 수 있었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "하 ##코 ##다 ##테 전쟁 \n",
      "\n",
      "Untokenized Answer :  하코다테 전쟁\n",
      "\n",
      "real answer :  [{'text': '하코다테 전쟁', 'answer_start': 4}]\n",
      "\n",
      "Question :  제럴드 포드 대통령 시기 헤이그가 최고사령부의 최고 사령관으로 임명된 곳은 어디인가?\n",
      "--------------------------------------------------\n",
      "Context :  헤이그는 닉슨 대통령이 그를 사성 장군과 육군 부참모로 진급시킬 때 집중 광선과 논쟁으로 들어갔다. 헤이그를 군사의 최상으로 밀어넣은 닉슨의 행동은 대통령의 남자들을 다양한 연방 대리법에서 권한의 직우들로 놓은 노력과 함께 일치였다. 하지만 그는 곧 백악관으로 돌아가 \n",
      "1973년부터 1974년까지 대통령 특별 보좌관을 지냈다. 워터게이트 사건이 일어난지 한달 후, 헤이그는 포위된 닉슨 대통령을 위한 치명적 역할을 하였다. 그일은 8월 닉슨의 사임과 제럴드 포드의 대통령으로 계승으로 이끈 협상들에서 헤이그가 수단이었던 우연이 아니었다.\n",
      " 곧 후에 헤이그는 미국 유럽 연합군 최고사령부의 최고 사령관으로 임명되었다. 그는 나토에서 다음 5년을 보내고 1979년 군에서 퇴역하여 미국 기술 주식 회사의 우두머리가 되었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "미국 유럽 연 ##합 ##군 \n",
      "\n",
      "Untokenized Answer :  미국 유럽 연합군\n",
      "\n",
      "real answer :  [{'text': '미국 유럽 연합군', 'answer_start': 311}]\n",
      "\n",
      "Question :  1868년 게이오 4년 4월 11일 신정부 군에게 양도되기로 한 반류마루를 기상 불량 등의 이유로 연기한 후 인도를 거부한 사람은 누구인가?\n",
      "--------------------------------------------------\n",
      "Context :  1868년 게이오 4년 4월 11일 에도 성 무혈 개성을 한 이후 신정부 군에게 양도가 약속되어 있었다. 그러나 해군 부총재, 에노모토 다케아키가 기상 불량 등을 이유로 이를 연기한 후에 결국 인도를 거부했다. 도쿠가와 요시노부를 슨푸 번에 이송할 때의 태운 함선으로 \n",
      "사용한 후, 8월 19일 자정 (20일)에는 마쓰오카 바키치를 함장으로 카이요마루, 가이텐마루, 신소쿠마루, 간린마루 등과 함께 막부 해군이 정박하고 있던 시나가와 해역을 탈출했다. 그 때 태풍에 휘말려 침몰직전이 되었지만, 1개월만에 에노모토 해군과 합류하였다. 에조\n",
      "치에 건너가 하코다테 전쟁에서는 에노모토(하코다테 정부) 해군의 주력함이 되었다. 영국이 기증했을 때 엠퍼러(Emperor, 기증 당시 일본의 수장은 황제가 아니라 쇼군으로 인식되고 있었기 때문에 장군을 지칭)로 명명하고 있음에서 알 수 있듯이, 쇼군용 유람 요트로 기\n",
      "증되었다고 생각되지만, 세상이 그것을 허락하지 않았다. 아이러니하게도, 군함에 통합되어 실제로 쇼군이 첫 좌승한 것이 대정봉환 이후 슨푸 번에 이송되었을 때였다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "에 ##노 ##모토 다 ##케 ##아 ##키 \n",
      "\n",
      "Untokenized Answer :  에노모토 다케아키\n",
      "\n",
      "real answer :  [{'text': '에노모토 다케아키', 'answer_start': 71}]\n",
      "\n",
      "Question :  현대 대부분의 기독교에서는 노아의 방주를 어떤 의미로 받아들이는가?\n",
      "--------------------------------------------------\n",
      "Context :  역사학과 과학이 발달하지 않았던 과거 전통 신학계에서는 근본주의적 시각을 받아들여 노아의 방주를 역사적 사실로 기술하려 했으며, 이러한 관점은 아직도 과학과 역사학에 어두운 보수적 근본주의계열의 개신교에서만 받아들여지고 있다. 하지만 역사학과 과학의 발달로 인해, 노아\n",
      "의 방주의 실존에 대한 의문이 제기가 되고, 세계적 홍수가 존재할 수 없음이 밝혀짐에 따라 현대 신학계에서는 비록 노아의 홍수가 과학적으로 실존하지는 않았지만 그 자체의 의미는 신학적으로 매우 중요하며, 이에 대한 해석은 다양하게 이루어지고 있으며, 대부분의 기독교(가\n",
      "톨릭, 개신교를 포함한 대부분)에서는 노아의 방주는 상징적 의미로 받아들여진다. 그러므로 과학과는 상관없이 신학적으로 노아의 방주 자체의 의미는 중요하게 해석된다고 한다\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상 ##징 ##적 의 ##미 \n",
      "\n",
      "Untokenized Answer :  상징적 의미\n",
      "\n",
      "real answer :  [{'text': '상징적 의미', 'answer_start': 329}]\n",
      "\n",
      "Question :  1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의로 지명수배된 사람의 이름은?\n",
      "--------------------------------------------------\n",
      "Context :  1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률위반)으로 지명수배되었다. 1989년 3월 12일 서울지방검찰청 공안부는 임종석의 사전구속영장을 발부받았다. 같은 해 6월 30일 평양축전에 임수경을 대표로 파견하여 국가보안법위반 혐의가\n",
      " 추가되었다. 경찰은 12월 18일~20일 사이 서울 경희대학교에서 임종석이 성명 발표를 추진하고 있다는 첩보를 입수했고, 12월 18일 오전 7시 40분 경 가스총과 전자봉으로 무장한 특공조 및 대공과 직원 12명 등 22명의 사복 경찰을 승용차 8대에 나누어 경희대\n",
      "학교에 투입했다. 1989년 12월 18일 오전 8시 15분 경 서울청량리경찰서는 호위 학생 5명과 함께 경희대학교 학생회관 건물 계단을 내려오는 임종석을 발견, 검거해 구속을 집행했다. 임종석은 청량리경찰서에서 약 1시간 동안 조사를 받은 뒤 오전 9시 50분 경 서\n",
      "울 장안동의 서울지방경찰청 공안분실로 인계되었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "\n",
      "\n",
      "Untokenized Answer : \n",
      "\n",
      "real answer :  [{'text': '임종석', 'answer_start': 87}]\n",
      "\n",
      "Question :  노아의 방주를 만든 재질은?\n",
      "--------------------------------------------------\n",
      "Context :  노아는 하나님의 명령에 따라 배를 만들고 가족과 정결한 짐승 암수 일곱 마리씩, 부정한 짐승 암수 한 마리씩(혹은 두 마리씩; 사본에 따라 다름), 그리고 새 암수 일곱 마리씩을 싣고 밀어닥친 홍수를 피하였다. 모든 사람들이 타락한 생활에 빠져 있어 하나님이 홍수로 심\n",
      "판하려 할 때 홀로 바르게 살던 노아는 하나님의 특별한 계시로 홍수가 올 것을 미리 알게 된다. 그는 길이 300 규빗, 너비 50 규빗, 높이 30 규빗(고대의 1규빗은 팔꿈치에서 가운데 손가락끝까지의 길이로 약 45~46cm를 가리킴), 상 ·중 ·하 3층으로 된 \n",
      "방주를 만들어 8명의 가족과, 한 쌍씩의 여러 동물을 데리고 이 방주에 탄다. 대홍수를 만나 모든 생물(물고기 제외)이 전멸하고 말았지만, 이 방주에 탔던 노아의 가족과 동물들은 살아 남았다고 한다.〈창세기〉 6장 14~16절에 보면 길이 300규빗 (약 135m), \n",
      "폭 50 규빗 (약 22.5m), 높이 30 규빗 (약 13.5m)인 이 배는 지붕과 문을 달고 배 안은 3층으로 만들어져 있었다. 선체(船體)는 고페르나무(잣나무)로 되고 안쪽에는 역청(아스팔트와 비슷한 성분)을 칠하여 굳혔다고 기록하고 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "고 ##페 ##르 ##나 ##무 \n",
      "\n",
      "Untokenized Answer :  고페르나무\n",
      "\n",
      "real answer :  [{'text': '고페르나무(잣나무)', 'answer_start': 532}]\n",
      "\n",
      "Question :  노아는 누구의 명령에 따라 배를 만들고 가족과 동물들을 태웠는가?\n",
      "--------------------------------------------------\n",
      "Context :  노아는 하나님의 명령에 따라 배를 만들고 가족과 정결한 짐승 암수 일곱 마리씩, 부정한 짐승 암수 한 마리씩(혹은 두 마리씩; 사본에 따라 다름), 그리고 새 암수 일곱 마리씩을 싣고 밀어닥친 홍수를 피하였다. 모든 사람들이 타락한 생활에 빠져 있어 하나님이 홍수로 심\n",
      "판하려 할 때 홀로 바르게 살던 노아는 하나님의 특별한 계시로 홍수가 올 것을 미리 알게 된다. 그는 길이 300 규빗, 너비 50 규빗, 높이 30 규빗(고대의 1규빗은 팔꿈치에서 가운데 손가락끝까지의 길이로 약 45~46cm를 가리킴), 상 ·중 ·하 3층으로 된 \n",
      "방주를 만들어 8명의 가족과, 한 쌍씩의 여러 동물을 데리고 이 방주에 탄다. 대홍수를 만나 모든 생물(물고기 제외)이 전멸하고 말았지만, 이 방주에 탔던 노아의 가족과 동물들은 살아 남았다고 한다.〈창세기〉 6장 14~16절에 보면 길이 300규빗 (약 135m), \n",
      "폭 50 규빗 (약 22.5m), 높이 30 규빗 (약 13.5m)인 이 배는 지붕과 문을 달고 배 안은 3층으로 만들어져 있었다. 선체(船體)는 고페르나무(잣나무)로 되고 안쪽에는 역청(아스팔트와 비슷한 성분)을 칠하여 굳혔다고 기록하고 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "하 ##나 ##님 \n",
      "\n",
      "Untokenized Answer :  하나님\n",
      "\n",
      "real answer :  [{'text': '하나님', 'answer_start': 4}]\n",
      "\n",
      "Question :  '행보가 비서 본연의 역할을 벗어난다', '장관들과 내각이 소외되고 대통령비서실의 권한이 너무 크다'는 의견이 제기된 대표적인 예는?\n",
      "--------------------------------------------------\n",
      "Context :  \"내각과 장관들이 소외되고 대통령비서실의 권한이 너무 크다\", \"행보가 비서 본연의 역할을 벗어난다\"는 의견이 제기되었다. 대표적인 예가 10차 개헌안 발표이다. 원로 헌법학자인 허영 경희대 석좌교수는 정부의 헌법개정안 준비 과정에 대해 \"청와대 비서실이 아닌 국무회의\n",
      " 중심으로 이뤄졌어야 했다\"고 지적했다. '국무회의의 심의를 거쳐야 한다'(제89조)는 헌법 규정에 충실하지 않았다는 것이다. 그러면서 \"법무부 장관을 제쳐놓고 민정수석이 개정안을 설명하는 게 이해가 안 된다\"고 지적했다. 민정수석은 국회의원에 대해 책임지는 법무부 장\n",
      "관도 아니고, 국민에 대해 책임지는 사람도 아니기 때문에 정당성이 없고, 단지 대통령의 신임이 있을 뿐이라는 것이다. 또한 국무총리 선출 방식에 대한 기자의 질문에 \"문 대통령도 취임 전에 국무총리에게 실질적 권한을 주겠다고 했지만 그러지 못하고 있다. 대통령비서실장만\n",
      "도 못한 권한을 행사하고 있다.\"고 답변했다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "10 ##차 개 ##헌 ##안 발 ##표 \n",
      "\n",
      "Untokenized Answer :  10차 개헌안 발표\n",
      "\n",
      "real answer :  [{'text': '10차 개헌안 발표', 'answer_start': 77}]\n",
      "\n",
      "Question :  임종석이 여의도 농민 폭력 시위를 주도한 혐의로 지명수배된 연도는?\n",
      "--------------------------------------------------\n",
      "Context :  1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률위반)으로 지명수배되었다. 1989년 3월 12일 서울지방검찰청 공안부는 임종석의 사전구속영장을 발부받았다. 같은 해 6월 30일 평양축전에 임수경을 대표로 파견하여 국가보안법위반 혐의가\n",
      " 추가되었다. 경찰은 12월 18일~20일 사이 서울 경희대학교에서 임종석이 성명 발표를 추진하고 있다는 첩보를 입수했고, 12월 18일 오전 7시 40분 경 가스총과 전자봉으로 무장한 특공조 및 대공과 직원 12명 등 22명의 사복 경찰을 승용차 8대에 나누어 경희대\n",
      "학교에 투입했다. 1989년 12월 18일 오전 8시 15분 경 서울청량리경찰서는 호위 학생 5명과 함께 경희대학교 학생회관 건물 계단을 내려오는 임종석을 발견, 검거해 구속을 집행했다. 임종석은 청량리경찰서에서 약 1시간 동안 조사를 받은 뒤 오전 9시 50분 경 서\n",
      "울 장안동의 서울지방경찰청 공안분실로 인계되었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "1989년 \n",
      "\n",
      "Untokenized Answer :  1989년\n",
      "\n",
      "real answer :  [{'text': '1989년', 'answer_start': 0}]\n",
      "\n",
      "Question :  헤이그가 군에서 퇴역한 해는 언제인가?\n",
      "--------------------------------------------------\n",
      "Context :  헤이그는 닉슨 대통령이 그를 사성 장군과 육군 부참모로 진급시킬 때 집중 광선과 논쟁으로 들어갔다. 헤이그를 군사의 최상으로 밀어넣은 닉슨의 행동은 대통령의 남자들을 다양한 연방 대리법에서 권한의 직우들로 놓은 노력과 함께 일치였다. 하지만 그는 곧 백악관으로 돌아가 \n",
      "1973년부터 1974년까지 대통령 특별 보좌관을 지냈다. 워터게이트 사건이 일어난지 한달 후, 헤이그는 포위된 닉슨 대통령을 위한 치명적 역할을 하였다. 그일은 8월 닉슨의 사임과 제럴드 포드의 대통령으로 계승으로 이끈 협상들에서 헤이그가 수단이었던 우연이 아니었다.\n",
      " 곧 후에 헤이그는 미국 유럽 연합군 최고사령부의 최고 사령관으로 임명되었다. 그는 나토에서 다음 5년을 보내고 1979년 군에서 퇴역하여 미국 기술 주식 회사의 우두머리가 되었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "1979 ##년 \n",
      "\n",
      "Untokenized Answer :  1979년\n",
      "\n",
      "real answer :  [{'text': '1979년', 'answer_start': 363}]\n",
      "\n",
      "Question :  노아의 방주가 역사적으로 실재했다는 주장은 무엇이 존재하지 않아 학계로부터 전혀 인정받지 못하고 있는가?\n",
      "--------------------------------------------------\n",
      "Context :  물론 노아의 방주가 신학과 신앙에서 중요한 영향을 차지하는 것은 사실이나, 현재 노아의 방주가 역사적으로 실존한다는 주장은 그 증거가 존재하지 않기에 관련 학계로부터 전혀 인정받지 못하고 있으며 그 실존과 안정성에 대한 수많은 논란이 있다. 한국창조과학회 등에서는 제칠\n",
      "일안식교를 기반으로 한 홍수지질학적 주장들을을 내어 놓고 있지만, 사실과 다른 근거들을 바탕으로 주장하므로 신뢰하기 힘든 것들이 전부라 할 수 있다. 그러므로 현재 노아의 방주가 실존한다는 주장은 그 증거가 존재하지 않기에 관련 학계로부터 전혀 인정받지 못하고 있다. \n",
      "모든 과학관련 학계에서는 노아의 방주의 구조나 재질등이 실제로 존재할 수 없는 설화속 이야기라는 데에 동의하고 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "증 ##거 \n",
      "\n",
      "Untokenized Answer :  증거\n",
      "\n",
      "real answer :  [{'text': '증거', 'answer_start': 71}]\n",
      "\n",
      "Question :  만약 대홍수가 실재했다면 현생 지구의 생물다양성에 이르기 위해서는 종분화가 몇년 이내에 이루어졌어야 하는가?\n",
      "--------------------------------------------------\n",
      "Context :  기독교 성경 내용에는 모든 종들을 방주에 태운다고 이야기하고 있으나, 어류나 수중 생물에 대해서는 언급하지 않았다. 이것을 신학적 의미로만 받아들이면 괜찮은 문제이나, 이 현상이 실제로 일어났다고 가정할 경우,이는 종 간 생존 환경의 차이에 대해서 간과하고 있다. 수중\n",
      " 생물이라 하더라도 종에 따라 생존할 수 있는 환경은 각각 다른 것이며, 40일 이내에 현존하는 가장 높은 산인 에베레스트 산도 잠기게 할 정도의 폭우로 인해 담수와 염수가 급작스럽게 섞일 경우, 급격한 삼투압 변화로 인해 대부분의 수생생물들이 폐사하게 되며, 결과적으\n",
      "로 육지 뿐 아니라 바다와 강의 모든 생태계가 파괴된다. 이후 5천년이라는 지극히 짧은 세월 동안 지구상의 동식물이 모두 페름기 대멸종 또는 K-T 대멸종에 준하는 대량절멸에 가까운 상태에서부터 시작하여 현재의 대략 870만(±120만)종에 달하는 생물다양성을 획득하려\n",
      "면 모든 생물들이 각 세대마다 종분화가 일어나야 할 만큼 엄청난 속도로 진화 및 번식이 (멸종 없이) 이루어져야만 가능한 일이다. (이와 관련하여 창조과학회 측에서는 북극곰의 예시를 통해 가지고 있던 특성이 없어지는 것이 진화가 아니라고 주장하지만, 통상적으로 알려진 \n",
      "바와 같이 생물학에서는 이미 존재하는 특성이 없어지는 현상, 즉 퇴화 역시 진화의 정의에 포함된다.) 즉, 노아의 홍수가 실재하는 사건이었다면 진화적 종분화가 현재까지 알려진 것과 비교할 수 없이 엄청난 속도로 이루어져야만 현재 지구의 생물다양성을 설명할 수 있다. 게\n",
      "다가 이것은 현재의 생물종 멸종 속도를 전혀 고려하지 않았다. 다시 말해, 노아의 홍수가 실재하는 전지구적인 사건이기 위해서는 최소 캄브리아기 대폭발 수준의 폭발적인 진화적 종분화가 1-2억년이 아니라 최대 3-4천년 이내에 이루어졌어야만 현생 지구의 생물다양성에 대한\n",
      " 설명이 가능해진다. 그보다 더 중요한 것은, 각 동물들이 차지하는 영역과 먹이사슬에서의 위치, 375일 동안 먹이도 없이 밀폐된 공간으로 인해 받을 스트레스 등 생태적 지위에 대한 고려가 전혀 없다는 점이다. 또한 바다에서 생존이 불가능한 생물종까지 숫자에 포함되었다\n",
      "는 점에서 논란이 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "40 ##일 \n",
      "\n",
      "Untokenized Answer :  40일\n",
      "\n",
      "real answer :  [{'text': '3-4천년', 'answer_start': 866}]\n",
      "\n",
      "Question :  현재도 노아의 방주를 역사적 사실로 받아들이는 집단은?\n",
      "--------------------------------------------------\n",
      "Context :  역사학과 과학이 발달하지 않았던 과거 전통 신학계에서는 근본주의적 시각을 받아들여 노아의 방주를 역사적 사실로 기술하려 했으며, 이러한 관점은 아직도 과학과 역사학에 어두운 보수적 근본주의계열의 개신교에서만 받아들여지고 있다. 하지만 역사학과 과학의 발달로 인해, 노아\n",
      "의 방주의 실존에 대한 의문이 제기가 되고, 세계적 홍수가 존재할 수 없음이 밝혀짐에 따라 현대 신학계에서는 비록 노아의 홍수가 과학적으로 실존하지는 않았지만 그 자체의 의미는 신학적으로 매우 중요하며, 이에 대한 해석은 다양하게 이루어지고 있으며, 대부분의 기독교(가\n",
      "톨릭, 개신교를 포함한 대부분)에서는 노아의 방주는 상징적 의미로 받아들여진다. 그러므로 과학과는 상관없이 신학적으로 노아의 방주 자체의 의미는 중요하게 해석된다고 한다\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "개 ##신 ##교 \n",
      "\n",
      "Untokenized Answer :  개신교\n",
      "\n",
      "real answer :  [{'text': '보수적 근본주의계열의 개신교', 'answer_start': 97}]\n",
      "\n",
      "Question :  1955년 프랑스 탐험가가 발견한 목재파편은 스페인 연구소에서 몇 년 전 것이라고 밝혀졌는가?\n",
      "--------------------------------------------------\n",
      "Context :  일반적으로 터키의 아라랏 산의 경우, 실제 성경 속에 등장하는 아라랏 산은 지금 아라랏이라 불리는 하나의 산이 아니라 당시 아라랏이라고 불리던 광대한 지역의 산들을 모두 가리키는 표현이라는 주장도 나와 있으며, 또한 목재로 만들어진 방주가 현재까지 남아있을 수는 없다는\n",
      " 비판도 받고 있다. 예를 들어, 1955년 프랑스의 탐험가인 Fernand Navarra가 발견한 목재 파편의 경우, 스페인의 임업 연구소에서 목재의 특성을 토대로 5000년 전의 것이라고 밝히긴 했으나 그 신빙성에 문제점이 있었고 후에 방사성 동위원소 측정법 등의 \n",
      "첨단 과학의 도움을 받은 5개 연구소에서 모두 기원 이후의 시기로 연대를 측정했다. 2009년 뿐 아니라 거의 수년에 한번씩 어디선가 노아의 방주를 발견했다는 주장들이 제시되었지만, 심지어 같은 창조과학을 주장하는 사람들에게조차 비판받을 정도였다. 노아의 방주가 다른 \n",
      "여러 지방에서 발견되었다는 주장이 있으나 너무나 다양한 지방(중국, 터키, 인도 등)에 걸쳐있고, 그 주장도 각각 제각각이므로 신빙성이 없다. 예를 들자면, 중국 BTV에서는 2012년에 중국에서 노아의 방주가 발견되었다는 보도를 하였는데, 이것은 창조과학회에서 주장하\n",
      "는 장소와는 전혀 다른곳이기도 하며, 화석화가 진행되지 않은 나무의 존재등으로 가짜임이 밝혀졌다. 때때로 일부 \"학자\"라 칭하는 사람들이 이를 찾기 위해 노력한다고 주장하지만, 이는 학계에서 유사지질학으로 평가되고 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "5000 ##년 \n",
      "\n",
      "Untokenized Answer :  5000년\n",
      "\n",
      "real answer :  [{'text': '5000년 전', 'answer_start': 243}]\n",
      "\n",
      "Question :  노아의 방주를 상징적 의미로 받아들이는 종교는 무엇인가?\n",
      "--------------------------------------------------\n",
      "Context :  역사학과 과학이 발달하지 않았던 과거 전통 신학계에서는 근본주의적 시각을 받아들여 노아의 방주를 역사적 사실로 기술하려 했으며, 이러한 관점은 아직도 과학과 역사학에 어두운 보수적 근본주의계열의 개신교에서만 받아들여지고 있다. 하지만 역사학과 과학의 발달로 인해, 노아\n",
      "의 방주의 실존에 대한 의문이 제기가 되고, 세계적 홍수가 존재할 수 없음이 밝혀짐에 따라 현대 신학계에서는 비록 노아의 홍수가 과학적으로 실존하지는 않았지만 그 자체의 의미는 신학적으로 매우 중요하며, 이에 대한 해석은 다양하게 이루어지고 있으며, 대부분의 기독교(가\n",
      "톨릭, 개신교를 포함한 대부분)에서는 노아의 방주는 상징적 의미로 받아들여진다. 그러므로 과학과는 상관없이 신학적으로 노아의 방주 자체의 의미는 중요하게 해석된다고 한다\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "기 ##독 ##교 \n",
      "\n",
      "Untokenized Answer :  기독교\n",
      "\n",
      "real answer :  [{'text': '기독교', 'answer_start': 295}]\n",
      "\n",
      "Question :  노아의 방주의 선체는 어떠한 나무로 만들었는가?\n",
      "--------------------------------------------------\n",
      "Context :  노아는 하나님의 명령에 따라 배를 만들고 가족과 정결한 짐승 암수 일곱 마리씩, 부정한 짐승 암수 한 마리씩(혹은 두 마리씩; 사본에 따라 다름), 그리고 새 암수 일곱 마리씩을 싣고 밀어닥친 홍수를 피하였다. 모든 사람들이 타락한 생활에 빠져 있어 하나님이 홍수로 심\n",
      "판하려 할 때 홀로 바르게 살던 노아는 하나님의 특별한 계시로 홍수가 올 것을 미리 알게 된다. 그는 길이 300 규빗, 너비 50 규빗, 높이 30 규빗(고대의 1규빗은 팔꿈치에서 가운데 손가락끝까지의 길이로 약 45~46cm를 가리킴), 상 ·중 ·하 3층으로 된 \n",
      "방주를 만들어 8명의 가족과, 한 쌍씩의 여러 동물을 데리고 이 방주에 탄다. 대홍수를 만나 모든 생물(물고기 제외)이 전멸하고 말았지만, 이 방주에 탔던 노아의 가족과 동물들은 살아 남았다고 한다.〈창세기〉 6장 14~16절에 보면 길이 300규빗 (약 135m), \n",
      "폭 50 규빗 (약 22.5m), 높이 30 규빗 (약 13.5m)인 이 배는 지붕과 문을 달고 배 안은 3층으로 만들어져 있었다. 선체(船體)는 고페르나무(잣나무)로 되고 안쪽에는 역청(아스팔트와 비슷한 성분)을 칠하여 굳혔다고 기록하고 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "고 ##페 ##르 ##나 ##무 \n",
      "\n",
      "Untokenized Answer :  고페르나무\n",
      "\n",
      "real answer :  [{'text': '고페르나무', 'answer_start': 532}]\n",
      "\n",
      "Question :  극보수주의계열의 기독교이자 아직도 노아의 홍수가 있었다고 주장하는 곳은 어디인가?\n",
      "--------------------------------------------------\n",
      "Context :  역사학과 과학의 발달이 더뎠던 고대사회에서는, 성경이 단순한 교리적인 부분 뿐 아니라 역사책으로서의 권위도 높았기에 노아의 방주를 역사적인 존재로서 다루고 있었다. 이는 제칠일안식교에서 비롯된 의사과학의 한 종류인 유사지질학인 홍수지질학과 같은 것에 영향을 주었으며, \n",
      "과거 신학에서는 이러한 근본주의적 해석을 받아들여 역사와 사회적인 모든 부분에 있어 성경을 교과서로 채택할 것을 촉구했다. 이러한 홍수지질학을 주장했던 유사지질학자들은 성경에 나오는 노아의 홍수가 어딘가에 그 흔적이 남아 있을것이라고 주장하며 노아의 방주를 찾기 위한 \n",
      "노력을 했다고 주장한다. 이들은 같은 메소포타미아 지방의 신화인 이슬람교 경전이나 길가메쉬 서사시등의 신화를 들어서 이를 근거라고 주장하기도 했다. 그러나 이러한 전통적 근본주의적 시각은 과거에는 상당히 힘을 얻었으나, 역사학과 과학의 발달에 따라 힘을 잃게 되었고, \n",
      "홍수지질학은 유사과학으로서 남게 되었다. 현대에는 뒤의 실존논란에서 다루는 것처럼 이러한 근본주의적 해석은 비과학적인 해석으로 여기는 것이 일반적이지만, 남침례교로 대표되는 극보수주의계열 기독교에서는 아직도 이것이 받아들여지고 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "남 ##침 ##례 ##교 \n",
      "\n",
      "Untokenized Answer :  남침례교\n",
      "\n",
      "real answer :  [{'text': '남침례교', 'answer_start': 536}]\n",
      "\n",
      "Question :  역사학과 과학의 발달이 미비했을 때 전통 신학계에서는 어떠한 시작으로 노아의 방주를 역사적 사실로 기술하였는가?\n",
      "--------------------------------------------------\n",
      "Context :  역사학과 과학이 발달하지 않았던 과거 전통 신학계에서는 근본주의적 시각을 받아들여 노아의 방주를 역사적 사실로 기술하려 했으며, 이러한 관점은 아직도 과학과 역사학에 어두운 보수적 근본주의계열의 개신교에서만 받아들여지고 있다. 하지만 역사학과 과학의 발달로 인해, 노아\n",
      "의 방주의 실존에 대한 의문이 제기가 되고, 세계적 홍수가 존재할 수 없음이 밝혀짐에 따라 현대 신학계에서는 비록 노아의 홍수가 과학적으로 실존하지는 않았지만 그 자체의 의미는 신학적으로 매우 중요하며, 이에 대한 해석은 다양하게 이루어지고 있으며, 대부분의 기독교(가\n",
      "톨릭, 개신교를 포함한 대부분)에서는 노아의 방주는 상징적 의미로 받아들여진다. 그러므로 과학과는 상관없이 신학적으로 노아의 방주 자체의 의미는 중요하게 해석된다고 한다\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "근 ##본 ##주의 ##적 시 ##각 \n",
      "\n",
      "Untokenized Answer :  근본주의적 시각\n",
      "\n",
      "real answer :  [{'text': '근본주의적', 'answer_start': 31}]\n",
      "\n",
      "Question :  노아의 방주 안전성을 연구하는 주요 연구자의 직업은?\n",
      "--------------------------------------------------\n",
      "Context :  창조과학회에서는 또한 노아의 방주가 안정적인 구조였다고 주장하지만, 이와는 달리 노아의 방주는 항해가 불가능한 설계에 가깝다. 실제로 창조과학에서 주장하는 방주의 크기와 철제 부품을 사용하지 않은 목재 선박 중에서 가장 큰 수준의 선박들을 비교하면 배수량이 두배 이상 \n",
      "차이난다. 그리고 목재 선박은 강도 상의 문제 때문에 통상 길이 100m, 배수량 2000톤 정도가 한계로 여겨져 왔다. 창조과학회에서는 노아의 방주의 안정성을 실험하기 위한 연구가 있다고 주장하기도 하나, 그 자체의 불합리성에 대한 비판을 받고 있으며, 관련 주요 연\n",
      "구자는 지질학 석사학위, 생물학 학사학위를 가진 초등학교 교사로서, 주류 학계의 학회나 저널 등에 발표한 적이 없으며 또한 정당한 피어 리뷰에 의해 검증받지 않았다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "초 ##등학교 \n",
      "\n",
      "Untokenized Answer :  초등학교\n",
      "\n",
      "real answer :  [{'text': '초등학교 교사', 'answer_start': 327}]\n",
      "\n",
      "Question :  한국에서 홍수지질학적 주장들을 내어 놓고 있는 집단은?\n",
      "--------------------------------------------------\n",
      "Context :  물론 노아의 방주가 신학과 신앙에서 중요한 영향을 차지하는 것은 사실이나, 현재 노아의 방주가 역사적으로 실존한다는 주장은 그 증거가 존재하지 않기에 관련 학계로부터 전혀 인정받지 못하고 있으며 그 실존과 안정성에 대한 수많은 논란이 있다. 한국창조과학회 등에서는 제칠\n",
      "일안식교를 기반으로 한 홍수지질학적 주장들을을 내어 놓고 있지만, 사실과 다른 근거들을 바탕으로 주장하므로 신뢰하기 힘든 것들이 전부라 할 수 있다. 그러므로 현재 노아의 방주가 실존한다는 주장은 그 증거가 존재하지 않기에 관련 학계로부터 전혀 인정받지 못하고 있다. \n",
      "모든 과학관련 학계에서는 노아의 방주의 구조나 재질등이 실제로 존재할 수 없는 설화속 이야기라는 데에 동의하고 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "한국 ##창 ##조 ##과 ##학 ##회 \n",
      "\n",
      "Untokenized Answer :  한국창조과학회\n",
      "\n",
      "real answer :  [{'text': '한국창조과학회', 'answer_start': 135}]\n",
      "\n",
      "Question :  막부 해군이 정박하고 있던 시나가와 해역을 탈출한 시간은?\n",
      "--------------------------------------------------\n",
      "Context :  1868년 게이오 4년 4월 11일 에도 성 무혈 개성을 한 이후 신정부 군에게 양도가 약속되어 있었다. 그러나 해군 부총재, 에노모토 다케아키가 기상 불량 등을 이유로 이를 연기한 후에 결국 인도를 거부했다. 도쿠가와 요시노부를 슨푸 번에 이송할 때의 태운 함선으로 \n",
      "사용한 후, 8월 19일 자정 (20일)에는 마쓰오카 바키치를 함장으로 카이요마루, 가이텐마루, 신소쿠마루, 간린마루 등과 함께 막부 해군이 정박하고 있던 시나가와 해역을 탈출했다. 그 때 태풍에 휘말려 침몰직전이 되었지만, 1개월만에 에노모토 해군과 합류하였다. 에조\n",
      "치에 건너가 하코다테 전쟁에서는 에노모토(하코다테 정부) 해군의 주력함이 되었다. 영국이 기증했을 때 엠퍼러(Emperor, 기증 당시 일본의 수장은 황제가 아니라 쇼군으로 인식되고 있었기 때문에 장군을 지칭)로 명명하고 있음에서 알 수 있듯이, 쇼군용 유람 요트로 기\n",
      "증되었다고 생각되지만, 세상이 그것을 허락하지 않았다. 아이러니하게도, 군함에 통합되어 실제로 쇼군이 첫 좌승한 것이 대정봉환 이후 슨푸 번에 이송되었을 때였다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "8월 19일 \n",
      "\n",
      "Untokenized Answer :  8월 19일\n",
      "\n",
      "real answer :  [{'text': '자정', 'answer_start': 164}]\n",
      "\n",
      "Question :  국무회의의 심의를 거쳐야 한다는 헌법 제 몇 조의 내용인가?\n",
      "--------------------------------------------------\n",
      "Context :  \"내각과 장관들이 소외되고 대통령비서실의 권한이 너무 크다\", \"행보가 비서 본연의 역할을 벗어난다\"는 의견이 제기되었다. 대표적인 예가 10차 개헌안 발표이다. 원로 헌법학자인 허영 경희대 석좌교수는 정부의 헌법개정안 준비 과정에 대해 \"청와대 비서실이 아닌 국무회의\n",
      " 중심으로 이뤄졌어야 했다\"고 지적했다. '국무회의의 심의를 거쳐야 한다'(제89조)는 헌법 규정에 충실하지 않았다는 것이다. 그러면서 \"법무부 장관을 제쳐놓고 민정수석이 개정안을 설명하는 게 이해가 안 된다\"고 지적했다. 민정수석은 국회의원에 대해 책임지는 법무부 장\n",
      "관도 아니고, 국민에 대해 책임지는 사람도 아니기 때문에 정당성이 없고, 단지 대통령의 신임이 있을 뿐이라는 것이다. 또한 국무총리 선출 방식에 대한 기자의 질문에 \"문 대통령도 취임 전에 국무총리에게 실질적 권한을 주겠다고 했지만 그러지 못하고 있다. 대통령비서실장만\n",
      "도 못한 권한을 행사하고 있다.\"고 답변했다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "제 ##8 ##9 ##조 \n",
      "\n",
      "Untokenized Answer :  제89조\n",
      "\n",
      "real answer :  [{'text': '제89조', 'answer_start': 192}]\n",
      "\n",
      "Question :  퇴역 후 헤이그는 어느 회사의 대표가 되었나?\n",
      "--------------------------------------------------\n",
      "Context :  헤이그는 닉슨 대통령이 그를 사성 장군과 육군 부참모로 진급시킬 때 집중 광선과 논쟁으로 들어갔다. 헤이그를 군사의 최상으로 밀어넣은 닉슨의 행동은 대통령의 남자들을 다양한 연방 대리법에서 권한의 직우들로 놓은 노력과 함께 일치였다. 하지만 그는 곧 백악관으로 돌아가 \n",
      "1973년부터 1974년까지 대통령 특별 보좌관을 지냈다. 워터게이트 사건이 일어난지 한달 후, 헤이그는 포위된 닉슨 대통령을 위한 치명적 역할을 하였다. 그일은 8월 닉슨의 사임과 제럴드 포드의 대통령으로 계승으로 이끈 협상들에서 헤이그가 수단이었던 우연이 아니었다.\n",
      " 곧 후에 헤이그는 미국 유럽 연합군 최고사령부의 최고 사령관으로 임명되었다. 그는 나토에서 다음 5년을 보내고 1979년 군에서 퇴역하여 미국 기술 주식 회사의 우두머리가 되었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "미국 기 ##술 \n",
      "\n",
      "Untokenized Answer :  미국 기술\n",
      "\n",
      "real answer :  [{'text': '미국 기술 주식 회사', 'answer_start': 378}]\n",
      "\n",
      "Question :  노아의 방주는 몇층으로 구성되어 있었는가?\n",
      "--------------------------------------------------\n",
      "Context :  노아는 하나님의 명령에 따라 배를 만들고 가족과 정결한 짐승 암수 일곱 마리씩, 부정한 짐승 암수 한 마리씩(혹은 두 마리씩; 사본에 따라 다름), 그리고 새 암수 일곱 마리씩을 싣고 밀어닥친 홍수를 피하였다. 모든 사람들이 타락한 생활에 빠져 있어 하나님이 홍수로 심\n",
      "판하려 할 때 홀로 바르게 살던 노아는 하나님의 특별한 계시로 홍수가 올 것을 미리 알게 된다. 그는 길이 300 규빗, 너비 50 규빗, 높이 30 규빗(고대의 1규빗은 팔꿈치에서 가운데 손가락끝까지의 길이로 약 45~46cm를 가리킴), 상 ·중 ·하 3층으로 된 \n",
      "방주를 만들어 8명의 가족과, 한 쌍씩의 여러 동물을 데리고 이 방주에 탄다. 대홍수를 만나 모든 생물(물고기 제외)이 전멸하고 말았지만, 이 방주에 탔던 노아의 가족과 동물들은 살아 남았다고 한다.〈창세기〉 6장 14~16절에 보면 길이 300규빗 (약 135m), \n",
      "폭 50 규빗 (약 22.5m), 높이 30 규빗 (약 13.5m)인 이 배는 지붕과 문을 달고 배 안은 3층으로 만들어져 있었다. 선체(船體)는 고페르나무(잣나무)로 되고 안쪽에는 역청(아스팔트와 비슷한 성분)을 칠하여 굳혔다고 기록하고 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "3 ##층 \n",
      "\n",
      "Untokenized Answer :  3층\n",
      "\n",
      "real answer :  [{'text': '3층', 'answer_start': 293}]\n",
      "\n",
      "Question :  노아 가족과 동물들이 노아의 방주에서 버틴 날짜는 총 몇일인가?\n",
      "--------------------------------------------------\n",
      "Context :  기독교 성경 내용에는 모든 종들을 방주에 태운다고 이야기하고 있으나, 어류나 수중 생물에 대해서는 언급하지 않았다. 이것을 신학적 의미로만 받아들이면 괜찮은 문제이나, 이 현상이 실제로 일어났다고 가정할 경우,이는 종 간 생존 환경의 차이에 대해서 간과하고 있다. 수중\n",
      " 생물이라 하더라도 종에 따라 생존할 수 있는 환경은 각각 다른 것이며, 40일 이내에 현존하는 가장 높은 산인 에베레스트 산도 잠기게 할 정도의 폭우로 인해 담수와 염수가 급작스럽게 섞일 경우, 급격한 삼투압 변화로 인해 대부분의 수생생물들이 폐사하게 되며, 결과적으\n",
      "로 육지 뿐 아니라 바다와 강의 모든 생태계가 파괴된다. 이후 5천년이라는 지극히 짧은 세월 동안 지구상의 동식물이 모두 페름기 대멸종 또는 K-T 대멸종에 준하는 대량절멸에 가까운 상태에서부터 시작하여 현재의 대략 870만(±120만)종에 달하는 생물다양성을 획득하려\n",
      "면 모든 생물들이 각 세대마다 종분화가 일어나야 할 만큼 엄청난 속도로 진화 및 번식이 (멸종 없이) 이루어져야만 가능한 일이다. (이와 관련하여 창조과학회 측에서는 북극곰의 예시를 통해 가지고 있던 특성이 없어지는 것이 진화가 아니라고 주장하지만, 통상적으로 알려진 \n",
      "바와 같이 생물학에서는 이미 존재하는 특성이 없어지는 현상, 즉 퇴화 역시 진화의 정의에 포함된다.) 즉, 노아의 홍수가 실재하는 사건이었다면 진화적 종분화가 현재까지 알려진 것과 비교할 수 없이 엄청난 속도로 이루어져야만 현재 지구의 생물다양성을 설명할 수 있다. 게\n",
      "다가 이것은 현재의 생물종 멸종 속도를 전혀 고려하지 않았다. 다시 말해, 노아의 홍수가 실재하는 전지구적인 사건이기 위해서는 최소 캄브리아기 대폭발 수준의 폭발적인 진화적 종분화가 1-2억년이 아니라 최대 3-4천년 이내에 이루어졌어야만 현생 지구의 생물다양성에 대한\n",
      " 설명이 가능해진다. 그보다 더 중요한 것은, 각 동물들이 차지하는 영역과 먹이사슬에서의 위치, 375일 동안 먹이도 없이 밀폐된 공간으로 인해 받을 스트레스 등 생태적 지위에 대한 고려가 전혀 없다는 점이다. 또한 바다에서 생존이 불가능한 생물종까지 숫자에 포함되었다\n",
      "는 점에서 논란이 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "40 ##일 \n",
      "\n",
      "Untokenized Answer :  40일\n",
      "\n",
      "real answer :  [{'text': '375일', 'answer_start': 954}]\n",
      "\n",
      "Question :  헤이그가 공부한 대학교는?\n",
      "--------------------------------------------------\n",
      "Context :  노터데임 대학교에서 2년간 합리적으로 심각한 공부를 한 후 헤이그는 1944년 미국 육군사관학교로 임명을 획득하여 자신의 어린 시절을 군사 경력의 야망으로 알아챘다. 그 경력은 헤이그의 학문적 경연이 암시하려고 한것보다 더욱 극적이었으며 그는 1947년 310의 동기병\n",
      "에서 217번째 사관으로서 졸업하였다. 22세의 소위로 헤이그는 처음에 캔자스 주 포트라일리에서 정통 제병 연합부대로, 그러고나서 켄터키 주 포트녹스에 있는 기갑 훈련소로 갔다. 그후에 그는 제1 기병 사단으로 선임되고 그러고나서 일본에서 점령군의 임무와 기력이 없는 \n",
      "훈련을 하였다. 그는 1950년 5월 한번 자신의 사령관 알론조 폭스 장군의 딸 퍼트리샤 앤토이넷 폭스와 결혼하여 슬하 3명의 자식을 두었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "노 ##터 ##데 ##임 대학교 \n",
      "\n",
      "Untokenized Answer :  노터데임 대학교\n",
      "\n",
      "real answer :  [{'text': '노터데임 대학교', 'answer_start': 0}]\n",
      "\n",
      "Question :  정부의 헌법개정안 준비 과정에 대해서 청와대 비서실이 아니라 국무회의 중심으로 이뤄졌어야 했다고 지적한 원로 헌법학자는?\n",
      "--------------------------------------------------\n",
      "Context :  \"내각과 장관들이 소외되고 대통령비서실의 권한이 너무 크다\", \"행보가 비서 본연의 역할을 벗어난다\"는 의견이 제기되었다. 대표적인 예가 10차 개헌안 발표이다. 원로 헌법학자인 허영 경희대 석좌교수는 정부의 헌법개정안 준비 과정에 대해 \"청와대 비서실이 아닌 국무회의\n",
      " 중심으로 이뤄졌어야 했다\"고 지적했다. '국무회의의 심의를 거쳐야 한다'(제89조)는 헌법 규정에 충실하지 않았다는 것이다. 그러면서 \"법무부 장관을 제쳐놓고 민정수석이 개정안을 설명하는 게 이해가 안 된다\"고 지적했다. 민정수석은 국회의원에 대해 책임지는 법무부 장\n",
      "관도 아니고, 국민에 대해 책임지는 사람도 아니기 때문에 정당성이 없고, 단지 대통령의 신임이 있을 뿐이라는 것이다. 또한 국무총리 선출 방식에 대한 기자의 질문에 \"문 대통령도 취임 전에 국무총리에게 실질적 권한을 주겠다고 했지만 그러지 못하고 있다. 대통령비서실장만\n",
      "도 못한 권한을 행사하고 있다.\"고 답변했다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "허 ##영 경 ##희 ##대 \n",
      "\n",
      "Untokenized Answer :  허영 경희대\n",
      "\n",
      "real answer :  [{'text': '허영', 'answer_start': 100}]\n",
      "\n",
      "Question :  알렉산더 헤이그가 로널드 레이건 대통령 밑에서 맡은 직책은 무엇이었나?\n",
      "--------------------------------------------------\n",
      "Context :  알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr., 1924년 12월 2일 ~ 2010년 2월 20일)는 미국의 국무 장관을 지낸 미국의 군인, 관료 및 정치인이다. 로널드 레이건 대통령 밑에서 국무장관을 지냈으며, 리처드 닉슨과 제럴\n",
      "드 포드 대통령 밑에서 백악관 비서실장을 지냈다. 또한 그는 미국 군대에서 2번째로 높은 직위인 미국 육군 부참모 총장과 나토 및 미국 군대의 유럽연합군 최고사령관이었다. 한국 전쟁 시절 더글러스 맥아더 유엔군 사령관의 참모로 직접 참전하였으며, 로널드 레이건 정부 출\n",
      "범당시 초대 국무장관직을 맡아 1980년대 대한민국과 미국의 관계를 조율해 왔다. 저서로 회고록 《경고:현실주의, 레이건과 외교 정책》(1984년 발간)이 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "국 ##무 ##장 ##관 \n",
      "\n",
      "Untokenized Answer :  국무장관\n",
      "\n",
      "real answer :  [{'text': '국무장관', 'answer_start': 128}]\n",
      "\n",
      "Question :  2012년 중국 BTV에서 노아의 방주가 발견되었다고 보도한 나라는?\n",
      "--------------------------------------------------\n",
      "Context :  일반적으로 터키의 아라랏 산의 경우, 실제 성경 속에 등장하는 아라랏 산은 지금 아라랏이라 불리는 하나의 산이 아니라 당시 아라랏이라고 불리던 광대한 지역의 산들을 모두 가리키는 표현이라는 주장도 나와 있으며, 또한 목재로 만들어진 방주가 현재까지 남아있을 수는 없다는\n",
      " 비판도 받고 있다. 예를 들어, 1955년 프랑스의 탐험가인 Fernand Navarra가 발견한 목재 파편의 경우, 스페인의 임업 연구소에서 목재의 특성을 토대로 5000년 전의 것이라고 밝히긴 했으나 그 신빙성에 문제점이 있었고 후에 방사성 동위원소 측정법 등의 \n",
      "첨단 과학의 도움을 받은 5개 연구소에서 모두 기원 이후의 시기로 연대를 측정했다. 2009년 뿐 아니라 거의 수년에 한번씩 어디선가 노아의 방주를 발견했다는 주장들이 제시되었지만, 심지어 같은 창조과학을 주장하는 사람들에게조차 비판받을 정도였다. 노아의 방주가 다른 \n",
      "여러 지방에서 발견되었다는 주장이 있으나 너무나 다양한 지방(중국, 터키, 인도 등)에 걸쳐있고, 그 주장도 각각 제각각이므로 신빙성이 없다. 예를 들자면, 중국 BTV에서는 2012년에 중국에서 노아의 방주가 발견되었다는 보도를 하였는데, 이것은 창조과학회에서 주장하\n",
      "는 장소와는 전혀 다른곳이기도 하며, 화석화가 진행되지 않은 나무의 존재등으로 가짜임이 밝혀졌다. 때때로 일부 \"학자\"라 칭하는 사람들이 이를 찾기 위해 노력한다고 주장하지만, 이는 학계에서 유사지질학으로 평가되고 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "중국 \n",
      "\n",
      "Untokenized Answer :  중국\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real answer :  [{'text': '중국', 'answer_start': 555}]\n",
      "\n",
      "Question :  하코다테 전쟁 시 반류마루의 함장의 이름은 무엇인가?\n",
      "--------------------------------------------------\n",
      "Context :  일련의 하코다테 전쟁은 적아 쌍방의 문서에 마쓰오카 바키치 함장의 능란한 조함 능력과 냉정한 지휘만이 기록되어 있다. 함포 사격으로 마쓰마에 성을 공격하여 엄호한 이후, 1869년 메이지 2년 3월 25일 미야코 만 해전에서는 폭풍우를 만나 요함과 헤어졌을 때에 만날 \n",
      "약속했던 하치노헤 항에서 대기하고 있었기 때문에 참전에는 이르지 못했다. 이 폭풍우 때도 “함장 마쓰오카 바키치는 배를 조정하는 명수로 로프 하나 손상되지 않았다”고 타고 있던 하야시 다다스가 남긴 바 있다. 이 귀로에서 신정부 군의 철갑함의 추격을 받았다. 기관 능력\n",
      "의 차이로 인한 속도차 때문에 도주가 불가능하다고 판단하고 맞장 공격을 하겠다고 전투 준비를 했지만, 철갑선의 사정거리에 들어간 순간에 순풍이 불기 시작하여 추격을 뿌리치고 하코다테로 돌아올 수 있었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "마 ##쓰 ##오 ##카 바 ##키 ##치 \n",
      "\n",
      "Untokenized Answer :  마쓰오카 바키치\n",
      "\n",
      "real answer :  [{'text': '마쓰오카 바키치', 'answer_start': 24}]\n",
      "\n",
      "Question :  함장 마쓰오카 바키치는 배를 조정하는 명수로 로프 하나 손상되지 않았다고 말한 사람은?\n",
      "--------------------------------------------------\n",
      "Context :  일련의 하코다테 전쟁은 적아 쌍방의 문서에 마쓰오카 바키치 함장의 능란한 조함 능력과 냉정한 지휘만이 기록되어 있다. 함포 사격으로 마쓰마에 성을 공격하여 엄호한 이후, 1869년 메이지 2년 3월 25일 미야코 만 해전에서는 폭풍우를 만나 요함과 헤어졌을 때에 만날 \n",
      "약속했던 하치노헤 항에서 대기하고 있었기 때문에 참전에는 이르지 못했다. 이 폭풍우 때도 “함장 마쓰오카 바키치는 배를 조정하는 명수로 로프 하나 손상되지 않았다”고 타고 있던 하야시 다다스가 남긴 바 있다. 이 귀로에서 신정부 군의 철갑함의 추격을 받았다. 기관 능력\n",
      "의 차이로 인한 속도차 때문에 도주가 불가능하다고 판단하고 맞장 공격을 하겠다고 전투 준비를 했지만, 철갑선의 사정거리에 들어간 순간에 순풍이 불기 시작하여 추격을 뿌리치고 하코다테로 돌아올 수 있었다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "하 ##야 ##시 다 ##다 ##스 \n",
      "\n",
      "Untokenized Answer :  하야시 다다스\n",
      "\n",
      "real answer :  [{'text': '하야시 다다스', 'answer_start': 249}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for i in random.sample(range(100),100):\n",
    "  doc = dev['context'][i]\n",
    "  question = dev['question'][i]\n",
    "  answers = dev['answers'][i]\n",
    "  predict_letter(question, doc)\n",
    "  print(\"\")\n",
    "  print(\"real answer : \", answers)\n",
    "  print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1c5YChJ55yt"
   },
   "source": [
    "한번 만들어진 BERT 모형에 질문을 해 볼까요?  \n",
    "나무위키에서 데이터를 가져와서 질문을 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "T_I3QsA99ZhH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question :  mp3는 언제 개발 되었어?\n",
      "--------------------------------------------------\n",
      "Context :  2000년 5월 소리바다에서 개발한 mp3 음악파일 교환 서비스로 P2P 프로그램으로 출발해 대표적인 음악파일 교환 서비스로 성장하였다. 저작권 침해 문제로 서비스 중지 가처분 결정을 받았으나 소리바다5로 2006년 7월 전면 유료화 서비스로 전환하였고 월정액제와 자유\n",
      "이용권 등의 제도를 운영하고 있다.사용자끼리 서로의 mp3 파일을 검색하고다운로드받을 수 있는 개인 대 개인(P2P) 프로그램으로 출발하였다. 2000년 5월부터 온라인 서비스에 들어가 국내 대표적인음악파일 교환 서비스로 자리잡았다. 그러나 한국음반산업협회에서 소리바다\n",
      "를 상대로가처분신청을 제기하였고, 2002년 7월 11일법원은 소리바다의 음악파일 공유 서비스가저작권을 침해할 소지가 있다고 판단해 서비스 중지 가처분 결정을 내려 7월 31일 이후 서비스가 중단됐다.상황이 이렇게 되자 8월 24일 중앙집중식 검색 기능을 없앤 새 파일\n",
      " 교환 프로그램 소리바다 2를 개발하였다. 이 프로그램은 메인 서버 없이 슈퍼피어(SuperPeer) 방식으로 사용자 리스트를 받을 수 있으며, 전반적으로 사용자 인터페이스를 개선한 것이었다.소리바다는 2003년 11월 주식회사로 법인 전환을 하였다. 2004년 7월 \n",
      "'소리바다3'를 출시하였으며, 12월 유료 mp3＃을 열었다. 2005년 11월 서비스를 중단하였다가 2006년 3월 '소리바다5'라는 이름으로 서비스를 재개하였으며, 7월부터 전면 유료화되었다. '소리바다5'는 회원들이 공유한 mp3파일을 실시간으로 검색하여 원하는 \n",
      "파일을 다운로드할 수 있는 P2P 프로그램으로 운영되며, 월정액제의 자유이용권을 구매하여 이용할 수 있다. 다운로드하면서 미리듣기를 할 수 있고, 원하는 mp3파일의 가사도 볼 수 있다. 또 오르골이라는 무제한 용량의 저장공간도 제공된다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "2000년 5월 \n",
      "\n",
      "Untokenized Answer :  2000년 5월\n"
     ]
    }
   ],
   "source": [
    "doc = \"2000년 5월 소리바다에서 개발한 mp3 음악파일 교환 서비스로 P2P 프로그램으로 출발해 대표적인 음악파일 교환 서비스로 성장하였다. 저작권 침해 문제로 서비스 중지 가처분 결정을 받았으나 소리바다5로 2006년 7월 전면 유료화 서비스로 전환하였고 월정액제와 자유이용권 등의 제도를 운영하고 있다.사용자끼리 서로의 mp3 파일을 검색하고다운로드받을 수 있는 개인 대 개인(P2P) 프로그램으로 출발하였다. 2000년 5월부터 온라인 서비스에 들어가 국내 대표적인음악파일 교환 서비스로 자리잡았다. 그러나 한국음반산업협회에서 소리바다를 상대로가처분신청을 제기하였고, 2002년 7월 11일법원은 소리바다의 음악파일 공유 서비스가저작권을 침해할 소지가 있다고 판단해 서비스 중지 가처분 결정을 내려 7월 31일 이후 서비스가 중단됐다.상황이 이렇게 되자 8월 24일 중앙집중식 검색 기능을 없앤 새 파일 교환 프로그램 소리바다 2를 개발하였다. 이 프로그램은 메인 서버 없이 슈퍼피어(SuperPeer) 방식으로 사용자 리스트를 받을 수 있으며, 전반적으로 사용자 인터페이스를 개선한 것이었다.소리바다는 2003년 11월 주식회사로 법인 전환을 하였다. 2004년 7월 '소리바다3'를 출시하였으며, 12월 유료 mp3＃을 열었다. 2005년 11월 서비스를 중단하였다가 2006년 3월 '소리바다5'라는 이름으로 서비스를 재개하였으며, 7월부터 전면 유료화되었다. '소리바다5'는 회원들이 공유한 mp3파일을 실시간으로 검색하여 원하는 파일을 다운로드할 수 있는 P2P 프로그램으로 운영되며, 월정액제의 자유이용권을 구매하여 이용할 수 있다. 다운로드하면서 미리듣기를 할 수 있고, 원하는 mp3파일의 가사도 볼 수 있다. 또 오르골이라는 무제한 용량의 저장공간도 제공된다.\"\n",
    "question = \"mp3는 언제 개발 되었어?\"\n",
    "\n",
    "predict_letter(question, doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question :  목성의 부피는 지구의 몇배인가?\n",
      "--------------------------------------------------\n",
      "Context :  태양계의 5번째 행성이며, 태양계의 행성 중 가장 부피가 크고 무겁다. 반지름은 지구의 11.2배, 부피는 지구의 1300배가 넘는다. 질량은 지구의 318배다. 부피에 비해 질량이 작은 이유는 암석형 행성보다 밀도가 낮은 성분들이 주요 구성성분인 가스형 행성이기 때문\n",
      "이다. 그럼에도 목성의 질량은 다른 태양계 행성들을 합친 것보다도 무겁다. 심지어 그 7개 행성의 질량을 몽땅 다 합쳐도 목성의 절반도 되지 않는다. 태양계에서 태양이 99.86%를 차지하고, 목성은 나머지 0.14% 중에서 약 2/3인 0.095%를 차지한다. 뒤를 \n",
      "이어 토성이 0.029%를 차지하며, 나머지 행성들을 모두 합쳐도 태양계 질량의 0.016% 정도 밖에 되지 않는다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "1300 ##배 \n",
      "\n",
      "Untokenized Answer :  1300배\n"
     ]
    }
   ],
   "source": [
    "doc = \"태양계의 5번째 행성이며, 태양계의 행성 중 가장 부피가 크고 무겁다. 반지름은 지구의 11.2배, 부피는 지구의 1300배가 넘는다. 질량은 지구의 318배다. 부피에 비해 질량이 작은 이유는 암석형 행성보다 밀도가 낮은 성분들이 주요 구성성분인 가스형 행성이기 때문이다. 그럼에도 목성의 질량은 다른 태양계 행성들을 합친 것보다도 무겁다. 심지어 그 7개 행성의 질량을 몽땅 다 합쳐도 목성의 절반도 되지 않는다. 태양계에서 태양이 99.86%를 차지하고, 목성은 나머지 0.14% 중에서 약 2/3인 0.095%를 차지한다. 뒤를 이어 토성이 0.029%를 차지하며, 나머지 행성들을 모두 합쳐도 태양계 질량의 0.016% 정도 밖에 되지 않는다.\"\n",
    "question = \"목성의 부피는 지구의 몇배인가?\"\n",
    "\n",
    "predict_letter(question, doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "oQFOPwW-WsAN",
    "outputId": "d2e63a4c-c1bf-47ae-bb86-6f2354f50cb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question :  우한 폐렴은 어디서 발생하였는가?\n",
      "--------------------------------------------------\n",
      "Context :  사스와 메르스처럼 코로나 바이러스의 보고되지 않은 종에 인한 감염으로 발생하는 호흡기 질환이다. 최초 발생 원인과 전파 경로는 아직 정확히 밝혀지지 않았다.발병 초기에 보고된 불상의 폐병 증상으로 대중적으로는 '우한 폐렴' 등의 키워드로 불렸으며, 현재 세계보건기구(W\n",
      "HO)에서는 Novel coronavirus(2019-nCoV)라는 표현을 사용 중이다(#). 미국, 영국 등 일부 외신에서는 Wuhan coronavirus라는 표현을 사용하기도 한다. 현재 미국 정부는 질병 명칭에는 Wuhan을 넣지 않은 Coronavirus라고만\n",
      " 지칭 중이다.[11] 대한민국 정부에서 잠정적으로 사용하는 질병 명칭은 신종 코로나바이러스감염증이다. 이는 2015년부터 낙인 효과를 우려한 WHO에서 병명에 지역 이름을 넣는 것을 피하도록 한 권고[12](#)에 따른 것이다. 물론 해당 권고는 구속력이 없으며, 정\n",
      "부나 공공 의료기관이 아닌 일반인, 그리고 언론이 우한 폐렴을 사용하는 것에도 문제가 없다. 실제로 외신이나 당사자인 중국 본토에서도 '우한' 혹은 '중국' 명칭을 사용하고 있다. #기사 사태 초반에는 우한시 안에 국한될 것으로 판단하는 이들이 많았으나, 점차 우한 외\n",
      " 후베이성과 인근 지역, 그리고 중국을 벗어나 해외로까지 퍼지면서 상황이 심각해졌다. 우한시의 인구는 약 1,100만 명이며, 하필 맞물린 춘절[13]로 인한 인구 대이동으로 병이 사방으로 퍼질 위험이 있어 중국 현지에 비상이 걸렸다. 게다가 춘절 기간 중 중국인 관광\n",
      "객들이 해외여행을 많이 가다보니 세계 여러 나라에서도 촉각이 곤두서있다. 따라서 춘절 전후가 감염병 확산의 고비라 할 수 있다.\n",
      "--------------------------------------------------\n",
      "ANSWER :  \n",
      "\n",
      "\n",
      "\n",
      "Untokenized Answer : \n"
     ]
    }
   ],
   "source": [
    "\n",
    "doc = \"사스와 메르스처럼 코로나 바이러스의 보고되지 않은 종에 인한 감염으로 발생하는 호흡기 질환이다. 최초 발생 원인과 전파 경로는 아직 정확히 밝혀지지 않았다.발병 초기에 보고된 불상의 폐병 증상으로 대중적으로는 '우한 폐렴' 등의 키워드로 불렸으며, 현재 세계보건기구(WHO)에서는 Novel coronavirus(2019-nCoV)라는 표현을 사용 중이다(#). 미국, 영국 등 일부 외신에서는 Wuhan coronavirus라는 표현을 사용하기도 한다. 현재 미국 정부는 질병 명칭에는 Wuhan을 넣지 않은 Coronavirus라고만 지칭 중이다.[11] 대한민국 정부에서 잠정적으로 사용하는 질병 명칭은 신종 코로나바이러스감염증이다. 이는 2015년부터 낙인 효과를 우려한 WHO에서 병명에 지역 이름을 넣는 것을 피하도록 한 권고[12](#)에 따른 것이다. 물론 해당 권고는 구속력이 없으며, 정부나 공공 의료기관이 아닌 일반인, 그리고 언론이 우한 폐렴을 사용하는 것에도 문제가 없다. 실제로 외신이나 당사자인 중국 본토에서도 '우한' 혹은 '중국' 명칭을 사용하고 있다. #기사 사태 초반에는 우한시 안에 국한될 것으로 판단하는 이들이 많았으나, 점차 우한 외 후베이성과 인근 지역, 그리고 중국을 벗어나 해외로까지 퍼지면서 상황이 심각해졌다. 우한시의 인구는 약 1,100만 명이며, 하필 맞물린 춘절[13]로 인한 인구 대이동으로 병이 사방으로 퍼질 위험이 있어 중국 현지에 비상이 걸렸다. 게다가 춘절 기간 중 중국인 관광객들이 해외여행을 많이 가다보니 세계 여러 나라에서도 촉각이 곤두서있다. 따라서 춘절 전후가 감염병 확산의 고비라 할 수 있다.\"\n",
    "question = \"우한 폐렴은 어디서 발생하였는가?\"\n",
    "\n",
    "predict_letter(question, doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "05_케라스로_KorQuAD(한국어 Q&A) 구현하기.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch1.7.1",
   "language": "python",
   "name": "torch1.7.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}