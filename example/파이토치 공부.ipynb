{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "neutral-activation",
   "metadata": {},
   "source": [
    "https://wikidocs.net/book/2788"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-firmware",
   "metadata": {},
   "source": [
    "# 03. 선형 회귀(Linear Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-background",
   "metadata": {},
   "source": [
    "## 2. 자동 미분(Autograd) 실습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "square-store",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "capital-kitty",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor(2.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pregnant-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = w**2\n",
    "z = 2*y +5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "photographic-mirror",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "genuine-terminal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수식을 w로 미분한 겂 : 8.0\n"
     ]
    }
   ],
   "source": [
    "print('수식을 w로 미분한 겂 : {}'.format(w.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-screening",
   "metadata": {},
   "source": [
    "# 04. nn.Module로 구현하는 선형 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-columbia",
   "metadata": {},
   "source": [
    "## 1. 단순 선형 회귀 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "descending-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "revolutionary-edition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2c70a238de0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "valid-backup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[2], [4], [6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "meaningful-cooperative",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 선언 및 초기화, 단순 선형 회귀 회귀이므로 input_dim=1, output_dim=1.\n",
    "model = nn.Linear(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "swedish-intention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.1939]], requires_grad=True), Parameter containing:\n",
      "tensor([0.4694], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "accessory-environment",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "geological-surgeon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/2000 Cost: 33.679783\n",
      "Epoch  100/2000 Cost: 0.223159\n",
      "Epoch  200/2000 Cost: 0.137899\n",
      "Epoch  300/2000 Cost: 0.085213\n",
      "Epoch  400/2000 Cost: 0.052656\n",
      "Epoch  500/2000 Cost: 0.032539\n",
      "Epoch  600/2000 Cost: 0.020107\n",
      "Epoch  700/2000 Cost: 0.012425\n",
      "Epoch  800/2000 Cost: 0.007678\n",
      "Epoch  900/2000 Cost: 0.004744\n",
      "Epoch 1000/2000 Cost: 0.002932\n",
      "Epoch 1100/2000 Cost: 0.001812\n",
      "Epoch 1200/2000 Cost: 0.001119\n",
      "Epoch 1300/2000 Cost: 0.000692\n",
      "Epoch 1400/2000 Cost: 0.000427\n",
      "Epoch 1500/2000 Cost: 0.000264\n",
      "Epoch 1600/2000 Cost: 0.000163\n",
      "Epoch 1700/2000 Cost: 0.000101\n",
      "Epoch 1800/2000 Cost: 0.000062\n",
      "Epoch 1900/2000 Cost: 0.000039\n",
      "Epoch 2000/2000 Cost: 0.000024\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 2000\n",
    "for epoch in range(nb_epochs+1):\n",
    "    # H(x) 게산\n",
    "    prediction = model(x_train)\n",
    "    \n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "    \n",
    "    # cost로 H(x)를 개선하는 부분\n",
    "    # gradient를 0으로 초기화\n",
    "    optimizer.zero_grad()\n",
    "    # 비용 함수를 미분하여 gradient 계산\n",
    "    cost.backward()\n",
    "    # W 와 b를 업데이트\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(epoch, nb_epochs, cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "pleasant-pollution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 후 입력이 4일 때의 예측값 : tensor([[7.9902]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 임의의 입력 4를 선언\n",
    "new_var = torch.FloatTensor([[4.0]])\n",
    "# 입력한 값 4에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
    "pred_y = model(new_var)# forward 연산\n",
    "# Y = 2x 이므로 입력이 4라면 y가 8에 가까운 값이 나와야 제대로 학습이 된 것\n",
    "print(\"훈련 후 입력이 4일 때의 예측값 :\", pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "balanced-segment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[1.9943]], requires_grad=True), Parameter containing:\n",
      "tensor([0.0128], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-snowboard",
   "metadata": {},
   "source": [
    "## 다중 선형 회귀 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "anonymous-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "conventional-tyler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2c70a238de0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "divine-startup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 90],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "variable-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 선언 및 초기화, 다중 선형 회귀 이므로 input_dim=3, output_dim=1.\n",
    "model = nn.Linear(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "suburban-scout",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.2975, -0.2548, -0.1119]], requires_grad=True), Parameter containing:\n",
      "tensor([0.2710], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "wireless-wayne",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "valued-administration",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/10000 Cost: 0.199752\n",
      "Epoch  100/10000 Cost: 0.198930\n",
      "Epoch  200/10000 Cost: 0.198148\n",
      "Epoch  300/10000 Cost: 0.197388\n",
      "Epoch  400/10000 Cost: 0.196674\n",
      "Epoch  500/10000 Cost: 0.195989\n",
      "Epoch  600/10000 Cost: 0.195327\n",
      "Epoch  700/10000 Cost: 0.194704\n",
      "Epoch  800/10000 Cost: 0.194097\n",
      "Epoch  900/10000 Cost: 0.193519\n",
      "Epoch 1000/10000 Cost: 0.192972\n",
      "Epoch 1100/10000 Cost: 0.192443\n",
      "Epoch 1200/10000 Cost: 0.191937\n",
      "Epoch 1300/10000 Cost: 0.191451\n",
      "Epoch 1400/10000 Cost: 0.190982\n",
      "Epoch 1500/10000 Cost: 0.190535\n",
      "Epoch 1600/10000 Cost: 0.190104\n",
      "Epoch 1700/10000 Cost: 0.189689\n",
      "Epoch 1800/10000 Cost: 0.189292\n",
      "Epoch 1900/10000 Cost: 0.188909\n",
      "Epoch 2000/10000 Cost: 0.188540\n",
      "Epoch 2100/10000 Cost: 0.188179\n",
      "Epoch 2200/10000 Cost: 0.187842\n",
      "Epoch 2300/10000 Cost: 0.187504\n",
      "Epoch 2400/10000 Cost: 0.187183\n",
      "Epoch 2500/10000 Cost: 0.186876\n",
      "Epoch 2600/10000 Cost: 0.186588\n",
      "Epoch 2700/10000 Cost: 0.186299\n",
      "Epoch 2800/10000 Cost: 0.186021\n",
      "Epoch 2900/10000 Cost: 0.185746\n",
      "Epoch 3000/10000 Cost: 0.185491\n",
      "Epoch 3100/10000 Cost: 0.185239\n",
      "Epoch 3200/10000 Cost: 0.184991\n",
      "Epoch 3300/10000 Cost: 0.184756\n",
      "Epoch 3400/10000 Cost: 0.184530\n",
      "Epoch 3500/10000 Cost: 0.184304\n",
      "Epoch 3600/10000 Cost: 0.184086\n",
      "Epoch 3700/10000 Cost: 0.183871\n",
      "Epoch 3800/10000 Cost: 0.183668\n",
      "Epoch 3900/10000 Cost: 0.183465\n",
      "Epoch 4000/10000 Cost: 0.183271\n",
      "Epoch 4100/10000 Cost: 0.183079\n",
      "Epoch 4200/10000 Cost: 0.182901\n",
      "Epoch 4300/10000 Cost: 0.182716\n",
      "Epoch 4400/10000 Cost: 0.182535\n",
      "Epoch 4500/10000 Cost: 0.182369\n",
      "Epoch 4600/10000 Cost: 0.182198\n",
      "Epoch 4700/10000 Cost: 0.182033\n",
      "Epoch 4800/10000 Cost: 0.181867\n",
      "Epoch 4900/10000 Cost: 0.181712\n",
      "Epoch 5000/10000 Cost: 0.181561\n",
      "Epoch 5100/10000 Cost: 0.181410\n",
      "Epoch 5200/10000 Cost: 0.181256\n",
      "Epoch 5300/10000 Cost: 0.181109\n",
      "Epoch 5400/10000 Cost: 0.180971\n",
      "Epoch 5500/10000 Cost: 0.180826\n",
      "Epoch 5600/10000 Cost: 0.180690\n",
      "Epoch 5700/10000 Cost: 0.180555\n",
      "Epoch 5800/10000 Cost: 0.180415\n",
      "Epoch 5900/10000 Cost: 0.180288\n",
      "Epoch 6000/10000 Cost: 0.180160\n",
      "Epoch 6100/10000 Cost: 0.180031\n",
      "Epoch 6200/10000 Cost: 0.179904\n",
      "Epoch 6300/10000 Cost: 0.179777\n",
      "Epoch 6400/10000 Cost: 0.179658\n",
      "Epoch 6500/10000 Cost: 0.179537\n",
      "Epoch 6600/10000 Cost: 0.179420\n",
      "Epoch 6700/10000 Cost: 0.179297\n",
      "Epoch 6800/10000 Cost: 0.179187\n",
      "Epoch 6900/10000 Cost: 0.179070\n",
      "Epoch 7000/10000 Cost: 0.178958\n",
      "Epoch 7100/10000 Cost: 0.178843\n",
      "Epoch 7200/10000 Cost: 0.178731\n",
      "Epoch 7300/10000 Cost: 0.178624\n",
      "Epoch 7400/10000 Cost: 0.178513\n",
      "Epoch 7500/10000 Cost: 0.178415\n",
      "Epoch 7600/10000 Cost: 0.178303\n",
      "Epoch 7700/10000 Cost: 0.178200\n",
      "Epoch 7800/10000 Cost: 0.178097\n",
      "Epoch 7900/10000 Cost: 0.177990\n",
      "Epoch 8000/10000 Cost: 0.177891\n",
      "Epoch 8100/10000 Cost: 0.177788\n",
      "Epoch 8200/10000 Cost: 0.177692\n",
      "Epoch 8300/10000 Cost: 0.177589\n",
      "Epoch 8400/10000 Cost: 0.177498\n",
      "Epoch 8500/10000 Cost: 0.177398\n",
      "Epoch 8600/10000 Cost: 0.177298\n",
      "Epoch 8700/10000 Cost: 0.177202\n",
      "Epoch 8800/10000 Cost: 0.177110\n",
      "Epoch 8900/10000 Cost: 0.177017\n",
      "Epoch 9000/10000 Cost: 0.176922\n",
      "Epoch 9100/10000 Cost: 0.176835\n",
      "Epoch 9200/10000 Cost: 0.176742\n",
      "Epoch 9300/10000 Cost: 0.176650\n",
      "Epoch 9400/10000 Cost: 0.176555\n",
      "Epoch 9500/10000 Cost: 0.176468\n",
      "Epoch 9600/10000 Cost: 0.176377\n",
      "Epoch 9700/10000 Cost: 0.176289\n",
      "Epoch 9800/10000 Cost: 0.176196\n",
      "Epoch 9900/10000 Cost: 0.176110\n",
      "Epoch 10000/10000 Cost: 0.176025\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10000\n",
    "\n",
    "for epoch in range(num_epochs + 1):\n",
    "    \n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "    # model(x_train)은 model.forward(x_train)와 동일함.\n",
    "    \n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "    \n",
    "    # cost로 H(x) 계선\n",
    "    # gradient를 0으로 초기화\n",
    "    optimizer.zero_grad()\n",
    "    # 비용 함수를 미분하여 gradient 계산\n",
    "    cost.backward()\n",
    "    # W와 b를 업데이트\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "          epoch, num_epochs, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "portable-simon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 후 입력이 73, 80, 75일 때의 예측값 : tensor([[151.4162]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 임의의 입력 [73, 80, 75]를 선언\n",
    "new_var =  torch.FloatTensor([[73, 80, 75]]) \n",
    "# 입력한 값 [73, 80, 75]에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
    "pred_y = model(new_var) \n",
    "print(\"훈련 후 입력이 73, 80, 75일 때의 예측값 :\", pred_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "institutional-audit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[0.9778, 0.4539, 0.5768]], requires_grad=True), Parameter containing:\n",
      "tensor([0.2802], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-bandwidth",
   "metadata": {},
   "source": [
    "# 05. 클래스로 파이토치 모델 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-entry",
   "metadata": {},
   "source": [
    "## 1. 모델을 클래스로 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "egyptian-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "empirical-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegressionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bottom-clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3, 1) # 다중 선형 회귀이므로 input_dim=3, output_dim=1.\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "offensive-average",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultivariateLinearRegressionModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-nirvana",
   "metadata": {},
   "source": [
    "## 2. 단순 선형 회귀 클래스로 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "global-computer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "explicit-appearance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2c70a238de0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "conservative-catholic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[2], [4], [6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "smoking-nowhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "alpha-support",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "attached-background",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bright-cleanup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/2000 Cost: 18.562185\n",
      "Epoch  100/2000 Cost: 0.128051\n",
      "Epoch  200/2000 Cost: 0.079128\n",
      "Epoch  300/2000 Cost: 0.048896\n",
      "Epoch  400/2000 Cost: 0.030215\n",
      "Epoch  500/2000 Cost: 0.018671\n",
      "Epoch  600/2000 Cost: 0.011538\n",
      "Epoch  700/2000 Cost: 0.007129\n",
      "Epoch  800/2000 Cost: 0.004406\n",
      "Epoch  900/2000 Cost: 0.002722\n",
      "Epoch 1000/2000 Cost: 0.001682\n",
      "Epoch 1100/2000 Cost: 0.001040\n",
      "Epoch 1200/2000 Cost: 0.000642\n",
      "Epoch 1300/2000 Cost: 0.000397\n",
      "Epoch 1400/2000 Cost: 0.000245\n",
      "Epoch 1500/2000 Cost: 0.000152\n",
      "Epoch 1600/2000 Cost: 0.000094\n",
      "Epoch 1700/2000 Cost: 0.000058\n",
      "Epoch 1800/2000 Cost: 0.000036\n",
      "Epoch 1900/2000 Cost: 0.000022\n",
      "Epoch 2000/2000 Cost: 0.000014\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2000\n",
    "for epoch in range(num_epochs + 1):\n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "    \n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "          epoch, nb_epochs, cost.item()\n",
    "      ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-ethernet",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.7.1",
   "language": "python",
   "name": "torch1.7.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
